[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/Exercice_6Bonus.html",
    "href": "posts/Exercice_6Bonus.html",
    "title": "Exercice 6 Bonus : Ridge vs Lasso",
    "section": "",
    "text": "Dans cette partie et avant de passer à l’exercice 7, nous allons faire la section 3.1 sur la gression Ridge et Lasso avec glmnet sous R du tutoriel de Laurent Rouvière\n\nRappels sur Ridge et Lasso\nOn se base encore ici sur notre modèle classique de régression linéaire :\n\\[y = X\\beta + \\mathcal{E} \\quad \\text{ou} \\quad y = \\beta_0 + \\beta_1X^1 + ... + \\beta_pX^p + \\mathcal{E}\\]\n\n\\(y \\in \\mathbb{R}^{n}\\) la variable réponse ou variable à expliquer\n\\(X \\in \\mathbb{R}^{n\\times (p+1)}\\) la matrice déterministe contenant nos \\(p\\) variables explicatives\n\\(\\beta \\in \\mathbb{R}^{p+1}\\) le vecteur qui contient les coefficients de régression \\(\\beta_0, ..., \\beta_p\\) que nous cherchons à estimer\n\\(\\mathcal{E} \\in \\mathbb{R}^{n}\\) le vecteur d’erreur qui n’est pas corrélé à nos variables explicatives. C’est la part d’aléa que nous n’arrivons pas à déterminer\n\nPour l’estimation des coefficients de regression de ce type de modèle, nous utilisons souvent la méthodes des moindres carrées ordinaire (MCO) qui nous donne\n\\[\\hat{\\beta} = \\underset{\\beta}{argmin}||y-X\\beta||^2\\] Malheureusement, lorsque \\(p\\) est grand ou que les variables sont linéairement dépendantes, les estimateurs des moindres carrées peuvent être mis en défaut. Les méthodes pénalisées ou sous contraintes consistent alors à restreindre l’espace sur lequel on minimise ce critère.\n\nL’idée principale de ces méthodes est de contraindre la valeur des estimateurs MCO pour réduire la variance, quitte à augmenter un peu le biais (d’où la terminologie de “régression biaisée”). Nous obtenons donc, pour un certain \\(t&gt;0\\), des estimations de la forme suivante : \\[ \\hat{\\beta}^{pen} = \\underset{\\beta}{argmin}||y-X\\beta||^2 \\quad \\text{sous la contrainte} \\quad ||\\beta||? \\leq t\\]\n\nRidgeLasso\n\n\nLa régression Ridge contraint la norme \\(\\ell^2\\) des coefficients \\(\\beta\\) à ne pas exploser, i.e \\(||\\beta||_2 = \\sum_{j=0}^{p} \\beta_j^2 \\leq t\\). Cela conduit à la solution d’optimisation suivante :\n\\[\n\\hat{\\beta}_{Ridge} = \\underset{\\beta}{\\operatorname{argmin}} \\ ||y - X\\beta||^2 \\quad \\text{sous la contrainte} \\quad \\sum_{j=0}^{p} \\beta_j^2 \\leq t\n\\]\noù \\(\\hat{\\beta}_{Ridge}\\) est unique, contrairement à Lasso qui peut produire plusieurs solutions.\nContrairement à Lasso, Ridge ne met pas exactement à zéro certains coefficients, mais réduit leur valeur. Il n’y a donc pas de sélection de variable effectué.\nCette méthode est tout de même robuste en grande dimension et particulièrement utile lorsque les variables sont fortement corrélées. Il empêche les coefficients de devenir trop grands, ce qui réduit la variance du modèle.\n\n\n\nLa régression Lasso (pour Least Absolute Shrinkage and Selection Operator) contraint la norme \\(\\ell^1\\) de \\(\\beta\\) à ne pas exploser, i.e \\(||\\beta||_1 = \\sum_{j=0}^{p} |\\beta_j| \\leq t\\). Nous obtenons donc\n\\[\\hat{\\beta}_{Lasso} = \\underset{\\beta}{argmin}||y-X\\beta||^2 \\quad \\text{sous la contrainte} \\quad \\sum_{j=0}^{p} |\\beta_j| \\leq t  \\]\nOù \\(\\hat{\\beta}_{Lasso}\\) n’est pas nécessairement unique mais la prévision \\(\\hat{y} = X\\hat{\\beta}_{Lasso}\\) est unique.\n\nCette méthode est principalement caractérisée par le fait qu’elle est robuste à la grande dimension en sélectionnant les variables les plus pertinentes. En effet, elle nous permet de réduire les coefficients MCO des variables sélectionnées en rapprochant leur valeur de 0, ce qui est appelé la propriété de “seuillage doux” du Lasso.\n\n\n\nIci, il sera donc présenté les étapes principales qui permettent de faire ce type de régression avec R. Le package le plus souvent utilisé est glmnet.\n\n\nSetup\n\npackagesfonctions\n\n\n\n\nShow the code\n# PCA\nlibrary(FactoMineR)\nlibrary(factoextra)\n\n\nLe chargement a nécessité le package : ggplot2\n\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\n\nShow the code\n# Plots\n## ggplot\nlibrary(ggplot2)\nlibrary(reshape2)     # transformer les données en format long\nlibrary(gridExtra)\n\n## for pairs panel\nlibrary(psych)\n\n\n\nAttachement du package : 'psych'\n\n\nLes objets suivants sont masqués depuis 'package:ggplot2':\n\n    %+%, alpha\n\n\nShow the code\nlibrary(RColorBrewer)\n\n\n\n\n\nboxplotpairs.panels\n\n\n\n\nShow the code\nmy_boxplot &lt;- function(data) {\n  # Transformer les données en format long pour ggplot\n  data_long &lt;- melt(data)\n  \n  ggplot(data_long, aes(x = variable, y = value, fill = variable)) +\n    geom_boxplot() +\n    scale_fill_viridis_d() +  # Palette de couleurs harmonieuse\n    labs(title = \"Distribution des Variables (Boxplot)\", x = \"Variables\", y = \"Valeurs\") +\n    theme_minimal() +  # Thème épuré\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotation des étiquettes\n}\n\n\n\n\n\n\nShow the code\nmy_pairs.panels &lt;- function(data){\n  pairs.panels(\n    data,\n    method = \"pearson\",      # Méthode de corrélation \n    hist.col = brewer.pal(9, \"Set3\"), # Couleurs des histogrammes\n    density = TRUE,          # Ajout des courbes de densité\n    ellipses = TRUE,         # Ajout d'ellipses \n    smooth = TRUE,           # Ajout de régressions lissées\n    lm = TRUE,               # Ajout des droites de régression\n    col = \"#69b3a2\",         # Couleur des points\n    alpha = 0.5              # Transparence \n    )\n}\n\n\n\n\n\n\n\n\n\n\nDonnées\nOn considère le jeu de données ozone.txt où on cherche à expliquer la concentration maximale en ozone relevée sur une journée (variable maxO3) par d’autres variables essentiellement météorologiques.\nLa base de données d’origine ozone.txt répertorie 112 données météorologiques mesurées durant l’été 2001 à Rennes. Celles-ci sont caractérisées par les 13 variables suivantes :\n\n\n\n\n\nmaxO3\nconcentration maximale d'ozone (en DU)\n\n\nT9\ntempérature à 9H (en °C)\n\n\nT12\ntempérature à 12H (en °C)\n\n\nT15\ntempérature à 15H (en °C)\n\n\nNe9\nnébulosité à 9H (en octa)\n\n\nNe12\nnébulosité à 12H (en octa)\n\n\nNe15\nnébulosité à 15H (en octa)\n\n\nVx9\nvitesse du vent à 9H\n\n\nVx12\nvitesse du vent à 12H\n\n\nVx15\nvitesse du vent à 15H\n\n\nmaxO3v\nconcentration maximale d'ozone de la veille (en DU)\n\n\nvent\ndirection principale du vent (Nord / Ouest / Sud / Est)\n\n\npluie\nprésence ou non de pluie (Sec / Pluie)\n\n\n\n\n\n\n\nOn identifie le regroupement de toutes les données météorologiques récoltées en une journée par la date à laquelle les relevés ont été effectués.\n\n\nShow the code\nozone &lt;-read.table(\"https://r-stat-sc-donnees.github.io/ozone.txt\", header=TRUE)\nozone %&gt;% DT::datatable()\n\n\n\n\n\n\n\n\nShow the code\nozone %&gt;% summary()\n\n\n     maxO3              T9             T12             T15       \n Min.   : 42.00   Min.   :11.30   Min.   :14.00   Min.   :14.90  \n 1st Qu.: 70.75   1st Qu.:16.20   1st Qu.:18.60   1st Qu.:19.27  \n Median : 81.50   Median :17.80   Median :20.55   Median :22.05  \n Mean   : 90.30   Mean   :18.36   Mean   :21.53   Mean   :22.63  \n 3rd Qu.:106.00   3rd Qu.:19.93   3rd Qu.:23.55   3rd Qu.:25.40  \n Max.   :166.00   Max.   :27.00   Max.   :33.50   Max.   :35.50  \n      Ne9             Ne12            Ne15           Vx9         \n Min.   :0.000   Min.   :0.000   Min.   :0.00   Min.   :-7.8785  \n 1st Qu.:3.000   1st Qu.:4.000   1st Qu.:3.00   1st Qu.:-3.2765  \n Median :6.000   Median :5.000   Median :5.00   Median :-0.8660  \n Mean   :4.929   Mean   :5.018   Mean   :4.83   Mean   :-1.2143  \n 3rd Qu.:7.000   3rd Qu.:7.000   3rd Qu.:7.00   3rd Qu.: 0.6946  \n Max.   :8.000   Max.   :8.000   Max.   :8.00   Max.   : 5.1962  \n      Vx12             Vx15            maxO3v           vent          \n Min.   :-7.878   Min.   :-9.000   Min.   : 42.00   Length:112        \n 1st Qu.:-3.565   1st Qu.:-3.939   1st Qu.: 71.00   Class :character  \n Median :-1.879   Median :-1.550   Median : 82.50   Mode  :character  \n Mean   :-1.611   Mean   :-1.691   Mean   : 90.57                     \n 3rd Qu.: 0.000   3rd Qu.: 0.000   3rd Qu.:106.00                     \n Max.   : 6.578   Max.   : 5.000   Max.   :166.00                     \n    pluie          \n Length:112        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\n\n\nAnalyse descriptive\n\nBoxplotCorrelation panelPCA\n\n\nOn peut regarder un peu la distribution de nos différents variables quantitatives via des boxplots.\n\n\nShow the code\nmy_boxplot(ozone)\n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn remarque bien que les variabeles qui sont de même nature mais à des points de temps différents sont d’avantages similaires.\n\nPour confirmer cela, on peut faire des boxplot pour uniquement une varibale et ses différents points de temps.\n\nTempératureNébulositéVitesse du vent\n\n\n\n\nShow the code\nsubset(ozone, select = c(\"T9\", \"T12\", \"T15\"))  %&gt;% my_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nsubset(ozone, select = c(\"Ne9\", \"Ne12\", \"Ne15\"))  %&gt;% my_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nsubset(ozone, select = c(\"Vx9\", \"Vx12\", \"Vx15\"))  %&gt;% my_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn regarde ici la corrélation calculée entre chacune de nos variables.\n\n\nShow the code\nmy_pairs.panels(ozone)\n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn voit la présence de plusieurs fortes corrélations qui peut déjà nous alerter si l’on veut faire des modèles de regressions linéaires car on risque d’avoir un problème de colinéarité entre les varibales explicatives.\nCependant ces corrélation fortes sont surtout présentes pour les variables qui sont à différents points de temps ce qui est logique.\n\n\n\nAvec une Analyse en Composantes Principales (PCA) on peut regarder un peu le comportement de nos données.\nEn effet, Cette méthode respose sur la transformation des variables d’origine en nouvelles variables non corrélées, appelées composantes principales, qui capturent successivement la plus grande variance possible des données.\n\n\nShow the code\nres_pca &lt;- PCA(ozone, \n               quali.sup = c(which(colnames(ozone) %in% c(\"vent\", \"pluie\"))),\n               quanti.sup = c(which(colnames(ozone) %in% c(\"max03\", \"max03v\"))),\n               graph = FALSE)\n\n\nIci, on spécifi nos varibales qualitatives et on décide de mettre la variable max03 et max03v en variable supplémentaire, ce qui veut d’ire qu’elles ne seront pas considérés pour la formation de nos composantes principales (variable que l’on cherchera à estimer plus tard).\n\nBarplot des variancesIndividusVariables\n\n\nTout d’abord, on peut commencer par regarder le pourcentage de variance expliqué par nos différentes composantes principales.\n\n\nShow the code\nfviz_eig(res_pca, \n         ncp = 10,\n         addlabels = TRUE, \n         barfill = \"coral\",\n         barcolor = \"coral\",\n         ylim = c(0, 60),\n         main = \"Percentage of variance of the 10 first components\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn voit ainsi que la majorité de la variance est expliquée par nos deux premières composantes principales.\n\n\n\nLe plan des individus est une projection des observations sur les axes principaux de la PCA. Cette visualisation permet d’identifier des regroupements, tendances et anomalies au sein des données.\nAinsi, des individus proches sur le graphique ont des caractéristiques similaires par rapport aux variables utilisées.\nPuis, le placement d’un individu en fonction des axes peut permettre de savoir comment le jouer se caractérise par rapport aux variables qui contribuent le plus à ces axes.\n\nPluievent\n\n\n\n\nShow the code\nfviz_pca_ind(res_pca,\n             label=\"none\", \n             pointsize = 2,\n             habillage=as.factor(ozone$pluie),\n             addEllipses=TRUE,\n             ellipse.level=0.95)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nfviz_pca_ind(res_pca,\n             label=\"none\",\n             pointsize = 2,\n             habillage=as.factor(ozone$vent),\n             addEllipses=TRUE,\n             ellipse.level=0.95)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nIci on voit une repartition plutot uniforme sur le plan qui ne semble pas permettre de distinguer une séparation forte correspodant à nos variables qualitatives.\n\n\n\nLe cercle des variables est une représentation graphique qui permet d’analyser les relations entre les variables initiales et les composantes principales qui forment nos axes. Il est basé sur les corrélations entre les variables et les axes principaux.\nAinsi, plus une variable est proche du bord du cercle, plus elle est bien représentée sur le plan factoriel et contribue fortement à la formation des axes. Ici, on utilise le cos2 pour le gradient de couleur qui va aider à l’indentifictation de ces différentes qualitées de représentation.\nDe plus, selon l’angle entre deux varibles, on peut faire des suppositions sur leur corrélation :\n\nSi deux variables ont des vecteurs proches (petit angle), elles sont fortement corrélées positivement\nSi deux variables ont des vecteurs opposés (angle proche de 180°), elles sont corrélées négativement\nSi l’angle est proche de 90°, alors les variables ne sont pas corrélées\n\n\n\nShow the code\nfviz_pca_var(res_pca, \n             col.var = \"cos2\",\n             gradient.cols = rainbow(n = 8, start = .6, end = .9),\n             repel = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nDans notre cas, ce que l’on peut voir c’est que la majorité de nos variables sont bien représentées par nos deux axes (cumulant plus de 70% d’explication). Mais beaucoup semblent aussi fortement corrélées avecla formation de trois groupes. Cette corrélation ayant déjà pu être observé précédemment et touours logique du fait du côté longitudinale de nos données.\nCe que l’on peut tout de même ajouté c’est que les variables max03 et surtout max03v semblent plutot corrélées aux variables température. Constat qui peut se confirmer avec le pairs.panels précédent.\n\n\n\n\n\n\n\n\n\nAnalyse inférentielle\n\n\nShow the code\n# ozone &lt;- read.csv(\"~/1.Workspace/Master_IS/M2/X3MS020_Statistique_en_grande_dimension/ozone.txt\", sep=\"\")\nozone &lt;-read.table(\"https://r-stat-sc-donnees.github.io/ozone.txt\", header=TRUE)\nhead(ozone)\n\n\n         maxO3   T9  T12  T15 Ne9 Ne12 Ne15     Vx9    Vx12    Vx15 maxO3v\n20010601    87 15.6 18.5 18.4   4    4    8  0.6946 -1.7101 -0.6946     84\n20010602    82 17.0 18.4 17.7   5    5    7 -4.3301 -4.0000 -3.0000     87\n20010603    92 15.3 17.6 19.5   2    5    4  2.9544  1.8794  0.5209     82\n20010604   114 16.2 19.7 22.5   1    1    0  0.9848  0.3473 -0.1736     92\n20010605    94 17.4 20.5 20.4   8    8    7 -0.5000 -2.9544 -4.3301    114\n20010606    80 17.7 19.8 18.3   6    6    7 -5.6382 -5.0000 -6.0000     94\n          vent pluie\n20010601  Nord   Sec\n20010602  Nord   Sec\n20010603   Est   Sec\n20010604  Nord   Sec\n20010605 Ouest   Sec\n20010606 Ouest Pluie\n\n\nShow the code\nsummary(ozone)\n\n\n     maxO3              T9             T12             T15       \n Min.   : 42.00   Min.   :11.30   Min.   :14.00   Min.   :14.90  \n 1st Qu.: 70.75   1st Qu.:16.20   1st Qu.:18.60   1st Qu.:19.27  \n Median : 81.50   Median :17.80   Median :20.55   Median :22.05  \n Mean   : 90.30   Mean   :18.36   Mean   :21.53   Mean   :22.63  \n 3rd Qu.:106.00   3rd Qu.:19.93   3rd Qu.:23.55   3rd Qu.:25.40  \n Max.   :166.00   Max.   :27.00   Max.   :33.50   Max.   :35.50  \n      Ne9             Ne12            Ne15           Vx9         \n Min.   :0.000   Min.   :0.000   Min.   :0.00   Min.   :-7.8785  \n 1st Qu.:3.000   1st Qu.:4.000   1st Qu.:3.00   1st Qu.:-3.2765  \n Median :6.000   Median :5.000   Median :5.00   Median :-0.8660  \n Mean   :4.929   Mean   :5.018   Mean   :4.83   Mean   :-1.2143  \n 3rd Qu.:7.000   3rd Qu.:7.000   3rd Qu.:7.00   3rd Qu.: 0.6946  \n Max.   :8.000   Max.   :8.000   Max.   :8.00   Max.   : 5.1962  \n      Vx12             Vx15            maxO3v           vent          \n Min.   :-7.878   Min.   :-9.000   Min.   : 42.00   Length:112        \n 1st Qu.:-3.565   1st Qu.:-3.939   1st Qu.: 71.00   Class :character  \n Median :-1.879   Median :-1.550   Median : 82.50   Mode  :character  \n Mean   :-1.611   Mean   :-1.691   Mean   : 90.57                     \n 3rd Qu.: 0.000   3rd Qu.: 0.000   3rd Qu.:106.00                     \n Max.   : 6.578   Max.   : 5.000   Max.   :166.00                     \n    pluie          \n Length:112        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nShow the code\nlibrary(psych)\npairs.panels(ozone)\n\n\n\n\n\n\n\n\n\nShow the code\nozone.X &lt;- model.matrix(maxO3~.,data=ozone)[,-1] #  codage des variables qualitatives avec la fonction model.matrix\nozone.Y &lt;- ozone$maxO3\n\nlibrary(glmnet)\n\n\nLe chargement a nécessité le package : Matrix\n\n\n\nAttachement du package : 'Matrix'\n\n\nLes objets suivants sont masqués depuis 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-8\n\n\nShow the code\nmod.R &lt;- glmnet(ozone.X, ozone.Y, alpha=0) ## Ridge \n\nmod.L &lt;- glmnet(ozone.X, ozone.Y, alpha=1) ## Lasso\n\n# Par défaut standardize = TRUE, intercept = TRUE\n\n## Analyse Modèle Ridge\nmod.R$lambda |&gt; head()\n\n\n[1] 22007.27 20052.20 18270.82 16647.69 15168.76 13821.21\n\n\nShow the code\n# When alpha=0, the largest lambda reported does not quite give \n# the zero coefficients reported (lambda=inf would in principle).\n# Instead, the largest lambda for alpha=0.001 is used, and the sequence \n# of lambda values is derived from this.\n\n\nmod.R$beta[,1]\n\n\n           T9           T12           T15           Ne9          Ne12 \n 6.376767e-36  5.523924e-36  4.867402e-36 -6.821464e-36 -7.994984e-36 \n         Ne15           Vx9          Vx12          Vx15        maxO3v \n-5.839057e-36  5.706014e-36  4.387350e-36  3.970583e-36  6.892387e-37 \n     ventNord     ventOuest       ventSud      pluieSec \n-5.830507e-36 -1.022483e-35  1.519222e-35  2.772246e-35 \n\n\nShow the code\n# Our coefficients\n\npar(mfrow=c(1,2))\nplot(mod.R,label=TRUE)  \n# lecture du graphe : \n#   - chaque courbe c'est lévolution d'un beta\n#   - à droite on à les valeurs de beta MCO \n#   - à gauche c'est quand lambda augmente, on tend vers 0\n\nplot(mod.R,xvar=\"lambda\",label=TRUE)\n\n\n\n\n\n\n\n\n\nShow the code\npar(mfrow=c(1,1))\n\n\n\n\n\n\n\n## Analyse Modèle Lasso\nmod.L$lambda |&gt; head()\n\n\n[1] 22.00727 20.05220 18.27082 16.64769 15.16876 13.82121\n\n\nShow the code\nmod.L$beta[,1]\n\n\n       T9       T12       T15       Ne9      Ne12      Ne15       Vx9      Vx12 \n        0         0         0         0         0         0         0         0 \n     Vx15    maxO3v  ventNord ventOuest   ventSud  pluieSec \n        0         0         0         0         0         0 \n\n\nShow the code\npar(mfrow=c(1,2))\nplot(mod.L,label=TRUE)  \nplot(mod.L,xvar=\"lambda\",label=TRUE)\n\n\n\n\n\n\n\n\n\nShow the code\npar(mfrow=c(1,1))\n\n####\n# Sélection des paramètres de régularisation ####\n\nridgeCV &lt;- cv.glmnet(ozone.X, ozone.Y, alpha=0)\nplot(ridgeCV)\n\n\n\n\n\n\n\n\n\nShow the code\n# abline(v=log(ridgeCV$lambda.1se), col='red')\n# abline(v=log(ridgeCV$lambda.min), col='red')\n\n# On visualise les erreurs quadratiques calculées \n# par validation croisée 10 blocs en fonction de lambda (échelle log)\n\n# Deux traites verticaux :\n#   - celui de gauche correspond à la valeur de `lambda`\n#     qui minimise l’erreur quadratique ;\n# \n#   - celui de droite correspond à la plus grande valeur de `lambda` \n#     telle que l’erreur ne dépasse pas \n#     l’erreur minimale + 1 écart-type estimé de cette erreur.\n\n\n# D’un point de vu pratique, cela signifie que l’utilisateur\n# peut choisir n’importe quelle valeur de lambda entre \n# les deux traits verticaux. Si on veut diminuer \n# la complexité du modèle on choisira la valeur de droite.\n# On peut obtenir ces deux valeurs \n\nridgeCV$lambda.min\n\n\n[1] 8.095109\n\n\nShow the code\nridgeCV$lambda.1se\n\n\n[1] 39.36329\n\n\nShow the code\nlassoCV &lt;- cv.glmnet(ozone.X, ozone.Y, alpha=1)\nplot(lassoCV)\n\n\n\n\n\n\n\n\n\nShow the code\n# abline(v=log(lassoCV$lambda.1se), col='red')\n# abline(v=log(lassoCV$lambda.min), col='red')\n\nlassoCV$lambda.min\n\n\n[1] 1.350346\n\n\nShow the code\nlassoCV$lambda.1se\n\n\n[1] 4.525822\n\n\nShow the code\n####\n# Prédiction de la variable cible pour de nouveaux individus ####\n\n# Première approche :\n# réajuster le modèle sur toutes les données pour la valeur \n# de lambda sélectionnée.\n# Cette étape est en réalité déjà effectuée par la fonction cv.glmnet.\n# Il suffit par conséquent d’appliquer la fonction predict à l’objet \n# obtenu avec cv.glmnet en spécifiant la valeur de lambda souhaitée.\npredict(ridgeCV, newx = ozone.X[50:51,],s=\"lambda.min\")\n\n\n         lambda.min\n20010723   89.63446\n20010724   96.79269\n\n\nShow the code\npredict(ridgeCV, newx = ozone.X[50:51,],s=\"lambda.1se\")\n\n\n         lambda.1se\n20010723   93.11072\n20010724   96.26805\n\n\nShow the code\npredict(lassoCV, newx = ozone.X[50:51,],s=\"lambda.min\")\n\n\n         lambda.min\n20010723   87.18766\n20010724   98.11351\n\n\nShow the code\npredict(lassoCV, newx = ozone.X[50:51,],s=\"lambda.1se\")\n\n\n         lambda.1se\n20010723   87.40631\n20010724   95.85602\n\n\nShow the code\n# Comparaison performances MCO, ridge et lasso ####\n\n# validation croisée pour comparer les performances des estimateurs\n# MCO, ridge et lasso.\n# On pourra utiliser les données ozone_complet.txt\n# qui contiennent plus d’individus et de variables.\n\n# ozone1 &lt;- read.csv(\"~/1. Workspace/Master IS/M2/X3MS020 Statistique en grande dimension/ozone_complet.txt\", sep=\";\") |&gt; na.omit()\nozone1 &lt;-read.table(\"https://r-stat-sc-donnees.github.io/ozone.txt\", header=TRUE) |&gt; na.omit()\nozone1.X &lt;- model.matrix(maxO3~., data=ozone1)[,-1]\nozone1.Y &lt;- ozone1$maxO3\n\nlibrary(tibble)\nlibrary(dplyr)\n\ncv.ridge.lasso &lt;- function(data,form){\n  set.seed(1234)\n  data.X &lt;- model.matrix(form,data=data)[,-1]\n  data.Y &lt;- data$maxO3\n  blocs &lt;- caret::createFolds(1:nrow(data),k=10)\n  prev &lt;- matrix(0,ncol=3,nrow=nrow(data)) |&gt; as.data.frame()\n  names(prev) &lt;- c(\"lin\",\"ridge\",\"lasso\")\n  for (k in 1:10){\n    app &lt;- data[-blocs[[k]],]\n    test &lt;- data[blocs[[k]],]\n    app.X &lt;- data.X[-blocs[[k]],]\n    app.Y &lt;- data.Y[-blocs[[k]]]\n    test.X &lt;- data.X[blocs[[k]],]\n    test.Y &lt;- data.Y[blocs[[k]]]\n    ridge &lt;- cv.glmnet(app.X,app.Y,alpha=0)\n    lasso &lt;- cv.glmnet(app.X,app.Y,alpha=1)\n    lin &lt;- lm(form,data=app)\n    prev[blocs[[k]],] &lt;- tibble(lin=predict(lin,newdata=test),\n                                ridge=as.vector(predict(ridge,newx=test.X)),\n                                lasso=as.vector(predict(lasso,newx=test.X)))\n  }\n  err &lt;- prev |&gt; mutate(obs=data$maxO3) |&gt; summarise_at(1:3,~mean((obs-.)^2))\n  return(err)\n}\n\ncv.ridge.lasso(ozone1, form=formula(maxO3~.))\n\n\n       lin    ridge    lasso\n1 247.4596 271.8111 272.9936\n\n\nShow the code\n# On remarque que les approches régularisées \n# n’apportent rien par rapport aux estimateurs MCO ici.\n# Ceci peut s’expliquer par le fait que le nombre de variables\n# n’est pas très important.\n\n# Considérons toutes les interactions d’ordre 2\ncv.ridge.lasso(ozone1, form=formula(maxO3~.^2))\n\n\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\n\n\n       lin    ridge    lasso\n1 196622.7 335.9692 268.1647\n\n\nShow the code\n# Les méthodes régularisées permettent ici de diminuer\n# les erreurs quadratiques de manière intéressante.\n# Cela vient certainement du fait du nombre de \n# variables explicatives qui est beaucoup plus \n# important lorsqu’on prend en compte toutes \n# les interactions d’ordre 2, nous en avons en effet 253 :\nozone2.X &lt;- model.matrix(maxO3~.^2,data=ozone1)[,-1]\ndim(ozone2.X)\n\n\n[1] 112 102"
  },
  {
    "objectID": "posts/Exercice_03.html",
    "href": "posts/Exercice_03.html",
    "title": "Exercice 3",
    "section": "",
    "text": "set.seed(123)\n\n\nQuestion 1 ————————————————————–\n\nx = rnorm(1000)\ny = x - 2*(x^2) + rnorm(1000)\n# modele avec n = 1000 et p = 2. beta = t(1, -2 )\n\nNous allons généré un modèle de régression linéaire classique : \\[Y = X\\beta + \\mathcal{E}\\] - \\(Y \\in \\mathbb{R}^{n}\\) la variable réponse ou variable à expliquer\n\n\\(X \\in \\mathbb{R}^{n\\times p}\\) la matrice contenant nos variables explicatives\n\\(\\beta \\in \\mathbb{R}^{n}\\) le vecteur composée des coefficients de régression\n\\(\\mathcal{E} \\in \\mathbb{R}^{n}\\) le vecteur d’erreur suivant une loi \\(\\mathcal{N}(0, 1)\\)\n\nPour la génération de nos données, nous allons alors poser que \\(\\beta = (1, 2)'\\) et \\(X = [x_1, x_1^2]\\), \\(x_1 \\in \\mathbb{R}^n\\) suivant une loi \\(\\mathcal{N}(0,1)\\).\n\n\nQuestion 2 ————————————————————–\n\nplot(x,y)\n\n\n\n\n\n\n\ncor(x,y)\n\n[1] 0.2908668\n\n# correlation faible, pourtant le nuage de point montre bien un effet de x sur y \n\n\n\nQuestion 3 ————————————————————–\n\ndf = as.data.frame(cbind(y, x, x^2, x^3, x^4))\nmod1 = lm(y~x, data = df)\nmod2 = lm(y~ x + V3, data=df)\nmod3 = lm(y~ x + V3 + V4, data=df)\nmod4 = lm(y~ x + V3 + V4 + V5, data=df)\n\nsummary(mod1)\n\n\nCall:\nlm(formula = y ~ x, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.8594  -0.9890   0.7507   1.8526   5.0428 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.92130    0.09229 -20.818   &lt;2e-16 ***\nx            0.89410    0.09310   9.604   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.918 on 998 degrees of freedom\nMultiple R-squared:  0.0846,    Adjusted R-squared:  0.08369 \nF-statistic: 92.24 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n\ncor(x,y)^2\n\n[1] 0.08460352\n\n#le r2 du mod1 doit correspondre à la corr^2 : ok\n\n\n\nQuestion 4 ————————————————————–\n\nsummary(mod1)$r.squared\n\n[1] 0.08460352\n\nBIC(mod1)\n\n[1] 4998.42\n\nAIC(mod1)\n\n[1] 4983.697\n\nBIC(mod2)\n\n[1] 2876.101\n\nAIC(mod2)\n\n[1] 2856.47\n\nBIC(mod3)\n\n[1] 2881.088\n\nAIC(mod3)\n\n[1] 2856.549\n\nBIC(mod4)\n\n[1] 2885.15\n\nAIC(mod4)\n\n[1] 2855.704\n\n# mod2 est le meilleur modèle \n\n## FAIRE UN TABLEAU POUR LES RESULTATS\n# R2, R2aj, Cp, AIC, BIC, coeff, etc...\n\n\n\nQuestion 5 ————————————————————–\n\nfmla2 = y~ x + V3\nfmla3 = y~ x + V3 + V4\nfmla1 = y~ x\nfmla4 = y~ x + V3 + V4 + V5\n####\n\n# ##### TRASH ####\n# \n# FMLA = c(fmla1, fmla2, fmla3, fmla4)\n# \n# LOO_1 = function(y, x, fmla, j){\n#   y_res = rep(NA, 1000)\n#   for (i in 1:1000){\n#     \n#     df[i] = as.data.frame(cbind(y[-i], x[-i], x[-i]^2, x[-i]^3, x[-i]^4))\n#     mod = lm(fmla[[j]], data = df[i])\n#     \n#     \n#     df2[i] = as.data.frame(cbind(x[-i], x[-i]^2, x[-i]^3, x[-i]^4))\n#     yi_hat = predict(mod, df2[i])\n#     yi = y[i]\n#     y_res[i] = yi - yi_hat \n#   }\n#   loo = mean(y_res^2)\n#     return(loo)\n# }\n# LOO_1(y,x,FMLA, 2)\n# \n# \n# \n# LOO_2 =function(y, x, fmla, i){\n#   r = lm(fmla[[i]], data = df)$residuals\n#   h = hatvalues(lm(fmla[[i]], data = df)) #diag de hatmatrix\n#   loo = mean((r/(1-h))^2)\n#   return(loo)\n# }\n# LOO_2(y,x,FMLA, 1)\n# LOO_2(y,x,FMLA, 2)\n# LOO_2(y,x,FMLA, 3)\n# LOO_2(y,x,FMLA, 4)\n# \n# #####\n\n# Fonction loo qui utilise en entree le modele (ne fonctionne pas si la formule utilise la fonction poly)\nloo=function(mod){\n  n = nrow(mod$model)\n  Call = mod$call # mod1$call --&gt; lm(formula = y ~ x, data = df)\n  erreur=1:n\n  for(i in 1:n){\n    Call$data = mod$model[-i, ] # mod1$call$data = df\n    fit = eval.parent(Call)\n    pred = predict(fit, mod$model[i,])\n    erreur[i] = (pred - mod$model[i,1])^2\n  }\n  return(mean(erreur))\n}\n\n\n\n#Fonction loo qui utilise la formule du cours\nloo2=function(mod){\n  mean((residuals(mod)/(1-hatvalues(mod)))^2)\n}\n\n\n\nQuestion 6 ————————————————————–\n\nloo(mod1)\n\n[1] 8.581687\n\nloo(mod2)\n\n[1] 1.016685\n\nloo(mod3)\n\n[1] 1.017154\n\nloo(mod4)\n\n[1] 1.01563\n\nloo2(mod1)\n\n[1] 8.581687\n\nloo2(mod2)\n\n[1] 1.016685\n\nloo2(mod3)\n\n[1] 1.017154\n\nloo2(mod4)\n\n[1] 1.01563\n\n# les resultats coincident\n# loo2 est plus rapide pour calculer \n# le plus haut loo est pour mod1 et le plus bas pour mod4 \n# (même si resultats prochent entre mod2, mod3 et mod4)\n\n# modèle le plus parcimonieux est le mod2\n\n\n\nQuestion 7 ————————————————————–\n\nlibrary(boot)\n# Loo c'est K=1\n\nmod1_glm = glm(formula = fmla1 , family = gaussian, data = df)\nmod2_glm = glm(formula = fmla2 , family = gaussian, data = df)\nmod3_glm = glm(formula = fmla3 , family = gaussian, data = df)\nmod4_glm = glm(formula = fmla4 , family = gaussian, data = df)\n\n\ncvmod1 = cv.glm(data = df, glmfit = mod1_glm, K = 10) \ncvmod2 = cv.glm(data = df, glmfit = mod2_glm, K = 10) \ncvmod3 = cv.glm(data = df, glmfit = mod3_glm, K = 10) \ncvmod4 = cv.glm(data = df, glmfit = mod4_glm, K = 10) \n\nsummary(cvmod1$delta)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  8.566   8.567   8.567   8.567   8.568   8.569 \n\nloo2(mod1)\n\n[1] 8.581687\n\nsummary(cvmod2$delta)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.015   1.015   1.016   1.016   1.016   1.016 \n\nloo2(mod2)\n\n[1] 1.016685\n\nsummary(cvmod3$delta)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.014   1.014   1.014   1.014   1.015   1.015 \n\nloo2(mod3)\n\n[1] 1.017154\n\nsummary(cvmod4$delta)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.017   1.017   1.017   1.017   1.017   1.017 \n\nloo2(mod4)\n\n[1] 1.01563\n\n# les valeurs ont la même ordre de grandeur\n\n\n\nQuestion 8 ————————————————————–\n\n# on regarde les 3 mod où loo faible \nsummary(mod2)\n\n\nCall:\nlm(formula = y ~ x + V3, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0319 -0.6942  0.0049  0.7116  3.2855 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.05006    0.03924   1.276    0.202    \nx            1.08894    0.03220  33.817   &lt;2e-16 ***\nV3          -2.00919    0.02338 -85.943   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.007 on 997 degrees of freedom\nMultiple R-squared:  0.8911,    Adjusted R-squared:  0.8909 \nF-statistic:  4080 on 2 and 997 DF,  p-value: &lt; 2.2e-16\n\nsummary(mod3)\n\n\nCall:\nlm(formula = y ~ x + V3 + V4, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0691 -0.6821  0.0060  0.7023  3.3186 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.05425    0.03934   1.379    0.168    \nx            1.02684    0.05522  18.594   &lt;2e-16 ***\nV3          -2.01489    0.02373 -84.917   &lt;2e-16 ***\nV4           0.02177    0.01573   1.384    0.167    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.006 on 996 degrees of freedom\nMultiple R-squared:  0.8913,    Adjusted R-squared:  0.891 \nF-statistic:  2723 on 3 and 996 DF,  p-value: &lt; 2.2e-16\n\nsummary(mod4)\n\n\nCall:\nlm(formula = y ~ x + V3 + V4 + V5, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0765 -0.6854 -0.0009  0.7140  3.3274 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.018703   0.044616   0.419   0.6752    \nx            1.014166   0.055684  18.213   &lt;2e-16 ***\nV3          -1.931446   0.054935 -35.158   &lt;2e-16 ***\nV4           0.028192   0.016171   1.743   0.0816 .  \nV5          -0.016599   0.009858  -1.684   0.0925 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.005 on 995 degrees of freedom\nMultiple R-squared:  0.8917,    Adjusted R-squared:  0.8912 \nF-statistic:  2047 on 4 and 995 DF,  p-value: &lt; 2.2e-16\n\n# les r2 sont tous bon mais le mod2 à toutes ses variables significatives (sauf intercept)\n# on va donc préférer le mod2\n\n# On enlève la cst non significative \nmod_final = lm(y ~ x + V3-1, data=df)\nmod_final_glm = glm(y ~ x + V3-1, data=df) # par defaut family = gaussian\nsummary(mod2)\n\n\nCall:\nlm(formula = y ~ x + V3, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0319 -0.6942  0.0049  0.7116  3.2855 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.05006    0.03924   1.276    0.202    \nx            1.08894    0.03220  33.817   &lt;2e-16 ***\nV3          -2.00919    0.02338 -85.943   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.007 on 997 degrees of freedom\nMultiple R-squared:  0.8911,    Adjusted R-squared:  0.8909 \nF-statistic:  4080 on 2 and 997 DF,  p-value: &lt; 2.2e-16\n\nsummary(mod_final)\n\n\nCall:\nlm(formula = y ~ x + V3 - 1, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9910 -0.6570  0.0328  0.7467  3.3288 \n\nCoefficients:\n   Estimate Std. Error t value Pr(&gt;|t|)    \nx   1.08779    0.03220   33.78   &lt;2e-16 ***\nV3 -1.99176    0.01898 -104.97   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.007 on 998 degrees of freedom\nMultiple R-squared:  0.9216,    Adjusted R-squared:  0.9215 \nF-statistic:  5870 on 2 and 998 DF,  p-value: &lt; 2.2e-16\n\nsummary(mod_final_glm)\n\n\nCall:\nglm(formula = y ~ x + V3 - 1, data = df)\n\nCoefficients:\n   Estimate Std. Error t value Pr(&gt;|t|)    \nx   1.08779    0.03220   33.78   &lt;2e-16 ***\nV3 -1.99176    0.01898 -104.97   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 1.014328)\n\n    Null deviance: 12919.5  on 1000  degrees of freedom\nResidual deviance:  1012.3  on  998  degrees of freedom\nAIC: 2856.1\n\nNumber of Fisher Scoring iterations: 2\n\n# x = rnorm(1000)\n# y = x - 2*(x^2) + rnorm(1000)\n \n# REMARQUE :\n# quand on enlève l'intercept, les valeurs des coeffs bougent légèrement \n# alors que théoriquement identique \n# pareil, on a une différence sur le r2\n# Pourquoi ??\n\n# regardons le modèle plus simple\nmod1_sansIntercept = lm(y ~ x -1, data=df)\nsummary(mod1)\n\n\nCall:\nlm(formula = y ~ x, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.8594  -0.9890   0.7507   1.8526   5.0428 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.92130    0.09229 -20.818   &lt;2e-16 ***\nx            0.89410    0.09310   9.604   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.918 on 998 degrees of freedom\nMultiple R-squared:  0.0846,    Adjusted R-squared:  0.08369 \nF-statistic: 92.24 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n\nsummary(mod1_sansIntercept)\n\n\nCall:\nlm(formula = y ~ x - 1, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-20.6785  -2.8966  -1.1766  -0.0688   3.1315 \n\nCoefficients:\n  Estimate Std. Error t value Pr(&gt;|t|)    \nx   0.8626     0.1114   7.741  2.4e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.493 on 999 degrees of freedom\nMultiple R-squared:  0.05659,   Adjusted R-squared:  0.05565 \nF-statistic: 59.93 on 1 and 999 DF,  p-value: 2.402e-14\n\n# on constante le même soucis\n\nmean(x) # x n'est pas parfaitement centré\n\n[1] 0.01612787\n\nvar(x) # var pas = 1\n\n[1] 0.9834589\n\n# Don même si on a demandé à r de générer un x centré reduit,\n# enfait les données ne le sont pas parfaitement !!!!\n\n# on test en juste centrer le jeu de données\ndf_center = as.data.frame(scale(df, center=TRUE, scale=FALSE))\n\nmod2_center= lm(y ~ x + V3, data=df_center)\nmod_final_center = lm(y ~ x + V3-1, data=df_center)\nsummary(mod2_center)\n\n\nCall:\nlm(formula = y ~ x + V3, data = df_center)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0319 -0.6942  0.0049  0.7116  3.2855 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.894e-17  3.184e-02    0.00        1    \nx            1.089e+00  3.220e-02   33.82   &lt;2e-16 ***\nV3          -2.009e+00  2.338e-02  -85.94   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.007 on 997 degrees of freedom\nMultiple R-squared:  0.8911,    Adjusted R-squared:  0.8909 \nF-statistic:  4080 on 2 and 997 DF,  p-value: &lt; 2.2e-16\n\nsummary(mod_final_center)\n\n\nCall:\nlm(formula = y ~ x + V3 - 1, data = df_center)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0319 -0.6942  0.0049  0.7116  3.2855 \n\nCoefficients:\n   Estimate Std. Error t value Pr(&gt;|t|)    \nx   1.08894    0.03218   33.83   &lt;2e-16 ***\nV3 -2.00919    0.02337  -85.99   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.006 on 998 degrees of freedom\nMultiple R-squared:  0.8911,    Adjusted R-squared:  0.8909 \nF-statistic:  4085 on 2 and 998 DF,  p-value: &lt; 2.2e-16\n\n# quasi plus de différence pour coeffs et r2\n\n\n# on test en scale le jeu de données\ndf_scale = as.data.frame(scale(df))\n\nmod2_scale= lm(y ~ x + V3, data=df_scale)\nmod_final_scale = lm(y ~ x + V3-1, data=df_scale)\nsummary(mod2_scale)\n\n\nCall:\nlm(formula = y ~ x + V3, data = df_scale)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.99458 -0.22772  0.00162  0.23344  1.07780 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -3.739e-17  1.044e-02    0.00        1    \nx            3.543e-01  1.048e-02   33.82   &lt;2e-16 ***\nV3          -9.003e-01  1.048e-02  -85.94   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3303 on 997 degrees of freedom\nMultiple R-squared:  0.8911,    Adjusted R-squared:  0.8909 \nF-statistic:  4080 on 2 and 997 DF,  p-value: &lt; 2.2e-16\n\nsummary(mod_final_scale)\n\n\nCall:\nlm(formula = y ~ x + V3 - 1, data = df_scale)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.99458 -0.22772  0.00162  0.23344  1.07780 \n\nCoefficients:\n   Estimate Std. Error t value Pr(&gt;|t|)    \nx   0.35425    0.01047   33.83   &lt;2e-16 ***\nV3 -0.90030    0.01047  -85.99   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3301 on 998 degrees of freedom\nMultiple R-squared:  0.8911,    Adjusted R-squared:  0.8909 \nF-statistic:  4085 on 2 and 998 DF,  p-value: &lt; 2.2e-16\n\n# quasi plus de différence pour coeffs et r2\n\n\n## remarque : \n# le r2 et r2aj est le meilleur pour mod_final qui correspond\n# au mod 2 sans intercept mais où l'on a pas scale le df"
  },
  {
    "objectID": "posts/Exercice_01.html",
    "href": "posts/Exercice_01.html",
    "title": "Exercice 1",
    "section": "",
    "text": "packagesFonctions\n\n\n\n\nShow the code\n# Données\nlibrary(ISLR)         # Hitters data \nlibrary(dplyr)        # manipulation des données\n\n# PCA\nlibrary(FactoMineR)\nlibrary(factoextra)\n\n# Inférence\nlibrary(leaps)        # regsubsets \nlibrary(car)          # pour VIF\n\n# Plots\n## ggplot\nlibrary(ggplot2)\nlibrary(reshape2)     # transformer les données en format long\nlibrary(gridExtra)\n\n## for pairs panel\nlibrary(psych)\nlibrary(RColorBrewer)\n\n\n\n\n\nCritèresplot pour nos critèresMeilleur modèle après regsubset\n\n\nOn rappel que \\(SCR = \\sum_i (y_i - f(x_i))^2\\) et \\(SCT = \\sum_i (y_i - \\bar{y})^2\\).\n\nAinsi, on peut aretrouver les différents critères :\n\\[ R^2 = 1 - \\frac{SCR}{SCT}\\]\n\n\nShow the code\nr2_fun &lt;- function(y, SCR){\n  # r2 = SSE/SST = (SST - SSR)/SST = 1 - ssr/sst\n  SCT &lt;- sum((y - mean(y) )^2)\n  r2 &lt;- 1 - SCR/SCT\n  return(r2)\n}\n\n\n\\[ R^2_{adjusted} = 1 - \\frac{SCR (n-1)}{SCT(n-(p+1))}\\]\n\n\nShow the code\nr2a_fun &lt;- function(y, SCR){\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  SCT &lt;- sum((y - mean(y) )^2)\n  r2a &lt;- 1 - (SCR/(n-(p+1)))/(SCT/(n-1))\n  return(r2a)\n}\n\n\n\\[ C_p = \\frac{SCR}{\\sigma^2} + 2(p+1) - n\\]\n\n\nShow the code\ncp_fun &lt;- function(mod, SCR){\n  sig &lt;- summary(mod)$sigma\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  cp &lt;- SCR/sig^2 + 2*(p+1) - n\n  return(cp)\n}\n\n\n\\[ AIC = n\\text{log}\\left(\\frac{SCR}{n}\\right) + 2(p+1)\\]\n\n\nShow the code\naic_fun &lt;- function(SCR){\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  aic &lt;- n * log(SCR/n) + 2*(p+1)\n  return(aic)\n}\n\n\n\\[ BIC = n\\text{log}\\left(\\frac{SCR}{n}\\right) + \\text{log}(n)(p+1)\\]\n\n\nShow the code\nbic_fun &lt;- function(SCR){\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  bic &lt;- n * log(SCR/n) + log(n)*(p+1)\n  return(bic)\n}\n\n\n\n\n\n\nShow the code\nCriteria_plot &lt;- function(Criteria, crit_name = \"Critère\") {\n  # Création d'un data frame pour ggplot\n  df_criteria &lt;- data.frame(\n    nb_var = seq_along(Criteria),  # Nombre de variables du modèle\n    Criteria = Criteria            # Critère\n  )\n\n  # Création du plot avec ggplot2\n  g &lt;- ggplot(df_criteria, aes(x = nb_var, y = Criteria)) +\n    geom_line(color = \"#0072B2\", linewidth = 1) +  \n    geom_point(color = \"#D55E00\", size = 4) + \n    labs(\n      title = paste(\"Évolution de\", crit_name, \"en fonction du nombre de variables\"),\n      x = \"Nombre de variables sélectionnées\",\n      y = crit_name\n    ) +\n    theme_minimal() + \n    theme(\n      plot.title = element_text(hjust = 0.5, face = \"bold\", size = 26),  # Titre centré et agrandi\n      axis.title.x = element_text(face = \"bold\", size = 22),\n      axis.title.y = element_text(face = \"bold\", size = 22),\n      axis.text = element_text(size = 20)\n    )\n\n  return(g)\n}\n\n\n\n\n\n\nShow the code\nBest_model &lt;- function(model, criteria_df){\n  ## On a d'abord les critères à maximiser\n  for(i in 1:2){\n    criteria_name &lt;- colnames(criteria_df)[i]\n    criteria &lt;- criteria_df[,i]\n    \n    best_model_criteria &lt;- which.max(criteria)\n    selected_vars &lt;- summary(model)$which[best_model_criteria,]\n    \n    cat(\"Meilleur modèle selon\", criteria_name,\" : Modèle avec\", best_model_criteria, \"variables\\n\", \n        rownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE]), \"\\n\", \"\\n\")\n  }\n  ## On a ensuite les critères à minimiser\n  for(i in 3:5){\n    criteria_name &lt;- colnames(criteria_df)[i]\n    criteria &lt;- criteria_df[,i]\n    \n    best_model_criteria &lt;- which.min(criteria)\n    selected_vars &lt;- summary(model)$which[best_model_criteria,]\n    \n    cat(\"Meilleur modèle selon\", criteria_name,\" : Modèle avec\", best_model_criteria, \"variables\\n\", \n        rownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE]), \"\\n\", \"\\n\")\n  }\n}"
  },
  {
    "objectID": "posts/Exercice_01.html#modèle-brut",
    "href": "posts/Exercice_01.html#modèle-brut",
    "title": "Exercice 1",
    "section": "Modèle brut",
    "text": "Modèle brut\nOn désire modéliser le salaire Salary en fonction des variables disponibles.\nOn va donc ajuster un modèle de régression linéaire en utilisant toutes les variables à disposition et analyser la qualité de cet ajustement.\n\n\nShow the code\nmod1 &lt;- lm(formula = Salary ~ .,\n           Hitters_Without_NA) \nmod1 %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ ., data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-907.62 -178.35  -31.11  139.09 1877.04 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  163.10359   90.77854   1.797 0.073622 .  \nAtBat         -1.97987    0.63398  -3.123 0.002008 ** \nHits           7.50077    2.37753   3.155 0.001808 ** \nHmRun          4.33088    6.20145   0.698 0.485616    \nRuns          -2.37621    2.98076  -0.797 0.426122    \nRBI           -1.04496    2.60088  -0.402 0.688204    \nWalks          6.23129    1.82850   3.408 0.000766 ***\nYears         -3.48905   12.41219  -0.281 0.778874    \nCAtBat        -0.17134    0.13524  -1.267 0.206380    \nCHits          0.13399    0.67455   0.199 0.842713    \nCHmRun        -0.17286    1.61724  -0.107 0.914967    \nCRuns          1.45430    0.75046   1.938 0.053795 .  \nCRBI           0.80771    0.69262   1.166 0.244691    \nCWalks        -0.81157    0.32808  -2.474 0.014057 *  \nLeagueN       62.59942   79.26140   0.790 0.430424    \nDivisionW   -116.84925   40.36695  -2.895 0.004141 ** \nPutOuts        0.28189    0.07744   3.640 0.000333 ***\nAssists        0.37107    0.22120   1.678 0.094723 .  \nErrors        -3.36076    4.39163  -0.765 0.444857    \nNewLeagueN   -24.76233   79.00263  -0.313 0.754218    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 315.6 on 243 degrees of freedom\nMultiple R-squared:  0.5461,    Adjusted R-squared:  0.5106 \nF-statistic: 15.39 on 19 and 243 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNote\n\n\n\nNous sommes sur un modèle comprenant des variables quantitatives et qualitative ce qui le rapproche d’une modélisation ANOVA.\n\n\n\n\n\n\nRésultats\n\n\nQuelques conclusions sur le modèle :\n\nbeaucoup de variables ont un effet non significatif\nle \\(R^2\\) et le \\(R^2_{adjusted}\\) sont autour de 0.5 ce qui témoigne d’une mauvaise qualité d’ajustament du modèle\nl’écart type résiduel est de 315.6 ce qui est assez important et témoigne d’un modèle peu précis\n\n\nPour tenter de trouver un meilleur ajustment, il est important d’analyser d’avantage le lien entre toutes les variables explicatives. On utilise alors comunément le VIF (variance inflation factor).\nOn obtient alors pour chacune de nos variable une valeur qui, plus elle est élevé, témoigne de la multicolinéarité entre nos variables explicatives.\n\n\nShow the code\nvif(mod1) \n\n\n     AtBat       Hits      HmRun       Runs        RBI      Walks      Years \n 22.944366  30.281255   7.758668  15.246418  11.921715   4.148712   9.313280 \n    CAtBat      CHits     CHmRun      CRuns       CRBI     CWalks     League \n251.561160 502.954289  46.488462 162.520810 131.965858  19.744105   4.134115 \n  Division    PutOuts    Assists     Errors  NewLeague \n  1.075398   1.236317   2.709341   2.214543   4.099063 \n\n\nOn remarque ainsi que beaucoup de valeurs sont supérieur à 10 ce qui s’interprète communément comme la précence d’une forte colinéarité sur nos variables explicatives.\n\n\n\n\n\n\nNote\n\n\n\nCette colinéarité se constatait déjà durant les analyses descriptive via les graphes de corrélations (d’où l’importance de ne pas se lancer trop rapidement dans les analyses inférentielles)."
  },
  {
    "objectID": "posts/Exercice_01.html#modèles-parcimonieux",
    "href": "posts/Exercice_01.html#modèles-parcimonieux",
    "title": "Exercice 1",
    "section": "Modèles parcimonieux",
    "text": "Modèles parcimonieux\nMaintenant, on va donc tenter de trouver le meilleur sous-modèle possible. Pour cela on va suivre la procédure suivante :\n\nmettre en oeuvre une méthode de sélection automatique exhaustive et observer l’évolution des SCR (Sommes de Carrés Résiduels) pour les modèles retenus en fonction de leur taille.\ndéduire de ces SCR le \\(R^2\\), \\(R^2_{adjusted}\\), AIC, BIC et \\(C_p\\) correspondants. Les comparer avec les valeurs fournies dans le summary de regsubsets et tracer leur évolution en fonction de la taille du modèle.\n\nPuis reproduire la même procédure avec des séléctions backward, forward et stepwise\n\n\n\n\n\n\nNote\n\n\n\nUn rappel sur nos critère se trouve dans la partie Setup, onglet fonction, de ce document avec la création de fonction pour les calculer.\n\n\n\nExhaustiveBackwardForwardStepwise\n\n\n\nModèleEvolution des critèresMeilleur modèle\n\n\n\n\nShow the code\nselec_auto &lt;- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"exhaustive\",\n                         nvmax = 19 # maximum size of subsets to examine\n                         )\n# selec_auto %&gt;% summary()\n\n\nOn va déjà commencer par regarder la valeur du critère en fonction des variables des différents modèles testés.\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(selec_auto, scale = 'bic') \nplot(selec_auto, scale = 'Cp') \nplot(selec_auto, scale = 'r2') \nplot(selec_auto, scale = 'adjr2') \n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nIci on remarque clairement que toutes nos variables ne sont pas gardés lorsque l’on cherche à optimiser nos critères.\nAussi, on peut voir encore de faibles valeurs pour les \\(R^2\\) et \\(R^2_{adjusted}\\) pouvant témoignés d’un mauvais ajustement de modèle.\n\n\n\n\n\n\n\nNote\n\n\n\nplot.regsubsets() de leaps ne prend pas directement “aic” comme option de scale. Pour une sélection basée sur AIC, une approche alternative consiste à utiliser la fonction stepAIC() du package MASS, qui permet une sélection pas à pas basée sur AIC.\n\n\n\n\nRegardons un peut l’évolution de la Somme des Carrés Résiduels (SCR).\n\n\nShow the code\nSCR &lt;- summary(selec_auto)$rss\nCriteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\")\n\n\n\n\n\n\n\n\n\nMaintenant regardons les autres critères mentionné précédemment\n\n\nShow the code\nr2 &lt;- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a &lt;- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp &lt;- cp_fun(mod1, SCR)\naic &lt;- aic_fun(SCR)\nbic &lt;- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n\n\n\n\n\n\n\n\n\nOn peut ainsi voir que ce sont plutot des modèles entre 5 et 10 variables qui optimisent nos critères (donc pas un modèle avec toutes nos variables).\n\n\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\n\nShow the code\ncriteria_df &lt;- data.frame(r2, r2a, cp, aic, bic)\nBest_model(selec_auto, criteria_df)\n\n\nMeilleur modèle selon r2  : Modèle avec 19 variables\n (Intercept) AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN \n \nMeilleur modèle selon r2a  : Modèle avec 11 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists \n \nMeilleur modèle selon cp  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon aic  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon bic  : Modèle avec 6 variables\n (Intercept) AtBat Hits Walks CRBI DivisionW PutOuts \n \n\n\n\n\n\n\n\nCette fois ci on va regarder en sélection backward. D’abord, on fait à nouveau avec la fonction regsubset.\n\nModèleEvolution des critèresMeilleur modèle\n\n\n\n\nShow the code\nselec_back &lt;- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"backward\",\n                         nvmax = 19)\n\n\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(selec_back, scale = 'bic') \nplot(selec_back, scale = 'Cp') \nplot(selec_back, scale = 'r2') \nplot(selec_back, scale = 'adjr2') \n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn remarque à nouveau une importante sélection de variables.\nMais ici aussi on a encore de faibles valeurs pour les \\(R^2\\) et \\(R^2_{adjusted}\\) pouvant témoignés d’un mauvais ajustement de modèle.\n\n\n\n\n\nShow the code\nSCR &lt;- summary(selec_back)$rss\nr2 &lt;- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a &lt;- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp &lt;- cp_fun(mod1, SCR)\naic &lt;- aic_fun(SCR)\nbic &lt;- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n\n\n\n\n\n\n\n\n\n\n\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\n\nShow the code\ncriteria_df &lt;- data.frame(r2, r2a, cp, aic, bic)\nBest_model(selec_back, criteria_df)\n\n\nMeilleur modèle selon r2  : Modèle avec 19 variables\n (Intercept) AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN \n \nMeilleur modèle selon r2a  : Modèle avec 11 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists \n \nMeilleur modèle selon cp  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon aic  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon bic  : Modèle avec 8 variables\n (Intercept) AtBat Hits Walks CRuns CRBI CWalks DivisionW PutOuts \n \n\n\n\n\n\n\nUtilisation de la fonction step\n\nOn peut également utiliser la fonction step de la library { stats }. Pour cela, on part du plus gros modèle défini précédemment par mod1.\nLa fonction step nous propose quel critère nous voulons utiliser pour la sélection entre le BIC, AIC et \\(C_p\\).\n\nBICAIC\\(C_p\\)\n\n\n\n\nShow the code\nn &lt;- nrow(Hitters_Without_NA)\nmodselect_back_bic &lt;- step(mod1,\n                       scope = formula(mod1),\n                       trace = FALSE, # trace = TRUE permet de voir le détail des étapes\n                       direction = c(\"backward\"),\n                       k = log(n) # BIC selection\n                       )\n\n\nPuis on peut regarder le modèle qui optimise le critère utilisé pour la selection.\n\n\nShow the code\nmodselect_back_bic %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CRuns + CRBI + CWalks + \n    Division + PutOuts, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-794.06 -171.94  -28.48  133.36 2017.83 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  117.15204   65.07016   1.800 0.072985 .  \nAtBat         -2.03392    0.52282  -3.890 0.000128 ***\nHits           6.85491    1.65215   4.149 4.56e-05 ***\nWalks          6.44066    1.52212   4.231 3.25e-05 ***\nCRuns          0.70454    0.24869   2.833 0.004981 ** \nCRBI           0.52732    0.18861   2.796 0.005572 ** \nCWalks        -0.80661    0.26395  -3.056 0.002483 ** \nDivisionW   -123.77984   39.28749  -3.151 0.001824 ** \nPutOuts        0.27539    0.07431   3.706 0.000259 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 314.7 on 254 degrees of freedom\nMultiple R-squared:  0.5281,    Adjusted R-squared:  0.5133 \nF-statistic: 35.54 on 8 and 254 DF,  p-value: &lt; 2.2e-16\n\n\nLa fonction step propose aussi une selection avec AIC et Cp.\n\n\n\n\nShow the code\nmodselect_back_aic &lt;- step(mod1,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"backward\"),\n                       k = 2 # AIC selection\n                       )\n\nmodselect_back_aic %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + \n    CRBI + CWalks + Division + PutOuts + Assists, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-939.11 -176.87  -34.08  130.90 1910.55 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  162.53544   66.90784   2.429 0.015830 *  \nAtBat         -2.16865    0.53630  -4.044 7.00e-05 ***\nHits           6.91802    1.64665   4.201 3.69e-05 ***\nWalks          5.77322    1.58483   3.643 0.000327 ***\nCAtBat        -0.13008    0.05550  -2.344 0.019858 *  \nCRuns          1.40825    0.39040   3.607 0.000373 ***\nCRBI           0.77431    0.20961   3.694 0.000271 ***\nCWalks        -0.83083    0.26359  -3.152 0.001818 ** \nDivisionW   -112.38006   39.21438  -2.866 0.004511 ** \nPutOuts        0.29737    0.07444   3.995 8.50e-05 ***\nAssists        0.28317    0.15766   1.796 0.073673 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.8 on 252 degrees of freedom\nMultiple R-squared:  0.5405,    Adjusted R-squared:  0.5223 \nF-statistic: 29.64 on 10 and 252 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nShow the code\nmodselect_back_cp &lt;- step(mod1,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"backward\"),\n                       k = 1 # Cp selection\n                       )\n\nmodselect_back_cp %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + \n    CRBI + CWalks + League + Division + PutOuts + Assists, data = Hitters_Without_NA)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-932.2 -175.4  -29.2  130.4 1897.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  135.75122   71.34623   1.903 0.058223 .  \nAtBat         -2.12775    0.53746  -3.959 9.81e-05 ***\nHits           6.92370    1.64612   4.206 3.62e-05 ***\nWalks          5.62028    1.59064   3.533 0.000488 ***\nCAtBat        -0.13899    0.05609  -2.478 0.013870 *  \nCRuns          1.45533    0.39270   3.706 0.000259 ***\nCRBI           0.78525    0.20978   3.743 0.000225 ***\nCWalks        -0.82286    0.26361  -3.121 0.002010 ** \nLeagueN       43.11162   39.96612   1.079 0.281755    \nDivisionW   -111.14603   39.21835  -2.834 0.004970 ** \nPutOuts        0.28941    0.07478   3.870 0.000139 ***\nAssists        0.26883    0.15816   1.700 0.090430 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 251 degrees of freedom\nMultiple R-squared:  0.5426,    Adjusted R-squared:  0.5226 \nF-statistic: 27.07 on 11 and 251 DF,  p-value: &lt; 2.2e-16\n\n\nOn voit que parmi nos modèles, le BIC semble le plus parcimonieux mais de manière général on constate encore des valeurs de \\(R^2\\) et \\(R^2_{adjusted}\\) assez faibles.\n\n\n\n\n\n\nCette fois ci on va regarder en sélection forward. D’abord, on fait à nouveau avec la fonction regsubset.\n\nModèleEvolution des critèresMeilleur modèle\n\n\n\n\nShow the code\nselec_forw &lt;- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"forward\",\n                         nvmax = 19)\n\n\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(selec_forw, scale = 'bic') \nplot(selec_forw, scale = 'Cp') \nplot(selec_forw, scale = 'r2') \nplot(selec_forw, scale = 'adjr2') \n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn remarque à nouveau une importante sélection de variables.\nMais ici aussi on a encore de faibles valeurs pour les \\(R^2\\) et \\(R^2_{adjusted}\\) pouvant témoignés d’un mauvais ajustement de modèle.\n\n\n\n\n\nShow the code\nSCR &lt;- summary(selec_forw)$rss\nr2 &lt;- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a &lt;- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp &lt;- cp_fun(mod1, SCR)\naic &lt;- aic_fun(SCR)\nbic &lt;- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n\n\n\n\n\n\n\n\n\n\n\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\n\nShow the code\ncriteria_df &lt;- data.frame(r2, r2a, cp, aic, bic)\nBest_model(selec_forw, criteria_df)\n\n\nMeilleur modèle selon r2  : Modèle avec 19 variables\n (Intercept) AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN \n \nMeilleur modèle selon r2a  : Modèle avec 11 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists \n \nMeilleur modèle selon cp  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon aic  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon bic  : Modèle avec 6 variables\n (Intercept) AtBat Hits Walks CRBI DivisionW PutOuts \n \n\n\n\n\n\n\nUtilisation de la fonction step\n\nOn peut également utiliser la fonction step de la library { stats }. Cette fois ci il faut définir en modèle de départ le plus petit modèle (celui composé seulement de l’intercept).\nLa fonction step nous propose quel critère nous voulons utiliser pour la sélection entre le BIC, AIC et \\(C_p\\).\n\nBICAIC\\(C_p\\)\n\n\n\n\nShow the code\nmod0 &lt;- lm(Salary~1,\n           Hitters_Without_NA)\n\nmodselect_forw_bic &lt;- step(mod0,\n                       scope = formula(mod1),\n                       trace = FALSE, # trace = TRUE permet de voir le détail des étapes\n                       direction = c(\"forward\"),\n                       k = log(n) # BIC selection\n                       )\n\n\nPuis on peut regarder le modèle qui optimise le critère utilisé pour la selection.\n\n\nShow the code\nmodselect_forw_bic %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-873.11 -181.72  -25.91  141.77 2040.47 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   91.51180   65.00006   1.408 0.160382    \nCRBI           0.64302    0.06443   9.979  &lt; 2e-16 ***\nHits           7.60440    1.66254   4.574 7.46e-06 ***\nPutOuts        0.26431    0.07477   3.535 0.000484 ***\nDivisionW   -122.95153   39.82029  -3.088 0.002239 ** \nAtBat         -1.86859    0.52742  -3.543 0.000470 ***\nWalks          3.69765    1.21036   3.055 0.002488 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 319.9 on 256 degrees of freedom\nMultiple R-squared:  0.5087,    Adjusted R-squared:  0.4972 \nF-statistic: 44.18 on 6 and 256 DF,  p-value: &lt; 2.2e-16\n\n\nLa fonction step propose aussi une selection avec AIC et Cp.\n\n\n\n\nShow the code\nmodselect_forw_aic &lt;- step(mod0,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"forward\"),\n                       k = 2 # AIC selection\n                       )\n\nmodselect_forw_aic %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-939.11 -176.87  -34.08  130.90 1910.55 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  162.53544   66.90784   2.429 0.015830 *  \nCRBI           0.77431    0.20961   3.694 0.000271 ***\nHits           6.91802    1.64665   4.201 3.69e-05 ***\nPutOuts        0.29737    0.07444   3.995 8.50e-05 ***\nDivisionW   -112.38006   39.21438  -2.866 0.004511 ** \nAtBat         -2.16865    0.53630  -4.044 7.00e-05 ***\nWalks          5.77322    1.58483   3.643 0.000327 ***\nCWalks        -0.83083    0.26359  -3.152 0.001818 ** \nCRuns          1.40825    0.39040   3.607 0.000373 ***\nCAtBat        -0.13008    0.05550  -2.344 0.019858 *  \nAssists        0.28317    0.15766   1.796 0.073673 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.8 on 252 degrees of freedom\nMultiple R-squared:  0.5405,    Adjusted R-squared:  0.5223 \nF-statistic: 29.64 on 10 and 252 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nShow the code\nmodselect_forw_cp &lt;- step(mod0,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"forward\"),\n                       k = 1 # Cp selection\n                       )\n\nmodselect_forw_cp %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists + League, data = Hitters_Without_NA)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-932.2 -175.4  -29.2  130.4 1897.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  135.75122   71.34623   1.903 0.058223 .  \nCRBI           0.78525    0.20978   3.743 0.000225 ***\nHits           6.92370    1.64612   4.206 3.62e-05 ***\nPutOuts        0.28941    0.07478   3.870 0.000139 ***\nDivisionW   -111.14603   39.21835  -2.834 0.004970 ** \nAtBat         -2.12775    0.53746  -3.959 9.81e-05 ***\nWalks          5.62028    1.59064   3.533 0.000488 ***\nCWalks        -0.82286    0.26361  -3.121 0.002010 ** \nCRuns          1.45533    0.39270   3.706 0.000259 ***\nCAtBat        -0.13899    0.05609  -2.478 0.013870 *  \nAssists        0.26883    0.15816   1.700 0.090430 .  \nLeagueN       43.11162   39.96612   1.079 0.281755    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 251 degrees of freedom\nMultiple R-squared:  0.5426,    Adjusted R-squared:  0.5226 \nF-statistic: 27.07 on 11 and 251 DF,  p-value: &lt; 2.2e-16\n\n\nOn voit que parmi nos modèles, le BIC semble le plus parcimonieux mais de manière général on constate encore des valeurs de \\(R^2\\) et \\(R^2_{adjusted}\\) assez faibles.\n\n\n\n\n\n\nMaintenant on va regarder en sélection stepwise. D’abord, on fait à nouveau avec la fonction regsubset.\n\nModèleEvolution des critèresMeilleur modèle\n\n\n\n\nShow the code\nselec_seq &lt;- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"seqrep\",\n                         nvmax = 19)\n\n\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(selec_seq, scale = 'bic') \nplot(selec_seq, scale = 'Cp') \nplot(selec_seq, scale = 'r2') \nplot(selec_seq, scale = 'adjr2') \n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn remarque à nouveau une importante sélection de variables.\nMais ici aussi on a encore de faibles valeurs pour les \\(R^2\\) et \\(R^2_{adjusted}\\) pouvant témoignés d’un mauvais ajustement de modèle.\n\n\n\n\n\nShow the code\nSCR &lt;- summary(selec_seq)$rss\nr2 &lt;- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a &lt;- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp &lt;- cp_fun(mod1, SCR)\naic &lt;- aic_fun(SCR)\nbic &lt;- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n\n\n\n\n\n\n\n\n\n\n\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\n\nShow the code\ncriteria_df &lt;- data.frame(r2, r2a, cp, aic, bic)\nBest_model(selec_seq, criteria_df)\n\n\nMeilleur modèle selon r2  : Modèle avec 19 variables\n (Intercept) AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN \n \nMeilleur modèle selon r2a  : Modèle avec 11 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists \n \nMeilleur modèle selon cp  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon aic  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon bic  : Modèle avec 6 variables\n (Intercept) AtBat Hits Walks CRBI DivisionW PutOuts \n \n\n\n\n\n\n\nUtilisation de la fonction step\n\nOn peut également utiliser la fonction step de la library { stats }.\nLa fonction step nous propose quel critère nous voulons utiliser pour la sélection entre le BIC, AIC et \\(C_p\\).\n\nBICAIC\\(C_p\\)\n\n\n\n\nShow the code\nmodselect_bic &lt;- step(mod0,\n                  scope = formula(mod1),\n                  trace = FALSE,\n                  direction = c(\"both\"),\n                  k = log(n))\nmodselect_bic %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-873.11 -181.72  -25.91  141.77 2040.47 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   91.51180   65.00006   1.408 0.160382    \nCRBI           0.64302    0.06443   9.979  &lt; 2e-16 ***\nHits           7.60440    1.66254   4.574 7.46e-06 ***\nPutOuts        0.26431    0.07477   3.535 0.000484 ***\nDivisionW   -122.95153   39.82029  -3.088 0.002239 ** \nAtBat         -1.86859    0.52742  -3.543 0.000470 ***\nWalks          3.69765    1.21036   3.055 0.002488 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 319.9 on 256 degrees of freedom\nMultiple R-squared:  0.5087,    Adjusted R-squared:  0.4972 \nF-statistic: 44.18 on 6 and 256 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nShow the code\nmodselect_aic &lt;- step(mod0,\n                  scope = formula(mod1),\n                  trace = FALSE,\n                  direction = c(\"both\"),\n                  k = 2)\nmodselect_aic %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-939.11 -176.87  -34.08  130.90 1910.55 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  162.53544   66.90784   2.429 0.015830 *  \nCRBI           0.77431    0.20961   3.694 0.000271 ***\nHits           6.91802    1.64665   4.201 3.69e-05 ***\nPutOuts        0.29737    0.07444   3.995 8.50e-05 ***\nDivisionW   -112.38006   39.21438  -2.866 0.004511 ** \nAtBat         -2.16865    0.53630  -4.044 7.00e-05 ***\nWalks          5.77322    1.58483   3.643 0.000327 ***\nCWalks        -0.83083    0.26359  -3.152 0.001818 ** \nCRuns          1.40825    0.39040   3.607 0.000373 ***\nCAtBat        -0.13008    0.05550  -2.344 0.019858 *  \nAssists        0.28317    0.15766   1.796 0.073673 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.8 on 252 degrees of freedom\nMultiple R-squared:  0.5405,    Adjusted R-squared:  0.5223 \nF-statistic: 29.64 on 10 and 252 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nShow the code\nmodselect_cp &lt;- step(mod0,\n                  scope = formula(mod1),\n                  trace = FALSE,\n                  direction = c(\"both\"),\n                  k = 1)\nmodselect_cp %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists + League, data = Hitters_Without_NA)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-932.2 -175.4  -29.2  130.4 1897.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  135.75122   71.34623   1.903 0.058223 .  \nCRBI           0.78525    0.20978   3.743 0.000225 ***\nHits           6.92370    1.64612   4.206 3.62e-05 ***\nPutOuts        0.28941    0.07478   3.870 0.000139 ***\nDivisionW   -111.14603   39.21835  -2.834 0.004970 ** \nAtBat         -2.12775    0.53746  -3.959 9.81e-05 ***\nWalks          5.62028    1.59064   3.533 0.000488 ***\nCWalks        -0.82286    0.26361  -3.121 0.002010 ** \nCRuns          1.45533    0.39270   3.706 0.000259 ***\nCAtBat        -0.13899    0.05609  -2.478 0.013870 *  \nAssists        0.26883    0.15816   1.700 0.090430 .  \nLeagueN       43.11162   39.96612   1.079 0.281755    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 251 degrees of freedom\nMultiple R-squared:  0.5426,    Adjusted R-squared:  0.5226 \nF-statistic: 27.07 on 11 and 251 DF,  p-value: &lt; 2.2e-16\n\n\nMalheuresement, même en sélection both nous avons encore des \\(R^2\\) et \\(R^2_{adjusted}\\) faibles.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAussi, si on veut comparer le modèle initial et le modèle final, on peut utiliser la fonction ANOVA. Cela permet de voir si la sélection de variables a significativement amélioré l’ajustement.\n\n\nShow the code\nanova(mod0, modselect_bic, test = \"Chisq\")\n\n\nAnalysis of Variance Table\n\nModel 1: Salary ~ 1\nModel 2: Salary ~ CRBI + Hits + PutOuts + Division + AtBat + Walks\n  Res.Df      RSS Df Sum of Sq  Pr(&gt;Chi)    \n1    262 53319113                           \n2    256 26194904  6  27124209 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDe manière logique on voit donc tout de même que le modèle avec nos variable explicatives sélectionnées (ici celui avec selection via le critère BIC) propose un meilleur ajustement que celui sans variable."
  },
  {
    "objectID": "posts/Exercice_02.html",
    "href": "posts/Exercice_02.html",
    "title": "Exercice 2",
    "section": "",
    "text": "packagesFonctions\n\n\n\n\nShow the code\n# Données\nlibrary(ISLR)         # Hitters data \nlibrary(dplyr)        # manipulation des données"
  },
  {
    "objectID": "posts/Exercice_02.html#modèle-brut",
    "href": "posts/Exercice_02.html#modèle-brut",
    "title": "Exercice 2",
    "section": "Modèle brut",
    "text": "Modèle brut\nOn désire modéliser le salaire Salary en fonction des variables disponibles.\nOn va donc ajuster un modèle de régression linéaire en utilisant toutes les variables à disposition et analyser la qualité de cet ajustement.\n\n\nShow the code\nmod1 &lt;- lm(formula = Salary ~ .,\n           Hitters_Without_NA_18) \nmod1 %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ ., data = Hitters_Without_NA_18)\n\nResiduals:\nALL 18 residuals are 0: no residual degrees of freedom!\n\nCoefficients: (2 not defined because of singularities)\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) -223.7909        NaN     NaN      NaN\nAtBat         -3.2428        NaN     NaN      NaN\nHits          13.1990        NaN     NaN      NaN\nHmRun        -60.8834        NaN     NaN      NaN\nRuns           0.6875        NaN     NaN      NaN\nRBI           10.3993        NaN     NaN      NaN\nWalks          7.0114        NaN     NaN      NaN\nYears         -2.3702        NaN     NaN      NaN\nCAtBat         0.2643        NaN     NaN      NaN\nCHits         -1.7919        NaN     NaN      NaN\nCHmRun         5.3897        NaN     NaN      NaN\nCRuns          4.0162        NaN     NaN      NaN\nCRBI          -4.0134        NaN     NaN      NaN\nCWalks         1.5822        NaN     NaN      NaN\nLeagueN      233.6380        NaN     NaN      NaN\nDivisionW    299.1771        NaN     NaN      NaN\nPutOuts       -0.1250        NaN     NaN      NaN\nAssists       -0.8539        NaN     NaN      NaN\nErrors             NA         NA      NA       NA\nNewLeagueN         NA         NA      NA       NA\n\nResidual standard error: NaN on 0 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:    NaN \nF-statistic:   NaN on 17 and 0 DF,  p-value: NA\n\n\n\n\n\n\nRésultats\n\n\nOn peut clairement constater que ce modèle brut ne fonctionne pas avec pourtant un \\(R^2 = 1\\). On retrouve donc le problème typique de l’analyse en grande dimension lorsque \\(p&gt;n\\) (fléau de la dimensionalité).\n\nOn peut aussi s’amuser à regarder les critères AIC et BIC de ce modèles qui se retrouve à tendre vers l’infini.\n\n\nShow the code\ncat( \"AIC = \", AIC(mod1), \"et BIC = \", BIC(mod1))\n\n\nAIC =  -Inf et BIC =  -Inf\n\n\n\nPrediction\nOn va maintenant tenter de prédire la variable Salary pour les autres joueurs.\nDéjà on peut regarder sur les 18 joueurs si la prédiction via le modèle nous donne des bonnes valeur.\n\n\nShow the code\nSalary_hat &lt;- predict(mod1, Hitters_Without_NA_18)\nSalary &lt;- Hitters_Without_NA_18$Salary\n\n\n\n\\(\\widehat{Salary} - Salary =\\) 0\n\nCe que l’on constate c’est qu’effectivement nous sommes avec un résultat qui pourrait nous faire penser que le modèle est bien ajusté.\nPourtant si nous regardons la prédiction obtenue par le modèle pour les autres joueurs et que nous effectuons la même soustraction pour comparer la qualité de prediction, nous voyons bien l’inéfficacité du modèle.\n\n\nShow the code\nHitters_Without_NA_No18 &lt;- Hitters_Without_NA[19:nrow(Hitters_Without_NA),]\nSalary_hat_No18 &lt;- predict(mod1, Hitters_Without_NA_No18)\nSalary_No18 &lt;- Hitters_Without_NA_No18$Salary\nsummary(Salary_hat_No18 - Salary_No18 )\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-2363.67  -424.10   -49.12   -70.88   294.40  2648.41 \n\n\nEn effet on voit bien au dessus que les valeurs ne sont pas proche de 0 en moyennes et on même des valeurs assez extrêmes."
  },
  {
    "objectID": "posts/Exercice_02.html#modèles-parcimonieux",
    "href": "posts/Exercice_02.html#modèles-parcimonieux",
    "title": "Exercice 2",
    "section": "Modèles parcimonieux",
    "text": "Modèles parcimonieux\nOn va maintenant mettre un oeuvre une méthode de sélection automatique classique pour réduire le nombre de variable explicative et tenter d’éviter les problèmes de grande dimension.\nPour cela nous allons donc partir du plus petit modèle (celui avec seulement l’intercept) puis faire grandir le nombre de variable. Il av donc s’agir d’une méthode de sélection automatique forward.\n\n\nShow the code\nmod0 &lt;- lm(Salary~1, Hitters_Without_NA_18)\nmod_forw &lt;- step(mod0,\n                 scope = formula(mod1),\n                 trace = FALSE,\n                 direction = c(\"forward\"))\nmod_forw %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ CWalks + League, data = Hitters_Without_NA_18)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-215.51  -82.67  -48.10   26.13  302.49 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  259.3539    77.1270   3.363  0.00427 ** \nCWalks         0.9699     0.1606   6.039 2.27e-05 ***\nLeagueN     -137.2850    79.1236  -1.735  0.10322    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 160.8 on 15 degrees of freedom\nMultiple R-squared:  0.7495,    Adjusted R-squared:  0.7161 \nF-statistic: 22.44 on 2 and 15 DF,  p-value: 3.095e-05\n\n\n\n\n\n\nRésultats\n\n\nNous obtenons maintenant un modèle avec 2 variable dont une significative. Puis nous pouvons constater des valeurs assez élevés pour le \\(R^2\\) et \\(R^2_{adjusted}\\).\nRegardons aussi les critères AIC et BIC.\n\n\nShow the code\ncat( \"AIC = \", AIC(mod_forw), \"et BIC = \", BIC(mod_forw))\n\n\nAIC =  238.6917 et BIC =  242.2531\n\n\n\nMaintenant, nous allons permuter de façon aléatoire les salaires des 18 joueurs et refaire la même analyse inférentielle. Ainsi, le lien linéaire devrait disparaitre et nous donner de mauvais résultats.\n\n\nShow the code\nSalary_permute &lt;- sample(Salary)\n\nmod1_permute &lt;- lm(Salary_permute~., Hitters_Without_NA_18)\nmod1_permute %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary_permute ~ ., data = Hitters_Without_NA_18)\n\nResiduals:\nALL 18 residuals are 0: no residual degrees of freedom!\n\nCoefficients: (3 not defined because of singularities)\n              Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) -1691.3242        NaN     NaN      NaN\nAtBat          23.5739        NaN     NaN      NaN\nHits          -83.2162        NaN     NaN      NaN\nHmRun        -216.4632        NaN     NaN      NaN\nRuns           23.8588        NaN     NaN      NaN\nRBI            48.1013        NaN     NaN      NaN\nWalks          -5.3417        NaN     NaN      NaN\nYears         212.2108        NaN     NaN      NaN\nCAtBat         -4.6390        NaN     NaN      NaN\nCHits          20.7608        NaN     NaN      NaN\nCHmRun         35.6101        NaN     NaN      NaN\nCRuns          -2.8155        NaN     NaN      NaN\nCRBI          -18.1981        NaN     NaN      NaN\nCWalks          3.2163        NaN     NaN      NaN\nLeagueN       530.1532        NaN     NaN      NaN\nDivisionW     278.8899        NaN     NaN      NaN\nPutOuts         0.2543        NaN     NaN      NaN\nAssists        -1.6806        NaN     NaN      NaN\nErrors              NA         NA      NA       NA\nSalary              NA         NA      NA       NA\nNewLeagueN          NA         NA      NA       NA\n\nResidual standard error: NaN on 0 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:    NaN \nF-statistic:   NaN on 17 and 0 DF,  p-value: NA\n\n\nA nouveau on peut constater l’inéfficacité d’un modèle avec toutes les variables du fait d’avoir \\(p&gt;n\\).\nUtilisons maintenant la sélection automatique.\n\n\nShow the code\nmod0_permute &lt;- lm(Salary_permute~1, Hitters_Without_NA_18)\nmod_forw_permute &lt;- step(mod0_permute, \n                         scope = formula(mod1_permute),\n                         trace = FALSE,\n                         direction = c(\"forward\"))\n\n\nWarning: tenter une sélection de modèle à partir d'un ajustement pratiquement\nparfait n'a pas de sens\n\n\nShow the code\nmod_forw_permute %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary_permute ~ CHmRun + PutOuts + Walks + Errors + \n    Runs + Hits + AtBat + CHits + CAtBat + RBI + Salary + CWalks + \n    Years + Assists + League + NewLeague + HmRun, data = Hitters_Without_NA_18)\n\nResiduals:\nALL 18 residuals are 0: no residual degrees of freedom!\n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) -1118.5036        NaN     NaN      NaN\nCHmRun         -4.2335        NaN     NaN      NaN\nPutOuts         0.6251        NaN     NaN      NaN\nWalks         -14.3743        NaN     NaN      NaN\nErrors        -19.4883        NaN     NaN      NaN\nRuns            3.8869        NaN     NaN      NaN\nHits          -96.1700        NaN     NaN      NaN\nAtBat          27.1961        NaN     NaN      NaN\nCHits          12.0885        NaN     NaN      NaN\nCAtBat         -3.4439        NaN     NaN      NaN\nRBI            11.8299        NaN     NaN      NaN\nSalary          1.6720        NaN     NaN      NaN\nCWalks         -2.2232        NaN     NaN      NaN\nYears         163.5650        NaN     NaN      NaN\nAssists         0.7908        NaN     NaN      NaN\nLeagueN       297.0710        NaN     NaN      NaN\nNewLeagueN   -228.2722        NaN     NaN      NaN\nHmRun          -2.5657        NaN     NaN      NaN\n\nResidual standard error: NaN on 0 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:    NaN \nF-statistic:   NaN on 17 and 0 DF,  p-value: NA\n\n\n\n\n\n\nRésultats\n\n\nOn retrouve ici un modèle très différent concernant les variables sélectionnés avec de très mauvais résultats de \\(R^2\\) et \\(R^2_{adjusted}\\).\n\nPour finir, on va maintenant reprendre le jeu de données Hitters complet et permuter tous les salaires de façon aléatoire. Ensuite, on va ajuster le meilleur modèle de régression possible pour expliquer les salaires en fonction des autres variables.\n\n\nShow the code\nSalary_permute &lt;- sample(Hitters_Without_NA$Salary)\nHitters_Without_NA_And_Salary = Hitters_Without_NA[,-19]\n\nHitters_With_Salary_permute &lt;- cbind(Hitters_Without_NA_And_Salary, Salary_permute)\n\nmod0_permute &lt;- lm(Salary_permute~., Hitters_With_Salary_permute)\nmod1_permute &lt;- lm(Salary_permute~1, Hitters_With_Salary_permute)\n\n\nmod_permute_back &lt;- step(mod1_permute,\n                         scope = formula(mod1_permute),\n                         trace = FALSE,\n                         direction = c(\"backward\"))\nmod_permute_back %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary_permute ~ 1, data = Hitters_With_Salary_permute)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-468.4 -345.9 -110.9  214.1 1924.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   535.93      27.82   19.27   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 451.1 on 262 degrees of freedom\n\n\nShow the code\nmod_permute_forw &lt;- step(mod0_permute,\n                         scope = formula(mod1_permute),\n                         trace = FALSE,\n                         direction = c(\"forward\"))\nmod_permute_forw %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary_permute ~ AtBat + Hits + HmRun + Runs + RBI + \n    Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + \n    CWalks + League + Division + PutOuts + Assists + Errors + \n    NewLeague, data = Hitters_With_Salary_permute)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-612.8 -328.7 -111.4  213.0 1738.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  474.94433  131.32939   3.616 0.000363 ***\nAtBat          0.84928    0.91718   0.926 0.355379    \nHits          -0.92684    3.43958  -0.269 0.787803    \nHmRun          1.54219    8.97164   0.172 0.863662    \nRuns           1.87754    4.31226   0.435 0.663662    \nRBI           -6.57059    3.76269  -1.746 0.082032 .  \nWalks          1.57687    2.64530   0.596 0.551662    \nYears          6.10092   17.95672   0.340 0.734333    \nCAtBat         0.06723    0.19565   0.344 0.731429    \nCHits          0.22465    0.97588   0.230 0.818128    \nCHmRun         1.50539    2.33966   0.643 0.520556    \nCRuns         -0.69513    1.08569  -0.640 0.522602    \nCRBI          -0.39049    1.00201  -0.390 0.697094    \nCWalks        -0.25751    0.47464  -0.543 0.587940    \nLeagueN      125.82538  114.66754   1.097 0.273594    \nDivisionW    -73.12519   58.39890  -1.252 0.211713    \nPutOuts       -0.06006    0.11203  -0.536 0.592365    \nAssists        0.08862    0.32001   0.277 0.782069    \nErrors        -3.62998    6.35338  -0.571 0.568293    \nNewLeagueN  -119.98962  114.29317  -1.050 0.294834    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 456.6 on 243 degrees of freedom\nMultiple R-squared:  0.05005,   Adjusted R-squared:  -0.02423 \nF-statistic: 0.6738 on 19 and 243 DF,  p-value: 0.8433\n\n\nShow the code\nmod_permute_both &lt;- step(mod0_permute,\n                         scope = formula(mod1_permute),\n                         trace = FALSE,\n                         direction = c(\"both\"))\nmod_permute_both %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary_permute ~ AtBat + RBI, data = Hitters_With_Salary_permute)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-609.7 -332.8 -120.9  204.1 1876.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 485.0873    81.0250   5.987 7.07e-09 ***\nAtBat         0.7041     0.3098   2.273   0.0239 *  \nRBI          -4.5325     1.7631  -2.571   0.0107 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 447.1 on 260 degrees of freedom\nMultiple R-squared:  0.0253,    Adjusted R-squared:  0.0178 \nF-statistic: 3.374 on 2 and 260 DF,  p-value: 0.03575\n\n\n\n\n\n\nRésultats\n\n\nOn constate de très mauvais résultats de \\(R^2\\) et \\(R^2_{adjusted}\\) et au final la seule variable qui semble vraiment significative est l’intercept ce qui montre bien qu’avec la permutation aléatoire de la variable Salary, le lien linéaire qui existait à disparu."
  },
  {
    "objectID": "posts/Exercice_09.html",
    "href": "posts/Exercice_09.html",
    "title": "Exercice 9",
    "section": "",
    "text": "On souhaite réaliser une petite étude par simulation pour évaluer les qualités respectives de 4 méthodes d’estimation d’un modèle de régression linéaire. On s’intéresse pour chacune d’elle à ses qualités de sélection de variables et à ses qualités prédictives. Le programme SimusReg.R permet de réaliser cette étude. Il contient deux fonctions, Simudata et la fonction principale fun, et un exemple d’utilisation en fin de programme.\n\n\nShow the code\nn = 100\np = 500\nX = matrix(rnorm(n*p), n, p)\n\n\n\n\nShow the code\nlibrary(lars)\n\n\nLoaded lars 1.3\n\n\n\nAttachement du package : 'lars'\n\n\nL'objet suivant est masqué depuis 'package:psych':\n\n    error.bars\n\n\nShow the code\nlibrary(leaps)\nlibrary(glmnet)\n\n\nLe chargement a nécessité le package : Matrix\n\n\nLoaded glmnet 4.1-8\n\n\nShow the code\nDataSimulation = function(n,p){\n  if(p &lt; 4){stop(\"p&gt;3 require\")}\n  # We create our matrix of explanatory variables\n  X = matrix(rnorm(n*p), n, p)\n  \n  # We define our coefficients of regression \n  coeff = matrix(0, p)\n  coeff[1:3] = 2\n  \n  # We build our explanatory variables\n  y = X%*%coeff + rnorm(n, sd = 2)\n  return(list(X = X, y = y, coeff = coeff))\n}\n\n\n\nfun = function(n, p, M = 100){ # By default, we make M = 100 simulation \n  \n  ## Initialization \n  #################\n  selec_method1 = NULL; selec_method2 = NULL; selec_method3 = NULL;\n  taille_method1 = NULL; taille_method2 = NULL; taille_method3 = NULL;\n  prev_method1 = NULL; prev_method2 = NULL; prev_method3 = NULL; prev_method4 = NULL;\n  temps1 = NULL; temps2 = NULL; temps3 = NULL; temps4 = NULL;\n  \n  for(i in 1:M){\n    cat(paste(i, \":\")) # counter to see progress\n    \n    # We define our train set\n    datatrain = DataSimulation(n, p)\n    Xtrain = datatrain$X\n    y = datatrain$y\n    coeff = datatrain$coeff\n    \n    # We define our test set\n    datatest = DataSimulation(n, p)\n    Xtest = datatest$X\n    ytest = datatest$y\n    \n    \n    ## Regression \n    #################\n    \n    # Method 1 : Forward-Hybrid with BIC\n    tic = proc.time()\n    tab = data.frame(y = y, X = Xtrain)\n    fit0 = lm(y~1, tab)\n    fit = lm(y~., tab)\n    tmp = step(fit0, scope = formula(fit),\n               k = log(n), # BIC criteria\n               direction = \"both\", # Hybrid\n               trace = 0)\n    noms = sort(names(tmp$model))\n    selec_method1[i] = identical(\n      noms[-length(noms)], sort(paste(\"X.\", which(coeff != 0), sep = \"\"))\n      )\n    taille_method1[i] = length(noms) - 1\n    prev_method1[i] = mean((predict(tmp,data.frame(X = Xtest)) - ytest)^2)\n    tac = proc.time() - tic\n    temps1[i] = tac[3]\n    \n    # Method 2 : Lasso\n    tic = proc.time()\n    cvglm = cv.glmnet(Xtrain, y) # By default we have Lasso\n    lambda = cvglm$lambda.min\n    coef2 = coef(cvglm, s = lambda)[-1]\n    index = which(coef2 != 0) \n    selec_method2[i] = identical(sort(index), which(coeff != 0))\n    taille_method2[i] = length(index)\n    prev_method2[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n    tac = proc.time() - tic\n    temps2[i] = tac[3]\n    \n    # Methods 3 and 4 : Adaptive Lasso and  Gauss-Lasso  \n    if(length(index) == 0){\n      selec_method3[i] = selec_method2[i]\n      taille_method3[i] = taille_method2[i]\n      prev_method3[i] = prev_method2[i]\n      prev_method4[i] = prev_method2[i]}\n    else{\n      # Adaptive Lasso part\n      cvglm = cv.glmnet(Xtrain, y,\n                        penalty.factor = 1/abs(coef2))\n      lambda = cvglm$lambda.min\n      coef3 = coef(cvglm, s = lambda)[-1]\n      index = which(coef3 != 0) \n      selec_method3[i] = identical(sort(index), which(coeff != 0))\n      taille_method3[i] = length(index)\n      prev_method3[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n      tac = proc.time() - tic\n      temps3[i] = tac[3]\n      \n      # Gauss-Lasso part\n      if(length(index) == 0){\n        prev_method4[i] = mean((mean(y) - ytest)^2)}\n      else{\n        tab = data.frame(y = y, X = Xtrain)\n        reg = lm(y~., \n                 data = tab[, c(1, index + 1)])\n        prev_method4[i] = mean((predict(reg, data.frame(X = Xtest)) - ytest)^2)\n        tac = proc.time() - tic\n        temps4[i] = tac[3]\n      }\n    }\n  }\n  \n  ## Results\n  #################\n  res = list(mean(selec_method1), mean(selec_method2), mean(selec_method3), taille_method1, taille_method2, taille_method3, prev_method1, prev_method2, prev_method3, prev_method4, mean(temps1), mean(temps2), mean(temps3), mean(temps4))\n  \n  names(res) = c(\"selec_method1\", \"selec_method2\", \"selec_method3\", \"taille_method1\", \"taille_method2\", \"taille_method3\", \"prev_method1\", \"prev_method2\", \"prev_method3\", \"prev_method4\", \"temps1\", \"temps2\", \"temps3\", \"temps4\")\n  \n  return(res)\n}\n\nfun2 = function(n, p, M = 100){ # By default, we make M = 100 simulation \n  \n  ## Initialization \n  #################\n  selec_method1 = NULL; selec_method2 = NULL; selec_method3 = NULL;\n  taille_method1 = NULL; taille_method2 = NULL; taille_method3 = NULL;\n  prev_method1 = NULL; prev_method2 = NULL; prev_method3 = NULL; prev_method4 = NULL;\n  temps1 = NULL; temps2 = NULL; temps3 = NULL; temps4 = NULL;\n  \n  for(i in 1:M){\n    cat(paste(i, \":\")) # counter to see progress\n    \n    # We define our train set\n    datatrain = DataSimulation(n, p)\n    Xtrain = datatrain$X\n    y = datatrain$y\n    coeff = datatrain$coeff\n    \n    # We define our test set\n    datatest = DataSimulation(n, p)\n    Xtest = datatest$X\n    ytest = datatest$y\n    \n    \n    ## Regression \n    #################\n    \n    # Method 2 : Lasso\n    tic = proc.time()\n    cvglm = cv.glmnet(Xtrain, y) # By default we have Lasso\n    lambda = cvglm$lambda.min\n    coef2 = coef(cvglm, s = lambda)[-1]\n    index = which(coef2 != 0) \n    selec_method2[i] = identical(sort(index), which(coeff != 0))\n    taille_method2[i] = length(index)\n    prev_method2[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n    tac = proc.time() - tic\n    temps2[i] = tac[3]\n    \n    # Methods 3 and 4 : Adaptive Lasso and  Gauss-Lasso  \n    if(length(index) == 0){\n      selec_method3[i] = selec_method2[i]\n      taille_method3[i] = taille_method2[i]\n      prev_method3[i] = prev_method2[i]\n      prev_method4[i] = prev_method2[i]}\n    else{\n      # Adaptive Lasso part\n      cvglm = cv.glmnet(Xtrain, y,\n                        penalty.factor = 1/abs(coef2))\n      lambda = cvglm$lambda.min\n      coef3 = coef(cvglm, s = lambda)[-1]\n      index = which(coef3 != 0) \n      selec_method3[i] = identical(sort(index), which(coeff != 0))\n      taille_method3[i] = length(index)\n      prev_method3[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n      tac = proc.time() - tic\n      temps3[i] = tac[3]\n      \n      # Gauss-Lasso part\n      if(length(index) == 0){\n        prev_method4[i] = mean((mean(y) - ytest)^2)}\n      else{\n        tab = data.frame(y = y, X = Xtrain)\n        reg = lm(y~., \n                 data = tab[, c(1, index + 1)])\n        prev_method4[i] = mean((predict(reg, data.frame(X = Xtest)) - ytest)^2)\n        tac = proc.time() - tic\n        temps4[i] = tac[3]\n      }\n    }\n  }\n  \n  ## Results\n  #################\n  res = list(mean(selec_method1), mean(selec_method2), mean(selec_method3), taille_method1, taille_method2, taille_method3, prev_method1, prev_method2, prev_method3, prev_method4, mean(temps1), mean(temps2), mean(temps3), mean(temps4))\n  \n  names(res) = c(\"selec_method1\", \"selec_method2\", \"selec_method3\", \"taille_method1\", \"taille_method2\", \"taille_method3\", \"prev_method1\", \"prev_method2\", \"prev_method3\", \"prev_method4\", \"temps1\", \"temps2\", \"temps3\", \"temps4\")\n  \n  return(res)\n}\n\n\n\n\nShow the code\n###### Exemple\na=fun(50,5,100)\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\n\n\nShow the code\na$selec_method1\n\n\n[1] 0.9\n\n\nShow the code\na$selec_method2\n\n\n[1] 0.16\n\n\nShow the code\na$selec_method3\n\n\n[1] 0.7\n\n\nShow the code\na$taille_method1\n\n\n  [1] 3 3 4 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3\n [38] 3 3 4 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 4 3 3 3 3 3\n [75] 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 4 3 3\n\n\nShow the code\na$taille_method2\n\n\n  [1] 5 5 5 4 4 5 3 5 3 5 5 5 5 4 4 4 3 4 4 4 5 4 3 4 5 5 4 4 3 5 5 4 4 4 5 4 4\n [38] 5 4 5 5 5 5 4 5 5 4 4 5 3 5 4 5 5 5 3 3 4 5 4 4 5 4 3 5 4 5 3 5 4 4 4 5 5\n [75] 5 3 4 5 3 4 5 5 5 5 5 5 5 5 3 3 5 5 3 4 5 5 4 4 3 5\n\n\nShow the code\na$taille_method3\n\n\n  [1] 3 3 5 3 3 5 3 3 3 3 3 3 5 3 3 3 3 3 4 3 3 3 3 3 5 3 3 3 3 4 5 4 3 3 4 3 3\n [38] 4 3 4 3 3 3 3 5 5 3 3 3 3 3 4 3 4 3 3 3 3 5 3 4 4 3 3 4 3 3 3 4 4 3 3 3 4\n [75] 4 3 3 4 3 3 3 5 3 4 3 3 4 3 3 3 5 4 3 3 3 3 3 4 3 3\n\n\nShow the code\nboxplot(sqrt(a$prev_method1),sqrt(a$prev_method2),sqrt(a$prev_method3),sqrt(a$prev_method4),names=c(\"Method1\",\"Method2\",\"Method3\",\"Method4\"),main=\"Title\")\n\n\n\n\n\n\n\n\n\nShow the code\nmean(a$prev_method1)\n\n\n[1] 4.317454\n\n\nShow the code\nmean(a$prev_method2)\n\n\n[1] 4.482734\n\n\nShow the code\nmean(a$prev_method3)\n\n\n[1] 4.405399\n\n\nShow the code\nmean(a$prev_method4)\n\n\n[1] 4.397463\n\n\nShow the code\na$temps1\n\n\n[1] 0.01149\n\n\nShow the code\na$temps2\n\n\n[1] 0.02251\n\n\nShow the code\na$temps3\n\n\n[1] 0.04536\n\n\nShow the code\na$temps4\n\n\n[1] 0.04648\n\n\n\nQuestion 1\nQuel modèle génère la fonction Simudata ? Combien de variables explicatives sont générées ? Parmi elles, lesquelles sont pertinentes pour la modélisation ? Ecrire l’équation du modèle.\n\n\nQuestion 2\nIdentifier les 4 méthodes d’estimation mises en oeuvre dans la fonction fun.\n\n\nQuestion 3\nDétailler les différentes sorties proposées par la fonction fun.\n\n\nQuestion 4\nRemplacer la valeur des options names et title du boxplot réalisé dans l’exemple par les bonnes informations.\n\n\nShow the code\nboxplot(sqrt(a$prev_method1),sqrt(a$prev_method2),sqrt(a$prev_method3),sqrt(a$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", 100,\"et p=\", 10),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"),\n        ylim = c(1,3))\n\n\n\n\n\n\n\n\n\n\n\nQuestion 5\nRéaliser une étude comparative des méthodes lorsque \\(n = 50\\) et \\(p = n/10\\), \\(p = n\\), \\(p = 2n\\), \\(p = 10n\\). Pour chaque situation, on considèrera \\(100\\) simulations afin de calculer les différents critères. On synthétisera les résultats en terme de qualité de sélection, nombre de variables sélectionnées, erreurs de prévision et temps de calcul.\n\n\nShow the code\n#parallelisation\nfuture::plan(multisession, workers = 2)\n\nn = 50\np_list = c(n/10, n, 2*n, 10*n)\n\nr_cas1 = fun(n, p_list[1])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nShow the code\nr_cas2 = fun(n, p_list[2])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nShow the code\nr_cas3 = fun(n, p_list[3])\n\n\n1 :2 :\n\n\n3 :\n\n\n4 :\n\n\n5 :\n\n\n6 :\n\n\n7 :\n\n\n8 :\n\n\n9 :\n\n\n10 :\n\n\n11 :\n\n\n12 :\n\n\n13 :14 :15 :\n\n\n16 :17 :\n\n\n18 :\n\n\n19 :\n\n\n20 :21 :\n\n\n22 :23 :\n\n\n24 :25 :\n\n\n26 :\n\n\n27 :28 :\n\n\n29 :\n\n\n30 :\n\n\n31 :\n\n\n32 :\n\n\n33 :\n\n\n34 :\n\n\n35 :\n\n\n36 :\n\n\n37 :\n\n\n38 :\n\n\n39 :\n\n\n40 :\n\n\n41 :\n\n\n42 :\n\n\n43 :\n\n\n44 :\n\n\n45 :\n\n\n46 :47 :\n\n\n48 :\n\n\n49 :50 :\n\n\n51 :\n\n\n52 :\n\n\n53 :54 :\n\n\n55 :\n\n\n56 :57 :\n\n\n58 :\n\n\n59 :\n\n\n60 :\n\n\n61 :\n\n\n62 :63 :\n\n\n64 :\n\n\n65 :\n\n\n66 :\n\n\n67 :\n\n\n68 :69 :\n\n\n70 :\n\n\n71 :\n\n\n72 :\n\n\n73 :74 :\n\n\n75 :76 :\n\n\n77 :78 :79 :80 :\n\n\n81 :\n\n\n82 :\n\n\n83 :\n\n\n84 :\n\n\n85 :\n\n\n86 :\n\n\n87 :\n\n\n88 :\n\n\n89 :\n\n\n90 :\n\n\n91 :\n\n\n92 :93 :\n\n\n94 :\n\n\n95 :\n\n\n96 :97 :\n\n\n98 :99 :\n\n\n100 :\n\n\nShow the code\nr_cas4 = fun(n, p_list[4],1)\n\n\n1 :\n\n\nShow the code\nr_cas4bis = fun2(n, p_list[4])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nShow the code\n# file_path &lt;- file.path(\"../Data/r_cas1.rds\")\n# saveRDS(r_cas1, file = file_path)\n\n# quit parallelisation\nfuture::plan(\"sequential\")\n\n\n\n\nShow the code\n# file_path &lt;- file.path(\"../Data/r_cas1.rds\")\n# r_cas1 &lt;- readRDS(file_path)\n\n\n\n\nShow the code\nres_cas1 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas1$selec_method1,r_cas1$selec_method2,r_cas1$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas1$taille_method1),mean(r_cas1$taille_method2),mean(r_cas1$taille_method3),NA),\n  Prevision_error = c(mean(r_cas1$prev_method1),mean(r_cas1$prev_method2),mean(r_cas1$prev_method3),mean(r_cas1$prev_method4)),\n  Running_time = c(r_cas1$temps1,r_cas1$temps2,r_cas1$temps3,r_cas1$temps4)\n)\nt(res_cas1)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.95\"     \"0.24\"     \"0.76\"             NA           \nMean_nb_selected_var \"3.05\"     \"4.19\"     \"3.29\"             NA           \nPrevision_error      \"4.267999\" \"4.372448\" \"4.311278\"         \"4.298561\"   \nRunning_time         \"0.01006\"  \"0.02122\"  \"0.04285\"          \"0.04382\"    \n\n\nShow the code\nboxplot(sqrt(r_cas1$prev_method1),sqrt(r_cas1$prev_method2),sqrt(r_cas1$prev_method3),sqrt(r_cas1$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[1]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres_cas2 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas2$selec_method1,r_cas2$selec_method2,r_cas2$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas2$taille_method1),mean(r_cas2$taille_method2),mean(r_cas2$taille_method3),NA),\n  Prevision_error = c(mean(r_cas2$prev_method1),mean(r_cas2$prev_method2),mean(r_cas2$prev_method3),mean(r_cas2$prev_method4)),\n  Running_time = c(r_cas2$temps1,r_cas2$temps2,r_cas2$temps3,r_cas2$temps4)\n)\nt(res_cas2)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.06\"     \"0.01\"     \"0.09\"             NA           \nMean_nb_selected_var \" 7.92\"    \"12.88\"    \" 8.17\"            NA           \nPrevision_error      \"7.050225\" \"5.609938\" \"5.487207\"         \"6.401796\"   \nRunning_time         \"0.07149\"  \"0.04010\"  \"0.06590\"          \"0.06738\"    \n\n\nShow the code\nboxplot(sqrt(r_cas2$prev_method1),sqrt(r_cas2$prev_method2),sqrt(r_cas2$prev_method3),sqrt(r_cas2$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[2]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres_cas3 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas3$selec_method1,r_cas3$selec_method2,r_cas3$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas3$taille_method1),mean(r_cas3$taille_method2),mean(r_cas3$taille_method3),NA),\n  Prevision_error = c(mean(r_cas3$prev_method1),mean(r_cas3$prev_method2),mean(r_cas3$prev_method3),mean(r_cas3$prev_method4)),\n  Running_time = c(r_cas3$temps1,r_cas3$temps2,r_cas3$temps3,r_cas3$temps4)\n)\nt(res_cas3)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.00\"      \"0.00\"      \"0.06\"             NA           \nMean_nb_selected_var \"40.57\"     \"15.80\"     \" 9.09\"            NA           \nPrevision_error      \"16.207790\" \" 6.138163\" \" 5.738140\"        \" 6.723044\"  \nRunning_time         \"0.71804\"   \"0.04013\"   \"0.06882\"          \"0.07045\"    \n\n\nShow the code\nboxplot(sqrt(r_cas3$prev_method1),sqrt(r_cas3$prev_method2),sqrt(r_cas3$prev_method3),sqrt(r_cas3$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres_cas4 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4$selec_method1,r_cas4$selec_method2,r_cas4$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4$taille_method1),mean(r_cas4$taille_method2),mean(r_cas4$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4$prev_method1),mean(r_cas4$prev_method2),mean(r_cas4$prev_method3),mean(r_cas4$prev_method4)),\n  Running_time = c(r_cas4$temps1,r_cas4$temps2,r_cas4$temps3,r_cas4$temps4)\n)\nt(res_cas4)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \" 0\"        \" 0\"        \" 0\"               NA           \nMean_nb_selected_var \"49\"        \"41\"        \"19\"               NA           \nPrevision_error      \"11.762266\" \" 4.734249\" \" 4.562205\"        \" 5.403622\"  \nRunning_time         \"6.500\"     \"0.041\"     \"0.077\"            \"0.080\"      \n\n\nShow the code\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4$prev_method2),sqrt(r_cas4$prev_method3),sqrt(r_cas4$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres_cas4bis = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4bis$selec_method1,r_cas4bis$selec_method2,r_cas4bis$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4bis$taille_method1),mean(r_cas4bis$taille_method2),mean(r_cas4bis$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4bis$prev_method1),mean(r_cas4bis$prev_method2),mean(r_cas4bis$prev_method3),mean(r_cas4bis$prev_method4)),\n  Running_time = c(r_cas4bis$temps1,r_cas4bis$temps2,r_cas4bis$temps3,r_cas4bis$temps4)\n)\n\n\nWarning in mean.default(r_cas4bis$taille_method1): l'argument n'est ni\nnumérique, ni logique : renvoi de NA\n\n\nWarning in mean.default(r_cas4bis$prev_method1): l'argument n'est ni numérique,\nni logique : renvoi de NA\n\n\nShow the code\nt(res_cas4bis)\n\n\n                     [,1]      [,2]       [,3]               [,4]         \nMethod               \"Forward\" \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection NA        \"0.00\"     \"0.04\"             NA           \nMean_nb_selected_var NA        \"24.87\"    \"12.34\"            NA           \nPrevision_error      NA        \"7.230664\" \"6.781834\"         \"7.861071\"   \nRunning_time         NA        \"0.04820\"  \"0.08404\"          \"0.08697\"    \n\n\nShow the code\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4bis$prev_method2),sqrt(r_cas4bis$prev_method3),sqrt(r_cas4bis$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[4]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nQuestion 6\nRéaliser la même étude pour \\(n = 100\\) et \\(p = n/10\\), \\(p = n\\), \\(p = 2n\\), toujours basée sur \\(100\\) simulations dans chaque cas. Considérer de plus le cas \\(p = 10n\\) en ne faisant qu’une seule simulation afin d’en évaluer le temps de calcul. Une fois ce temps analysé, lancer \\(100\\) simulations pour \\(p = 10n\\) mais en omettant la méthode la plus couteuse en temps de calcul.\n\n\nShow the code\n#parallelisation\nfuture::plan(multisession, workers = 2)\n\nn = 100\np_list = c(n/10, n, 2*n, 10*n)\n\nr_cas1 = fun(n, p_list[1])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nShow the code\nr_cas2 = fun(n, p_list[2])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nShow the code\nr_cas3 = fun(n, p_list[3])\n\n\n1 :\n\n\n2 :3 :4 :5 :6 :\n\n\n7 :8 :9 :\n\n\n10 :11 :\n\n\n12 :\n\n\n13 :14 :15 :16 :17 :18 :\n\n\n19 :20 :\n\n\n21 :\n\n\n22 :23 :24 :25 :\n\n\n26 :27 :\n\n\n28 :29 :30 :\n\n\n31 :\n\n\n32 :33 :34 :\n\n\n35 :\n\n\n36 :37 :38 :39 :\n\n\n40 :41 :42 :43 :\n\n\n44 :\n\n\n45 :46 :47 :\n\n\n48 :\n\n\n49 :\n\n\n50 :51 :52 :\n\n\n53 :54 :55 :56 :\n\n\n57 :58 :\n\n\n59 :\n\n\n60 :61 :\n\n\n62 :63 :\n\n\n64 :\n\n\n65 :66 :\n\n\n67 :68 :\n\n\n69 :\n\n\n70 :71 :72 :73 :74 :\n\n\n75 :\n\n\n76 :77 :78 :\n\n\n79 :80 :81 :82 :83 :\n\n\n84 :85 :86 :87 :88 :89 :90 :\n\n\n91 :\n\n\n92 :93 :\n\n\n94 :\n\n\n95 :96 :97 :98 :\n\n\n99 :100 :\n\n\nShow the code\nr_cas4 = fun(n, p_list[4],1)\n\n\n1 :\n\n\nShow the code\nr_cas4bis = fun2(n, p_list[4])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nShow the code\n# quit parallelisation\nfuture::plan(\"sequential\")\n\n\n\n\nShow the code\nres_cas1 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas1$selec_method1,r_cas1$selec_method2,r_cas1$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas1$taille_method1),mean(r_cas1$taille_method2),mean(r_cas1$taille_method3),NA),\n  Prevision_error = c(mean(r_cas1$prev_method1),mean(r_cas1$prev_method2),mean(r_cas1$prev_method3),mean(r_cas1$prev_method4)),\n  Running_time = c(r_cas1$temps1,r_cas1$temps2,r_cas1$temps3,r_cas1$temps4)\n)\nt(res_cas1)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.71\"     \"0.08\"     \"0.42\"             NA           \nMean_nb_selected_var \"3.30\"     \"6.35\"     \"4.15\"             NA           \nPrevision_error      \"4.270127\" \"4.367182\" \"4.300236\"         \"4.347811\"   \nRunning_time         \"0.01367\"  \"0.02255\"  \"0.04586\"          \"0.04690\"    \n\n\nShow the code\nboxplot(sqrt(r_cas1$prev_method1),sqrt(r_cas1$prev_method2),sqrt(r_cas1$prev_method3),sqrt(r_cas1$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[1]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres_cas2 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas2$selec_method1,r_cas2$selec_method2,r_cas2$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas2$taille_method1),mean(r_cas2$taille_method2),mean(r_cas2$taille_method3),NA),\n  Prevision_error = c(mean(r_cas2$prev_method1),mean(r_cas2$prev_method2),mean(r_cas2$prev_method3),mean(r_cas2$prev_method4)),\n  Running_time = c(r_cas2$temps1,r_cas2$temps2,r_cas2$temps3,r_cas2$temps4)\n)\nt(res_cas2)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.01\"     \"0.01\"     \"0.10\"             NA           \nMean_nb_selected_var \" 8.11\"    \"14.59\"    \" 7.61\"            NA           \nPrevision_error      \"5.682778\" \"4.824673\" \"4.588443\"         \"5.223387\"   \nRunning_time         \"0.13837\"  \"0.06476\"  \"0.09358\"          \"0.09517\"    \n\n\nShow the code\nboxplot(sqrt(r_cas2$prev_method1),sqrt(r_cas2$prev_method2),sqrt(r_cas2$prev_method3),sqrt(r_cas2$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[2]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres_cas3 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas3$selec_method1,r_cas3$selec_method2,r_cas3$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas3$taille_method1),mean(r_cas3$taille_method2),mean(r_cas3$taille_method3),NA),\n  Prevision_error = c(mean(r_cas3$prev_method1),mean(r_cas3$prev_method2),mean(r_cas3$prev_method3),mean(r_cas3$prev_method4)),\n  Running_time = c(r_cas3$temps1,r_cas3$temps2,r_cas3$temps3,r_cas3$temps4)\n)\nt(res_cas3)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.00\"      \"0.01\"      \"0.16\"             NA           \nMean_nb_selected_var \"48.66\"     \"17.34\"     \" 7.73\"            NA           \nPrevision_error      \"11.428807\" \" 5.016189\" \" 4.523595\"        \" 5.243494\"  \nRunning_time         \"2.67996\"   \"0.06936\"   \"0.10052\"          \"0.10242\"    \n\n\nShow the code\nboxplot(sqrt(r_cas3$prev_method1),sqrt(r_cas3$prev_method2),sqrt(r_cas3$prev_method3),sqrt(r_cas3$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres_cas4 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4$selec_method1,r_cas4$selec_method2,r_cas4$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4$taille_method1),mean(r_cas4$taille_method2),mean(r_cas4$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4$prev_method1),mean(r_cas4$prev_method2),mean(r_cas4$prev_method3),mean(r_cas4$prev_method4)),\n  Running_time = c(r_cas4$temps1,r_cas4$temps2,r_cas4$temps3,r_cas4$temps4)\n)\nt(res_cas4)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \" 0\"        \" 0\"        \" 0\"               NA           \nMean_nb_selected_var \"99\"        \"11\"        \" 6\"               NA           \nPrevision_error      \"11.946047\" \" 5.699005\" \" 4.413508\"        \" 5.439750\"  \nRunning_time         \"61.347\"    \" 0.088\"    \" 0.129\"           \" 0.133\"     \n\n\nShow the code\nres_cas4bis = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4bis$selec_method1,r_cas4bis$selec_method2,r_cas4bis$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4bis$taille_method1),mean(r_cas4bis$taille_method2),mean(r_cas4bis$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4bis$prev_method1),mean(r_cas4bis$prev_method2),mean(r_cas4bis$prev_method3),mean(r_cas4bis$prev_method4)),\n  Running_time = c(r_cas4bis$temps1,r_cas4bis$temps2,r_cas4bis$temps3,r_cas4bis$temps4)\n)\n\n\nWarning in mean.default(r_cas4bis$taille_method1): l'argument n'est ni\nnumérique, ni logique : renvoi de NA\n\n\nWarning in mean.default(r_cas4bis$prev_method1): l'argument n'est ni numérique,\nni logique : renvoi de NA\n\n\nShow the code\nt(res_cas4bis)\n\n\n                     [,1]      [,2]       [,3]               [,4]         \nMethod               \"Forward\" \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection NA        \"0.00\"     \"0.03\"             NA           \nMean_nb_selected_var NA        \"30.92\"    \"11.07\"            NA           \nPrevision_error      NA        \"5.260876\" \"4.776523\"         \"5.836417\"   \nRunning_time         NA        \"0.08522\"  \"0.13196\"          \"0.13632\"    \n\n\nShow the code\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4$prev_method2),sqrt(r_cas4$prev_method3),sqrt(r_cas4$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\nShow the code\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4bis$prev_method2),sqrt(r_cas4bis$prev_method3),sqrt(r_cas4bis$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[4]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nQuestion 7\nConclure sur les mérites respectifs de chaque méthode dans le contexte de l’étude.\n\n\nQuestion 8\nQuelles autres types de simulations pourrait-on envisager pour confirmer ou affiner ces conclusions ?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistique en grande dimension",
    "section": "",
    "text": "Exercice 1\n\n\n\n\n\n\nTP\n\n\n\nIl s’agit d’une première utilisation des méthodes de regression avec selection de variable via des approches stepwise sur des données de baseball\n\n\n\n\n\nInvalid Date\n\n\nClément Poupelin\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 2\n\n\n\n\n\n\nTP\n\n\n\nIci, on commence à utilser des méthodes de regression avec selection de variable et tester le lien linéaire existant sur des données de baseball\n\n\n\n\n\nInvalid Date\n\n\nClément Poupelin\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 3\n\n\n\n\n\n\nTP\n\n\n\nPremière essais de techniques de validations croisées sur des données générées manuellement\n\n\n\n\n\nInvalid Date\n\n\nClément Poupelin\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 9\n\n\n\n\n\n\nTP\n\n\n\nComparaison de différents modèles de regression\n\n\n\n\n\nInvalid Date\n\n\nClément Poupelin\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 6 Bonus : Ridge vs Lasso\n\n\n\n\n\n\nBonus\n\n\n\nComparaison de la regression Ridge et Lasso via le github de Laurent Rouvière\n\n\n\n\n\nInvalid Date\n\n\nClément Poupelin\n\n\n\n\n\n\nNo matching items"
  }
]