[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/Exercice_9.html",
    "href": "posts/Exercice_9.html",
    "title": "Exercice 9",
    "section": "",
    "text": "On souhaite réaliser une petite étude par simulation pour évaluer les qualités respectives de 4 méthodes d’estimation d’un modèle de régression linéaire. On s’intéresse pour chacune d’elle à ses qualités de sélection de variables et à ses qualités prédictives. Le programme SimusReg.R permet de réaliser cette étude. Il contient deux fonctions, Simudata et la fonction principale fun, et un exemple d’utilisation en fin de programme.\n\n\nCode\nn = 100\np = 500\nX = matrix(rnorm(n*p), n, p)\n\n\n\n\nCode\nlibrary(lars)\n\n\nLoaded lars 1.3\n\n\n\nAttachement du package : 'lars'\n\n\nL'objet suivant est masqué depuis 'package:psych':\n\n    error.bars\n\n\nCode\nlibrary(leaps)\nlibrary(glmnet)\n\n\nWarning: le package 'glmnet' a été compilé avec la version R 4.2.3\n\n\nLe chargement a nécessité le package : Matrix\n\n\nWarning: le package 'Matrix' a été compilé avec la version R 4.2.3\n\n\nLoaded glmnet 4.1-8\n\n\nCode\nDataSimulation = function(n,p){\n  if(p &lt; 4){stop(\"p&gt;3 require\")}\n  # We create our matrix of explanatory variables\n  X = matrix(rnorm(n*p), n, p)\n  \n  # We define our coefficients of regression \n  coeff = matrix(0, p)\n  coeff[1:3] = 2\n  \n  # We build our explanatory variables\n  y = X%*%coeff + rnorm(n, sd = 2)\n  return(list(X = X, y = y, coeff = coeff))\n}\n\n\n\nfun = function(n, p, M = 100){ # By default, we make M = 100 simulation \n  \n  ## Initialization \n  #################\n  selec_method1 = NULL; selec_method2 = NULL; selec_method3 = NULL;\n  taille_method1 = NULL; taille_method2 = NULL; taille_method3 = NULL;\n  prev_method1 = NULL; prev_method2 = NULL; prev_method3 = NULL; prev_method4 = NULL;\n  temps1 = NULL; temps2 = NULL; temps3 = NULL; temps4 = NULL;\n  \n  for(i in 1:M){\n    cat(paste(i, \":\")) # counter to see progress\n    \n    # We define our train set\n    datatrain = DataSimulation(n, p)\n    Xtrain = datatrain$X\n    y = datatrain$y\n    coeff = datatrain$coeff\n    \n    # We define our test set\n    datatest = DataSimulation(n, p)\n    Xtest = datatest$X\n    ytest = datatest$y\n    \n    \n    ## Regression \n    #################\n    \n    # Method 1 : Forward-Hybrid with BIC\n    tic = proc.time()\n    tab = data.frame(y = y, X = Xtrain)\n    fit0 = lm(y~1, tab)\n    fit = lm(y~., tab)\n    tmp = step(fit0, scope = formula(fit),\n               k = log(n), # BIC criteria\n               direction = \"both\", # Hybrid\n               trace = 0)\n    noms = sort(names(tmp$model))\n    selec_method1[i] = identical(\n      noms[-length(noms)], sort(paste(\"X.\", which(coeff != 0), sep = \"\"))\n      )\n    taille_method1[i] = length(noms) - 1\n    prev_method1[i] = mean((predict(tmp,data.frame(X = Xtest)) - ytest)^2)\n    tac = proc.time() - tic\n    temps1[i] = tac[3]\n    \n    # Method 2 : Lasso\n    tic = proc.time()\n    cvglm = cv.glmnet(Xtrain, y) # By default we have Lasso\n    lambda = cvglm$lambda.min\n    coef2 = coef(cvglm, s = lambda)[-1]\n    index = which(coef2 != 0) \n    selec_method2[i] = identical(sort(index), which(coeff != 0))\n    taille_method2[i] = length(index)\n    prev_method2[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n    tac = proc.time() - tic\n    temps2[i] = tac[3]\n    \n    # Methods 3 and 4 : Adaptive Lasso and  Gauss-Lasso  \n    if(length(index) == 0){\n      selec_method3[i] = selec_method2[i]\n      taille_method3[i] = taille_method2[i]\n      prev_method3[i] = prev_method2[i]\n      prev_method4[i] = prev_method2[i]}\n    else{\n      # Adaptive Lasso part\n      cvglm = cv.glmnet(Xtrain, y,\n                        penalty.factor = 1/abs(coef2))\n      lambda = cvglm$lambda.min\n      coef3 = coef(cvglm, s = lambda)[-1]\n      index = which(coef3 != 0) \n      selec_method3[i] = identical(sort(index), which(coeff != 0))\n      taille_method3[i] = length(index)\n      prev_method3[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n      tac = proc.time() - tic\n      temps3[i] = tac[3]\n      \n      # Gauss-Lasso part\n      if(length(index) == 0){\n        prev_method4[i] = mean((mean(y) - ytest)^2)}\n      else{\n        tab = data.frame(y = y, X = Xtrain)\n        reg = lm(y~., \n                 data = tab[, c(1, index + 1)])\n        prev_method4[i] = mean((predict(reg, data.frame(X = Xtest)) - ytest)^2)\n        tac = proc.time() - tic\n        temps4[i] = tac[3]\n      }\n    }\n  }\n  \n  ## Results\n  #################\n  res = list(mean(selec_method1), mean(selec_method2), mean(selec_method3), taille_method1, taille_method2, taille_method3, prev_method1, prev_method2, prev_method3, prev_method4, mean(temps1), mean(temps2), mean(temps3), mean(temps4))\n  \n  names(res) = c(\"selec_method1\", \"selec_method2\", \"selec_method3\", \"taille_method1\", \"taille_method2\", \"taille_method3\", \"prev_method1\", \"prev_method2\", \"prev_method3\", \"prev_method4\", \"temps1\", \"temps2\", \"temps3\", \"temps4\")\n  \n  return(res)\n}\n\nfun2 = function(n, p, M = 100){ # By default, we make M = 100 simulation \n  \n  ## Initialization \n  #################\n  selec_method1 = NULL; selec_method2 = NULL; selec_method3 = NULL;\n  taille_method1 = NULL; taille_method2 = NULL; taille_method3 = NULL;\n  prev_method1 = NULL; prev_method2 = NULL; prev_method3 = NULL; prev_method4 = NULL;\n  temps1 = NULL; temps2 = NULL; temps3 = NULL; temps4 = NULL;\n  \n  for(i in 1:M){\n    cat(paste(i, \":\")) # counter to see progress\n    \n    # We define our train set\n    datatrain = DataSimulation(n, p)\n    Xtrain = datatrain$X\n    y = datatrain$y\n    coeff = datatrain$coeff\n    \n    # We define our test set\n    datatest = DataSimulation(n, p)\n    Xtest = datatest$X\n    ytest = datatest$y\n    \n    \n    ## Regression \n    #################\n    \n    # Method 2 : Lasso\n    tic = proc.time()\n    cvglm = cv.glmnet(Xtrain, y) # By default we have Lasso\n    lambda = cvglm$lambda.min\n    coef2 = coef(cvglm, s = lambda)[-1]\n    index = which(coef2 != 0) \n    selec_method2[i] = identical(sort(index), which(coeff != 0))\n    taille_method2[i] = length(index)\n    prev_method2[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n    tac = proc.time() - tic\n    temps2[i] = tac[3]\n    \n    # Methods 3 and 4 : Adaptive Lasso and  Gauss-Lasso  \n    if(length(index) == 0){\n      selec_method3[i] = selec_method2[i]\n      taille_method3[i] = taille_method2[i]\n      prev_method3[i] = prev_method2[i]\n      prev_method4[i] = prev_method2[i]}\n    else{\n      # Adaptive Lasso part\n      cvglm = cv.glmnet(Xtrain, y,\n                        penalty.factor = 1/abs(coef2))\n      lambda = cvglm$lambda.min\n      coef3 = coef(cvglm, s = lambda)[-1]\n      index = which(coef3 != 0) \n      selec_method3[i] = identical(sort(index), which(coeff != 0))\n      taille_method3[i] = length(index)\n      prev_method3[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n      tac = proc.time() - tic\n      temps3[i] = tac[3]\n      \n      # Gauss-Lasso part\n      if(length(index) == 0){\n        prev_method4[i] = mean((mean(y) - ytest)^2)}\n      else{\n        tab = data.frame(y = y, X = Xtrain)\n        reg = lm(y~., \n                 data = tab[, c(1, index + 1)])\n        prev_method4[i] = mean((predict(reg, data.frame(X = Xtest)) - ytest)^2)\n        tac = proc.time() - tic\n        temps4[i] = tac[3]\n      }\n    }\n  }\n  \n  ## Results\n  #################\n  res = list(mean(selec_method1), mean(selec_method2), mean(selec_method3), taille_method1, taille_method2, taille_method3, prev_method1, prev_method2, prev_method3, prev_method4, mean(temps1), mean(temps2), mean(temps3), mean(temps4))\n  \n  names(res) = c(\"selec_method1\", \"selec_method2\", \"selec_method3\", \"taille_method1\", \"taille_method2\", \"taille_method3\", \"prev_method1\", \"prev_method2\", \"prev_method3\", \"prev_method4\", \"temps1\", \"temps2\", \"temps3\", \"temps4\")\n  \n  return(res)\n}\n\n\n\n\nCode\n###### Exemple\na=fun(50,5,100)\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\n\n\nCode\na$selec_method1\n\n\n[1] 0.9\n\n\nCode\na$selec_method2\n\n\n[1] 0.16\n\n\nCode\na$selec_method3\n\n\n[1] 0.7\n\n\nCode\na$taille_method1\n\n\n  [1] 3 3 4 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3\n [38] 3 3 4 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 4 3 3 3 3 3\n [75] 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 4 3 3\n\n\nCode\na$taille_method2\n\n\n  [1] 5 5 5 4 4 5 3 5 3 5 5 5 5 4 4 4 3 4 4 4 5 4 3 4 5 5 4 4 3 5 5 4 4 4 5 4 4\n [38] 5 4 5 5 5 5 4 5 5 4 4 5 3 5 4 5 5 5 3 3 4 5 4 4 5 4 3 5 4 5 3 5 4 4 4 5 5\n [75] 5 3 4 5 3 4 5 5 5 5 5 5 5 5 3 3 5 5 3 4 5 5 4 4 3 5\n\n\nCode\na$taille_method3\n\n\n  [1] 3 3 5 3 3 5 3 3 3 3 3 3 5 3 3 3 3 3 4 3 3 3 3 3 5 3 3 3 3 4 5 4 3 3 4 3 3\n [38] 4 3 4 3 3 3 3 5 5 3 3 3 3 3 4 3 4 3 3 3 3 5 3 4 4 3 3 4 3 3 3 4 4 3 3 3 4\n [75] 4 3 3 4 3 3 3 5 3 4 3 3 4 3 3 3 5 4 3 3 3 3 3 4 3 3\n\n\nCode\nboxplot(sqrt(a$prev_method1),sqrt(a$prev_method2),sqrt(a$prev_method3),sqrt(a$prev_method4),names=c(\"Method1\",\"Method2\",\"Method3\",\"Method4\"),main=\"Title\")\n\n\n\n\n\nCode\nmean(a$prev_method1)\n\n\n[1] 4.317454\n\n\nCode\nmean(a$prev_method2)\n\n\n[1] 4.482734\n\n\nCode\nmean(a$prev_method3)\n\n\n[1] 4.405399\n\n\nCode\nmean(a$prev_method4)\n\n\n[1] 4.397463\n\n\nCode\na$temps1\n\n\n[1] 0.0363\n\n\nCode\na$temps2\n\n\n[1] 0.0887\n\n\nCode\na$temps3\n\n\n[1] 0.1785\n\n\nCode\na$temps4\n\n\n[1] 0.1824\n\n\n\nQuestion 1\nQuel modèle génère la fonction Simudata ? Combien de variables explicatives sont générées ? Parmi elles, lesquelles sont pertinentes pour la modélisation ? Ecrire l’équation du modèle.\n\n\nQuestion 2\nIdentifier les 4 méthodes d’estimation mises en oeuvre dans la fonction fun.\n\n\nQuestion 3\nDétailler les différentes sorties proposées par la fonction fun.\n\n\nQuestion 4\nRemplacer la valeur des options names et title du boxplot réalisé dans l’exemple par les bonnes informations.\n\n\nCode\nboxplot(sqrt(a$prev_method1),sqrt(a$prev_method2),sqrt(a$prev_method3),sqrt(a$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", 100,\"et p=\", 10),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"),\n        ylim = c(1,3))\n\n\n\n\n\n\n\nQuestion 5\nRéaliser une étude comparative des méthodes lorsque \\(n = 50\\) et \\(p = n/10\\), \\(p = n\\), \\(p = 2n\\), \\(p = 10n\\). Pour chaque situation, on considèrera \\(100\\) simulations afin de calculer les différents critères. On synthétisera les résultats en terme de qualité de sélection, nombre de variables sélectionnées, erreurs de prévision et temps de calcul.\n\n\nCode\n#parallelisation\nfuture::plan(multisession, workers = 2)\n\nn = 50\np_list = c(n/10, n, 2*n, 10*n)\n\nr_cas1 = fun(n, p_list[1])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\nr_cas2 = fun(n, p_list[2])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\nr_cas3 = fun(n, p_list[3])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\nr_cas4 = fun(n, p_list[4],1)\n\n\n1 :\n\n\nCode\nr_cas4bis = fun2(n, p_list[4])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\n# quit parallelisation\nfuture::plan(\"sequential\")\n\n\n\n\nCode\nres_cas1 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas1$selec_method1,r_cas1$selec_method2,r_cas1$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas1$taille_method1),mean(r_cas1$taille_method2),mean(r_cas1$taille_method3),NA),\n  Prevision_error = c(mean(r_cas1$prev_method1),mean(r_cas1$prev_method2),mean(r_cas1$prev_method3),mean(r_cas1$prev_method4)),\n  Running_time = c(r_cas1$temps1,r_cas1$temps2,r_cas1$temps3,r_cas1$temps4)\n)\nt(res_cas1)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.95\"     \"0.24\"     \"0.76\"             NA           \nMean_nb_selected_var \"3.05\"     \"4.19\"     \"3.29\"             NA           \nPrevision_error      \"4.267999\" \"4.372448\" \"4.311278\"         \"4.298561\"   \nRunning_time         \"0.0395\"   \"0.0926\"   \"0.1862\"           \"0.1901\"     \n\n\nCode\nboxplot(sqrt(r_cas1$prev_method1),sqrt(r_cas1$prev_method2),sqrt(r_cas1$prev_method3),sqrt(r_cas1$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[1]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nCode\nres_cas2 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas2$selec_method1,r_cas2$selec_method2,r_cas2$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas2$taille_method1),mean(r_cas2$taille_method2),mean(r_cas2$taille_method3),NA),\n  Prevision_error = c(mean(r_cas2$prev_method1),mean(r_cas2$prev_method2),mean(r_cas2$prev_method3),mean(r_cas2$prev_method4)),\n  Running_time = c(r_cas2$temps1,r_cas2$temps2,r_cas2$temps3,r_cas2$temps4)\n)\nt(res_cas2)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.06\"     \"0.01\"     \"0.09\"             NA           \nMean_nb_selected_var \" 7.92\"    \"12.88\"    \" 8.17\"            NA           \nPrevision_error      \"7.050225\" \"5.609938\" \"5.487207\"         \"6.401796\"   \nRunning_time         \"0.3002\"   \"0.2568\"   \"0.3666\"           \"0.3720\"     \n\n\nCode\nboxplot(sqrt(r_cas2$prev_method1),sqrt(r_cas2$prev_method2),sqrt(r_cas2$prev_method3),sqrt(r_cas2$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[2]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nCode\nres_cas3 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas3$selec_method1,r_cas3$selec_method2,r_cas3$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas3$taille_method1),mean(r_cas3$taille_method2),mean(r_cas3$taille_method3),NA),\n  Prevision_error = c(mean(r_cas3$prev_method1),mean(r_cas3$prev_method2),mean(r_cas3$prev_method3),mean(r_cas3$prev_method4)),\n  Running_time = c(r_cas3$temps1,r_cas3$temps2,r_cas3$temps3,r_cas3$temps4)\n)\nt(res_cas3)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.00\"      \"0.00\"      \"0.06\"             NA           \nMean_nb_selected_var \"40.57\"     \"15.80\"     \" 9.09\"            NA           \nPrevision_error      \"16.207790\" \" 6.138163\" \" 5.738140\"        \" 6.723044\"  \nRunning_time         \"3.0726\"    \"0.2392\"    \"0.3635\"           \"0.3691\"     \n\n\nCode\nboxplot(sqrt(r_cas3$prev_method1),sqrt(r_cas3$prev_method2),sqrt(r_cas3$prev_method3),sqrt(r_cas3$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nCode\nres_cas4 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4$selec_method1,r_cas4$selec_method2,r_cas4$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4$taille_method1),mean(r_cas4$taille_method2),mean(r_cas4$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4$prev_method1),mean(r_cas4$prev_method2),mean(r_cas4$prev_method3),mean(r_cas4$prev_method4)),\n  Running_time = c(r_cas4$temps1,r_cas4$temps2,r_cas4$temps3,r_cas4$temps4)\n)\nt(res_cas4)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \" 0\"        \" 0\"        \" 0\"               NA           \nMean_nb_selected_var \"49\"        \"41\"        \"19\"               NA           \nPrevision_error      \"11.762266\" \" 4.734249\" \" 4.562205\"        \" 5.403622\"  \nRunning_time         \"25.65\"     \" 0.19\"     \" 0.36\"            \" 0.38\"      \n\n\nCode\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4$prev_method2),sqrt(r_cas4$prev_method3),sqrt(r_cas4$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nCode\nres_cas4bis = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4bis$selec_method1,r_cas4bis$selec_method2,r_cas4bis$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4bis$taille_method1),mean(r_cas4bis$taille_method2),mean(r_cas4bis$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4bis$prev_method1),mean(r_cas4bis$prev_method2),mean(r_cas4bis$prev_method3),mean(r_cas4bis$prev_method4)),\n  Running_time = c(r_cas4bis$temps1,r_cas4bis$temps2,r_cas4bis$temps3,r_cas4bis$temps4)\n)\n\n\nWarning in mean.default(r_cas4bis$taille_method1): l'argument n'est ni\nnumérique, ni logique : renvoi de NA\n\n\nWarning in mean.default(r_cas4bis$prev_method1): l'argument n'est ni numérique,\nni logique : renvoi de NA\n\n\nCode\nt(res_cas4bis)\n\n\n                     [,1]      [,2]       [,3]               [,4]         \nMethod               \"Forward\" \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection NA        \"0.00\"     \"0.04\"             NA           \nMean_nb_selected_var NA        \"24.87\"    \"12.34\"            NA           \nPrevision_error      NA        \"7.230664\" \"6.781834\"         \"7.861071\"   \nRunning_time         NA        \"0.1812\"   \"0.3352\"           \"0.3494\"     \n\n\nCode\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4bis$prev_method2),sqrt(r_cas4bis$prev_method3),sqrt(r_cas4bis$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[4]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nQuestion 6\nRéaliser la même étude pour \\(n = 100\\) et \\(p = n/10\\), \\(p = n\\), \\(p = 2n\\), toujours basée sur \\(100\\) simulations dans chaque cas. Considérer de plus le cas \\(p = 10n\\) en ne faisant qu’une seule simulation afin d’en évaluer le temps de calcul. Une fois ce temps analysé, lancer \\(100\\) simulations pour \\(p = 10n\\) mais en omettant la méthode la plus couteuse en temps de calcul.\n\n\nCode\n#parallelisation\nfuture::plan(multisession, workers = 2)\n\nn = 100\np_list = c(n/10, n, 2*n, 10*n)\n\nr_cas1 = fun(n, p_list[1])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\nr_cas2 = fun(n, p_list[2])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\nr_cas3 = fun(n, p_list[3])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\nr_cas4 = fun(n, p_list[4],1)\n\n\n1 :\n\n\nCode\nr_cas4bis = fun2(n, p_list[4])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\n# quit parallelisation\nfuture::plan(\"sequential\")\n\n\n\n\nCode\nres_cas1 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas1$selec_method1,r_cas1$selec_method2,r_cas1$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas1$taille_method1),mean(r_cas1$taille_method2),mean(r_cas1$taille_method3),NA),\n  Prevision_error = c(mean(r_cas1$prev_method1),mean(r_cas1$prev_method2),mean(r_cas1$prev_method3),mean(r_cas1$prev_method4)),\n  Running_time = c(r_cas1$temps1,r_cas1$temps2,r_cas1$temps3,r_cas1$temps4)\n)\nt(res_cas1)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.71\"     \"0.08\"     \"0.42\"             NA           \nMean_nb_selected_var \"3.30\"     \"6.35\"     \"4.15\"             NA           \nPrevision_error      \"4.270127\" \"4.367182\" \"4.300236\"         \"4.347811\"   \nRunning_time         \"0.0548\"   \"0.0985\"   \"0.2030\"           \"0.2076\"     \n\n\nCode\nboxplot(sqrt(r_cas1$prev_method1),sqrt(r_cas1$prev_method2),sqrt(r_cas1$prev_method3),sqrt(r_cas1$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[1]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nCode\nres_cas2 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas2$selec_method1,r_cas2$selec_method2,r_cas2$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas2$taille_method1),mean(r_cas2$taille_method2),mean(r_cas2$taille_method3),NA),\n  Prevision_error = c(mean(r_cas2$prev_method1),mean(r_cas2$prev_method2),mean(r_cas2$prev_method3),mean(r_cas2$prev_method4)),\n  Running_time = c(r_cas2$temps1,r_cas2$temps2,r_cas2$temps3,r_cas2$temps4)\n)\nt(res_cas2)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.01\"     \"0.01\"     \"0.10\"             NA           \nMean_nb_selected_var \" 8.11\"    \"14.59\"    \" 7.61\"            NA           \nPrevision_error      \"5.682778\" \"4.824673\" \"4.588443\"         \"5.223387\"   \nRunning_time         \"0.5960\"   \"0.5668\"   \"0.6884\"           \"0.6941\"     \n\n\nCode\nboxplot(sqrt(r_cas2$prev_method1),sqrt(r_cas2$prev_method2),sqrt(r_cas2$prev_method3),sqrt(r_cas2$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[2]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nCode\nres_cas3 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas3$selec_method1,r_cas3$selec_method2,r_cas3$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas3$taille_method1),mean(r_cas3$taille_method2),mean(r_cas3$taille_method3),NA),\n  Prevision_error = c(mean(r_cas3$prev_method1),mean(r_cas3$prev_method2),mean(r_cas3$prev_method3),mean(r_cas3$prev_method4)),\n  Running_time = c(r_cas3$temps1,r_cas3$temps2,r_cas3$temps3,r_cas3$temps4)\n)\nt(res_cas3)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.00\"      \"0.01\"      \"0.16\"             NA           \nMean_nb_selected_var \"48.66\"     \"17.34\"     \" 7.73\"            NA           \nPrevision_error      \"11.428807\" \" 5.016189\" \" 4.523595\"        \" 5.243494\"  \nRunning_time         \"11.0293\"   \" 0.4915\"   \" 0.6252\"          \" 0.6322\"    \n\n\nCode\nboxplot(sqrt(r_cas3$prev_method1),sqrt(r_cas3$prev_method2),sqrt(r_cas3$prev_method3),sqrt(r_cas3$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nCode\nres_cas4 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4$selec_method1,r_cas4$selec_method2,r_cas4$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4$taille_method1),mean(r_cas4$taille_method2),mean(r_cas4$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4$prev_method1),mean(r_cas4$prev_method2),mean(r_cas4$prev_method3),mean(r_cas4$prev_method4)),\n  Running_time = c(r_cas4$temps1,r_cas4$temps2,r_cas4$temps3,r_cas4$temps4)\n)\nt(res_cas4)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \" 0\"        \" 0\"        \" 0\"               NA           \nMean_nb_selected_var \"99\"        \"11\"        \" 6\"               NA           \nPrevision_error      \"11.946047\" \" 5.699005\" \" 4.413508\"        \" 5.439750\"  \nRunning_time         \"233.75\"    \"  0.40\"    \"  0.62\"           \"  0.65\"     \n\n\nCode\nres_cas4bis = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4bis$selec_method1,r_cas4bis$selec_method2,r_cas4bis$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4bis$taille_method1),mean(r_cas4bis$taille_method2),mean(r_cas4bis$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4bis$prev_method1),mean(r_cas4bis$prev_method2),mean(r_cas4bis$prev_method3),mean(r_cas4bis$prev_method4)),\n  Running_time = c(r_cas4bis$temps1,r_cas4bis$temps2,r_cas4bis$temps3,r_cas4bis$temps4)\n)\n\n\nWarning in mean.default(r_cas4bis$taille_method1): l'argument n'est ni\nnumérique, ni logique : renvoi de NA\n\n\nWarning in mean.default(r_cas4bis$prev_method1): l'argument n'est ni numérique,\nni logique : renvoi de NA\n\n\nCode\nt(res_cas4bis)\n\n\n                     [,1]      [,2]       [,3]               [,4]         \nMethod               \"Forward\" \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection NA        \"0.00\"     \"0.03\"             NA           \nMean_nb_selected_var NA        \"30.92\"    \"11.07\"            NA           \nPrevision_error      NA        \"5.260876\" \"4.776523\"         \"5.836417\"   \nRunning_time         NA        \"0.3399\"   \"0.5520\"           \"0.5763\"     \n\n\nCode\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4$prev_method2),sqrt(r_cas4$prev_method3),sqrt(r_cas4$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\nCode\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4bis$prev_method2),sqrt(r_cas4bis$prev_method3),sqrt(r_cas4bis$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[4]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nQuestion 7\nConclure sur les mérites respectifs de chaque méthode dans le contexte de l’étude.\n\n\nQuestion 8\nQuelles autres types de simulations pourrait-on envisager pour confirmer ou affiner ces conclusions ?"
  },
  {
    "objectID": "posts/Exercice_1.html",
    "href": "posts/Exercice_1.html",
    "title": "Exercice 1",
    "section": "",
    "text": "packagesFonctions\n\n\n\n# Données\nlibrary(ISLR)         # Hitters data \nlibrary(dplyr)        # manipulation des données\n\n# PCA\nlibrary(FactoMineR)\nlibrary(factoextra)\n\n# Inférence\nlibrary(leaps)        # regsubsets \nlibrary(car)          # pour VIF\n\n# Plots\n## ggplot\nlibrary(ggplot2)\nlibrary(reshape2)     # transformer les données en format long\nlibrary(gridExtra)\n\n## for pairs panel\nlibrary(psych)\nlibrary(RColorBrewer)\n\n\n\n\nCritèresplot pour PCAplot pour nos critères\n\n\nOn rappel que \\(SCR = \\sum_i (y_i - f(x_i))^2\\) et \\(SCT = \\sum_i (y_i - \\bar{y})^2\\).\n\nAinsi, on peut aretrouver les différents critères :\n\\[ R^2 = 1 - \\frac{SCR}{SCT}\\]\n\nr2_fun &lt;- function(y, SCR){\n  # r2 = SSE/SST = (SST - SSR)/SST = 1 - ssr/sst\n  SCT &lt;- sum((y - mean(y) )^2)\n  r2 &lt;- 1 - SCR/SCT\n  return(r2)\n}\n\n\\[ R^2_{adjusted} = 1 - \\frac{SCR (n-1)}{SCT(n-(p+1))}\\]\n\nr2a_fun &lt;- function(y, SCR){\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  SCT &lt;- sum((y - mean(y) )^2)\n  r2a &lt;- 1 - (SCR/(n-(p+1)))/(SCT/(n-1))\n  return(r2a)\n}\n\n\\[ C_p = \\frac{SCR}{\\sigma^2} + 2(p+1) - n\\]\n\ncp_fun &lt;- function(mod, SCR){\n  sig &lt;- summary(mod)$sigma\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  cp &lt;- SCR/sig^2 + 2*(p+1) - n\n  return(cp)\n}\n\n\\[ AIC = n\\text{log}\\left(\\frac{SCR}{n}\\right) + 2(p+1)\\]\n\naic_fun &lt;- function(SCR){\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  aic &lt;- n * log(SCR/n) + 2*(p+1)\n  return(aic)\n}\n\n\\[ BIC = n\\text{log}\\left(\\frac{SCR}{n}\\right) + \\text{log}(n)(p+1)\\]\n\nbic_fun &lt;- function(SCR){\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  bic &lt;- n * log(SCR/n) + log(n)*(p+1)\n  return(bic)\n}\n\n\n\n\nas_df_for_ggplot = function(x,\n                            y = NULL,\n                            size = NULL,\n                            color = NULL,\n                            fill = NULL,\n                            pattern = NULL,\n                            shape = NULL, \n                            rownames = NULL,\n                            label = NULL,\n                            group = NULL,\n                            order = NULL,\n                            decr = FALSE) {\n  df = data.frame(x = x)\n  if (!is.null(y)) {\n    df = cbind(df, data.frame(y = y))\n  }\n  if (!is.null(size)) {\n    df = cbind(df, data.frame(size = size))\n  }\n  if (!is.null(color)) {\n    df = cbind(df, data.frame(color = color))\n  }\n  if (!is.null(fill)) {\n    df = cbind(df, data.frame(fill = fill))\n  }\n  if (!is.null(shape)) {\n    df = cbind(df, data.frame(shape = shape))\n  }\n  if (!is.null(pattern)) {\n    df = cbind(df, data.frame(pattern = pattern))\n  }\n  if (!is.null(rownames)) {\n    rownames(df) = rownames\n  } else {\n    rownames(df) = 1:nrow(df)\n  }\n  if (!is.null(group)) {\n    df = cbind(df, data.frame(group = group))\n  }\n  if (!is.null(label)) {\n    df = cbind(df, data.frame(label = label))\n  }\n  if (!is.null(order)){\n    df = cbind(df,data.frame(order = order))\n    df = df[order(df[,\"order\"], decreasing = decr),]\n  }\n  \n  return(df)\n}\n\n\ndraw_variance_barplot_pca = function(res_pca, n = 10,title = \"\", ...) {\n  df = as_df_for_ggplot(x = factor(rownames(res_pca[[\"eig\"]])[1:n], levels = rownames(res_pca[[\"eig\"]])[1:n]),\n                        y = res_pca[[\"eig\"]][1:n, 2])\n  fig = ggplot(df, aes(x = x, y = y, fill = \"deeppink3\")) +\n    geom_bar(stat = \"identity\") +\n    labs(x = \"Component\",y= \"Percentage of explained variance\", title = title)+\n    guides(fill = \"none\")+\n    theme_bw()\n  return(fig)\n}\n\n\n\n\nCriteria_plot &lt;- function(Criteria, crit_name = \"Critère\") {\n  # Création d'un data frame pour ggplot\n  df_criteria &lt;- data.frame(\n    nb_var = seq_along(Criteria),  # Nombre de variables du modèle\n    Criteria = Criteria            # Critère\n  )\n\n  # Création du plot avec ggplot2\n  g &lt;- ggplot(df_criteria, aes(x = nb_var, y = Criteria)) +\n    geom_line(color = \"#0072B2\", linewidth = 1) +  \n    geom_point(color = \"#D55E00\", size = 4) + \n    labs(\n      title = paste(\"Évolution de\", crit_name, \"en fonction du nombre de variables\"),\n      x = \"Nombre de variables sélectionnées\",\n      y = crit_name\n    ) +\n    theme_minimal() + \n    theme(\n      plot.title = element_text(hjust = 0.5, face = \"bold\", size = 26),  # Titre centré et agrandi\n      axis.title.x = element_text(face = \"bold\", size = 22),\n      axis.title.y = element_text(face = \"bold\", size = 22),\n      axis.text = element_text(size = 20)\n    )\n\n  return(g)\n}"
  },
  {
    "objectID": "posts/Exercice_1.html#modèle-brut",
    "href": "posts/Exercice_1.html#modèle-brut",
    "title": "Exercice 1",
    "section": "Modèle brut",
    "text": "Modèle brut\nOn désire modéliser le salaire Salary en fonction des variables disponibles.\nOn va donc ajuster un modèle de régression linéaire en utilisant toutes les variables à disposition et analyser la qualité de cet ajustement.\n\nmod1 &lt;- lm(formula = Salary ~ .,\n           Hitters_Without_NA) \nmod1 %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ ., data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-907.62 -178.35  -31.11  139.09 1877.04 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  163.10359   90.77854   1.797 0.073622 .  \nAtBat         -1.97987    0.63398  -3.123 0.002008 ** \nHits           7.50077    2.37753   3.155 0.001808 ** \nHmRun          4.33088    6.20145   0.698 0.485616    \nRuns          -2.37621    2.98076  -0.797 0.426122    \nRBI           -1.04496    2.60088  -0.402 0.688204    \nWalks          6.23129    1.82850   3.408 0.000766 ***\nYears         -3.48905   12.41219  -0.281 0.778874    \nCAtBat        -0.17134    0.13524  -1.267 0.206380    \nCHits          0.13399    0.67455   0.199 0.842713    \nCHmRun        -0.17286    1.61724  -0.107 0.914967    \nCRuns          1.45430    0.75046   1.938 0.053795 .  \nCRBI           0.80771    0.69262   1.166 0.244691    \nCWalks        -0.81157    0.32808  -2.474 0.014057 *  \nLeagueN       62.59942   79.26140   0.790 0.430424    \nDivisionW   -116.84925   40.36695  -2.895 0.004141 ** \nPutOuts        0.28189    0.07744   3.640 0.000333 ***\nAssists        0.37107    0.22120   1.678 0.094723 .  \nErrors        -3.36076    4.39163  -0.765 0.444857    \nNewLeagueN   -24.76233   79.00263  -0.313 0.754218    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 315.6 on 243 degrees of freedom\nMultiple R-squared:  0.5461,    Adjusted R-squared:  0.5106 \nF-statistic: 15.39 on 19 and 243 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNote\n\n\n\nNous sommes sur un modèle comprenant des variables quantitatives et qualitative ce qui le rapproche d’une modélisation ANOVA.\n\n\n\nQuelques conclusions sur le modèle :\n\n\n\nbeaucoup de variables ont un effet non significatif\nle \\(R^2\\) et le \\(R^2_{adjusted}\\) sont autour de 0.5 ce qui témoigne d’une mauvaise qualité d’ajustament du modèle\nl’écart type résiduel est de 315.6 ce qui est assez important et témoigne d’un modèle peu précis\n\n\nPour tenter de trouver un meilleur ajustment, il est important d’analyser d’avantage le lien entre toutes les variables explicatives. On utilise alors comunément le VIF\n\nvif(mod1) \n\n     AtBat       Hits      HmRun       Runs        RBI      Walks      Years \n 22.944366  30.281255   7.758668  15.246418  11.921715   4.148712   9.313280 \n    CAtBat      CHits     CHmRun      CRuns       CRBI     CWalks     League \n251.561160 502.954289  46.488462 162.520810 131.965858  19.744105   4.134115 \n  Division    PutOuts    Assists     Errors  NewLeague \n  1.075398   1.236317   2.709341   2.214543   4.099063 \n\n\nOn remarque ainsi que beaucoup de valeurs sont supérieur à 10 ce qui s’interprète communément comme la précence d’une forte colinéarité sur nos variables explicatives.\nCette colinéarité se constatait déjà durant les analyses descriptive via les graphes de corrélations (d’où l’importance de ne pas se lancer trop rapidement dans les analyses inférentielles)."
  },
  {
    "objectID": "posts/Exercice_1.html#modèles-parcimonieux",
    "href": "posts/Exercice_1.html#modèles-parcimonieux",
    "title": "Exercice 1",
    "section": "Modèles parcimonieux",
    "text": "Modèles parcimonieux\nMaintenant, on va donc tenter de trouver le meilleur sous-modèle possible. Pour cela on va suivre la procédure suivante :\n\nmettre en oeuvre une méthode de sélection automatique exhaustive et observer l’évolution des SCR (Sommes de Carrés Résiduels) pour les modèles retenus en fonction de leur taille.\ndéduire de ces SCR le \\(R^2\\), \\(R^2_{adjusted}\\), AIC, BIC et \\(C_p\\) correspondants. Les comparer avec les valeurs fournies dans le summary de regsubsets et tracer leur évolution en fonction de la taille du modèle.\n\nPuis reproduire la même procédure avec des séléctions backward, forward et stepwise\n\n\n\n\n\n\nNote\n\n\n\nUn rappel sur nos critère se trouve dans la partie Setup, onglet fonction, de ce document avec la création de fonction pour les calculer.\n\n\n\nExhaustiveBackwardForwardStepwise\n\n\n\nselec_auto &lt;- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"exhaustive\",\n                         nvmax = 19 # maximum size of subsets to examine\n                         )\n# selec_auto %&gt;% summary()\n\nOn va déjà commencer par regarder la valeur du critère en fonction des variables des différents modèles testés.\n\npar(mfrow=c(2,2))\nplot(selec_auto, scale = 'bic') \nplot(selec_auto, scale = 'Cp') \nplot(selec_auto, scale = 'r2') \nplot(selec_auto, scale = 'adjr2') \n\n\n\n\nIci on remarque clairement que toutes nos variables ne sont pas gardés lorsque l’on cherche à optimiser nos critères.\nAussi, on peut voir encore de faibles valeurs pour les \\(R^2\\) et \\(R^2_{adjusted}\\) pouvant témoignés d’un mauvais ajustement de modèle.\n\n\n\n\n\n\nNote\n\n\n\nplot.regsubsets() de leaps ne prend pas directement “aic” comme option de scale. Pour une sélection basée sur AIC, une approche alternative consiste à utiliser la fonction stepAIC() du package MASS, qui permet une sélection pas à pas basée sur AIC.\n\n\nRegardons un peut l’évolution de la Somme des Carrés Résiduels (SCR).\n\nSCR &lt;- summary(selec_auto)$rss\nCriteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\")\n\n\n\n\nMaintenant regardons les autres critères mentionné précédemment\n\nr2 &lt;- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a &lt;- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp &lt;- cp_fun(mod1, SCR)\naic &lt;- aic_fun(SCR)\nbic &lt;- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n\n\n\n\nOn peut ainsi voir que ce sont plutot des modèles entre 5 et 10 variables qui optimisent nos critères (donc pas un modèle avec toutes nos variables).\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\nbest_model_r2 &lt;- which.max(r2)\nselected_vars &lt;- summary(selec_auto)$which[best_model_r2,]\ncat(\"Meilleur modèle selon R2 : Modèle avec\", best_model_r2, \"variables\\n\")\n\nMeilleur modèle selon R2 : Modèle avec 19 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"HmRun\"       \"Runs\"       \n [6] \"RBI\"         \"Walks\"       \"Years\"       \"CAtBat\"      \"CHits\"      \n[11] \"CHmRun\"      \"CRuns\"       \"CRBI\"        \"CWalks\"      \"LeagueN\"    \n[16] \"DivisionW\"   \"PutOuts\"     \"Assists\"     \"Errors\"      \"NewLeagueN\" \n\n\n\nbest_model_r2a &lt;- which.max(r2a)\nselected_vars &lt;- summary(selec_auto)$which[best_model_r2a,]\ncat(\"Meilleur modèle selon R2a : Modèle avec\", best_model_r2a, \"variables\\n\")\n\nMeilleur modèle selon R2a : Modèle avec 11 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CAtBat\"     \n [6] \"CRuns\"       \"CRBI\"        \"CWalks\"      \"LeagueN\"     \"DivisionW\"  \n[11] \"PutOuts\"     \"Assists\"    \n\n\n\nbest_model_cp &lt;- which.min(cp)\nselected_vars &lt;- summary(selec_auto)$which[best_model_cp,]\ncat(\"Meilleur modèle selon Cp : Modèle avec\", best_model_cp, \"variables\\n\")\n\nMeilleur modèle selon Cp : Modèle avec 10 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CAtBat\"     \n [6] \"CRuns\"       \"CRBI\"        \"CWalks\"      \"DivisionW\"   \"PutOuts\"    \n[11] \"Assists\"    \n\n\n\nbest_model_aic &lt;- which.min(aic)\nselected_vars &lt;- summary(selec_auto)$which[best_model_aic,]\ncat(\"Meilleur modèle selon AIC : Modèle avec\", best_model_aic, \"variables\\n\")\n\nMeilleur modèle selon AIC : Modèle avec 10 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CAtBat\"     \n [6] \"CRuns\"       \"CRBI\"        \"CWalks\"      \"DivisionW\"   \"PutOuts\"    \n[11] \"Assists\"    \n\n\n\nbest_model_bic &lt;- which.min(bic)\nselected_vars &lt;- summary(selec_auto)$which[best_model_bic,]\ncat(\"Meilleur modèle selon BIC : Modèle avec\", best_model_bic, \"variables\\n\")\n\nMeilleur modèle selon BIC : Modèle avec 6 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n[1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CRBI\"       \n[6] \"DivisionW\"   \"PutOuts\"    \n\n\n\n\nCette fois ci on va regarder en sélection backward. D’abord, on fait à nouveau avec la fonction regsubset.\n\nselec_back &lt;- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"backward\",\n                         nvmax = 19)\n\n\npar(mfrow=c(2,2))\nplot(selec_back, scale = 'bic') \nplot(selec_back, scale = 'Cp') \nplot(selec_back, scale = 'r2') \nplot(selec_back, scale = 'adjr2') \n\n\n\n\n\nSCR &lt;- summary(selec_back)$rss\nr2 &lt;- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a &lt;- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp &lt;- cp_fun(mod1, SCR)\naic &lt;- aic_fun(SCR)\nbic &lt;- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n\n\n\n\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\nbest_model_r2 &lt;- which.max(r2)\nselected_vars &lt;- summary(selec_back)$which[best_model_r2,]\ncat(\"Meilleur modèle selon R2 : Modèle avec\", best_model_r2, \"variables\\n\")\n\nMeilleur modèle selon R2 : Modèle avec 19 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"HmRun\"       \"Runs\"       \n [6] \"RBI\"         \"Walks\"       \"Years\"       \"CAtBat\"      \"CHits\"      \n[11] \"CHmRun\"      \"CRuns\"       \"CRBI\"        \"CWalks\"      \"LeagueN\"    \n[16] \"DivisionW\"   \"PutOuts\"     \"Assists\"     \"Errors\"      \"NewLeagueN\" \n\n\n\nbest_model_r2a &lt;- which.max(r2a)\nselected_vars &lt;- summary(selec_back)$which[best_model_r2a,]\ncat(\"Meilleur modèle selon R2a : Modèle avec\", best_model_r2a, \"variables\\n\")\n\nMeilleur modèle selon R2a : Modèle avec 11 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CAtBat\"     \n [6] \"CRuns\"       \"CRBI\"        \"CWalks\"      \"LeagueN\"     \"DivisionW\"  \n[11] \"PutOuts\"     \"Assists\"    \n\n\n\nbest_model_cp &lt;- which.min(cp)\nselected_vars &lt;- summary(selec_back)$which[best_model_cp,]\ncat(\"Meilleur modèle selon Cp : Modèle avec\", best_model_cp, \"variables\\n\")\n\nMeilleur modèle selon Cp : Modèle avec 10 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CAtBat\"     \n [6] \"CRuns\"       \"CRBI\"        \"CWalks\"      \"DivisionW\"   \"PutOuts\"    \n[11] \"Assists\"    \n\n\n\nbest_model_aic &lt;- which.min(aic)\nselected_vars &lt;- summary(selec_back)$which[best_model_aic,]\ncat(\"Meilleur modèle selon AIC : Modèle avec\", best_model_aic, \"variables\\n\")\n\nMeilleur modèle selon AIC : Modèle avec 10 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CAtBat\"     \n [6] \"CRuns\"       \"CRBI\"        \"CWalks\"      \"DivisionW\"   \"PutOuts\"    \n[11] \"Assists\"    \n\n\n\nbest_model_bic &lt;- which.min(bic)\nselected_vars &lt;- summary(selec_back)$which[best_model_bic,]\ncat(\"Meilleur modèle selon BIC : Modèle avec\", best_model_bic, \"variables\\n\")\n\nMeilleur modèle selon BIC : Modèle avec 8 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n[1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CRuns\"      \n[6] \"CRBI\"        \"CWalks\"      \"DivisionW\"   \"PutOuts\"    \n\n\nOn peut également utiliser la fonction step de la library { stats }. Pour cela, on part du plus gros modèle défini précédemment par mod1.\n\nn &lt;- nrow(Hitters_Without_NA)\nmodselect_back_bic &lt;- step(mod1,\n                       scope = formula(mod1),\n                       trace = FALSE, # trace = TRUE permet de voir le détail des étapes\n                       direction = c(\"backward\"),\n                       k = log(n) # BIC selection\n                       )\n\nPuis on peut regarder le modèle qui optimise le critère utilisé pour la selection.\n\nmodselect_back_bic %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CRuns + CRBI + CWalks + \n    Division + PutOuts, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-794.06 -171.94  -28.48  133.36 2017.83 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  117.15204   65.07016   1.800 0.072985 .  \nAtBat         -2.03392    0.52282  -3.890 0.000128 ***\nHits           6.85491    1.65215   4.149 4.56e-05 ***\nWalks          6.44066    1.52212   4.231 3.25e-05 ***\nCRuns          0.70454    0.24869   2.833 0.004981 ** \nCRBI           0.52732    0.18861   2.796 0.005572 ** \nCWalks        -0.80661    0.26395  -3.056 0.002483 ** \nDivisionW   -123.77984   39.28749  -3.151 0.001824 ** \nPutOuts        0.27539    0.07431   3.706 0.000259 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 314.7 on 254 degrees of freedom\nMultiple R-squared:  0.5281,    Adjusted R-squared:  0.5133 \nF-statistic: 35.54 on 8 and 254 DF,  p-value: &lt; 2.2e-16\n\n\nLa fonction step propose aussi une selection avec AIC et Cp.\n\nAIC\n\n\nmodselect_back_aic &lt;- step(mod1,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"backward\"),\n                       k = 2 # AIC selection\n                       )\n\nmodselect_back_aic %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + \n    CRBI + CWalks + Division + PutOuts + Assists, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-939.11 -176.87  -34.08  130.90 1910.55 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  162.53544   66.90784   2.429 0.015830 *  \nAtBat         -2.16865    0.53630  -4.044 7.00e-05 ***\nHits           6.91802    1.64665   4.201 3.69e-05 ***\nWalks          5.77322    1.58483   3.643 0.000327 ***\nCAtBat        -0.13008    0.05550  -2.344 0.019858 *  \nCRuns          1.40825    0.39040   3.607 0.000373 ***\nCRBI           0.77431    0.20961   3.694 0.000271 ***\nCWalks        -0.83083    0.26359  -3.152 0.001818 ** \nDivisionW   -112.38006   39.21438  -2.866 0.004511 ** \nPutOuts        0.29737    0.07444   3.995 8.50e-05 ***\nAssists        0.28317    0.15766   1.796 0.073673 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.8 on 252 degrees of freedom\nMultiple R-squared:  0.5405,    Adjusted R-squared:  0.5223 \nF-statistic: 29.64 on 10 and 252 DF,  p-value: &lt; 2.2e-16\n\n\n\n\\(C_p\\)\n\n\nmodselect_back_cp &lt;- step(mod1,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"backward\"),\n                       k = 1 # Cp selection\n                       )\n\nmodselect_back_cp %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + \n    CRBI + CWalks + League + Division + PutOuts + Assists, data = Hitters_Without_NA)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-932.2 -175.4  -29.2  130.4 1897.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  135.75122   71.34623   1.903 0.058223 .  \nAtBat         -2.12775    0.53746  -3.959 9.81e-05 ***\nHits           6.92370    1.64612   4.206 3.62e-05 ***\nWalks          5.62028    1.59064   3.533 0.000488 ***\nCAtBat        -0.13899    0.05609  -2.478 0.013870 *  \nCRuns          1.45533    0.39270   3.706 0.000259 ***\nCRBI           0.78525    0.20978   3.743 0.000225 ***\nCWalks        -0.82286    0.26361  -3.121 0.002010 ** \nLeagueN       43.11162   39.96612   1.079 0.281755    \nDivisionW   -111.14603   39.21835  -2.834 0.004970 ** \nPutOuts        0.28941    0.07478   3.870 0.000139 ***\nAssists        0.26883    0.15816   1.700 0.090430 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 251 degrees of freedom\nMultiple R-squared:  0.5426,    Adjusted R-squared:  0.5226 \nF-statistic: 27.07 on 11 and 251 DF,  p-value: &lt; 2.2e-16\n\n\nOn voit que parmi nos modèles, le BIC semble le plus parcimonieux mais de manière général on constate encore des valeurs de \\(R^2\\) et \\(R^2_{adjusted}\\) assez faibles.\n\n\nCette fois ci on va regarder en sélection forward. D’abord, on fait à nouveau avec la fonction regsubset.\n\nselec_forw &lt;- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"forward\",\n                         nvmax = 19)\n\n\npar(mfrow=c(2,2))\nplot(selec_forw, scale = 'bic') \nplot(selec_forw, scale = 'Cp') \nplot(selec_forw, scale = 'r2') \nplot(selec_forw, scale = 'adjr2') \n\n\n\n\n\nSCR &lt;- summary(selec_forw)$rss\nr2 &lt;- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a &lt;- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp &lt;- cp_fun(mod1, SCR)\naic &lt;- aic_fun(SCR)\nbic &lt;- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n\n\n\n\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\nbest_model_r2 &lt;- which.max(r2)\nselected_vars &lt;- summary(selec_forw)$which[best_model_r2,]\ncat(\"Meilleur modèle selon R2 : Modèle avec\", best_model_r2, \"variables\\n\")\n\nMeilleur modèle selon R2 : Modèle avec 19 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"HmRun\"       \"Runs\"       \n [6] \"RBI\"         \"Walks\"       \"Years\"       \"CAtBat\"      \"CHits\"      \n[11] \"CHmRun\"      \"CRuns\"       \"CRBI\"        \"CWalks\"      \"LeagueN\"    \n[16] \"DivisionW\"   \"PutOuts\"     \"Assists\"     \"Errors\"      \"NewLeagueN\" \n\n\n\nbest_model_r2a &lt;- which.max(r2a)\nselected_vars &lt;- summary(selec_forw)$which[best_model_r2a,]\ncat(\"Meilleur modèle selon R2a : Modèle avec\", best_model_r2a, \"variables\\n\")\n\nMeilleur modèle selon R2a : Modèle avec 11 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CAtBat\"     \n [6] \"CRuns\"       \"CRBI\"        \"CWalks\"      \"LeagueN\"     \"DivisionW\"  \n[11] \"PutOuts\"     \"Assists\"    \n\n\n\nbest_model_cp &lt;- which.min(cp)\nselected_vars &lt;- summary(selec_forw)$which[best_model_cp,]\ncat(\"Meilleur modèle selon Cp : Modèle avec\", best_model_cp, \"variables\\n\")\n\nMeilleur modèle selon Cp : Modèle avec 10 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CAtBat\"     \n [6] \"CRuns\"       \"CRBI\"        \"CWalks\"      \"DivisionW\"   \"PutOuts\"    \n[11] \"Assists\"    \n\n\n\nbest_model_aic &lt;- which.min(aic)\nselected_vars &lt;- summary(selec_forw)$which[best_model_aic,]\ncat(\"Meilleur modèle selon AIC : Modèle avec\", best_model_aic, \"variables\\n\")\n\nMeilleur modèle selon AIC : Modèle avec 10 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CAtBat\"     \n [6] \"CRuns\"       \"CRBI\"        \"CWalks\"      \"DivisionW\"   \"PutOuts\"    \n[11] \"Assists\"    \n\n\n\nbest_model_bic &lt;- which.min(bic)\nselected_vars &lt;- summary(selec_forw)$which[best_model_bic,]\ncat(\"Meilleur modèle selon BIC : Modèle avec\", best_model_bic, \"variables\\n\")\n\nMeilleur modèle selon BIC : Modèle avec 6 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n[1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CRBI\"       \n[6] \"DivisionW\"   \"PutOuts\"    \n\n\nOn peut également utiliser la fonction step de la library { stats }. Cette fois ci il faut définir en modèle de départ le plus petit modèle (celui composé seulement de l’intercept).\n\nmod0 &lt;- lm(Salary~1,\n           Hitters_Without_NA)\n\nmodselect_forw_bic &lt;- step(mod0,\n                       scope = formula(mod1),\n                       trace = FALSE, # trace = TRUE permet de voir le détail des étapes\n                       direction = c(\"forward\"),\n                       k = log(n) # BIC selection\n                       )\n\nPuis on peut regarder le modèle qui optimise le critère utilisé pour la selection.\n\nmodselect_forw_bic %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-873.11 -181.72  -25.91  141.77 2040.47 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   91.51180   65.00006   1.408 0.160382    \nCRBI           0.64302    0.06443   9.979  &lt; 2e-16 ***\nHits           7.60440    1.66254   4.574 7.46e-06 ***\nPutOuts        0.26431    0.07477   3.535 0.000484 ***\nDivisionW   -122.95153   39.82029  -3.088 0.002239 ** \nAtBat         -1.86859    0.52742  -3.543 0.000470 ***\nWalks          3.69765    1.21036   3.055 0.002488 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 319.9 on 256 degrees of freedom\nMultiple R-squared:  0.5087,    Adjusted R-squared:  0.4972 \nF-statistic: 44.18 on 6 and 256 DF,  p-value: &lt; 2.2e-16\n\n\nLa fonction step propose aussi une selection avec AIC et Cp.\n\nAIC\n\n\nmodselect_forw_aic &lt;- step(mod0,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"forward\"),\n                       k = 2 # AIC selection\n                       )\n\nmodselect_forw_aic %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-939.11 -176.87  -34.08  130.90 1910.55 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  162.53544   66.90784   2.429 0.015830 *  \nCRBI           0.77431    0.20961   3.694 0.000271 ***\nHits           6.91802    1.64665   4.201 3.69e-05 ***\nPutOuts        0.29737    0.07444   3.995 8.50e-05 ***\nDivisionW   -112.38006   39.21438  -2.866 0.004511 ** \nAtBat         -2.16865    0.53630  -4.044 7.00e-05 ***\nWalks          5.77322    1.58483   3.643 0.000327 ***\nCWalks        -0.83083    0.26359  -3.152 0.001818 ** \nCRuns          1.40825    0.39040   3.607 0.000373 ***\nCAtBat        -0.13008    0.05550  -2.344 0.019858 *  \nAssists        0.28317    0.15766   1.796 0.073673 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.8 on 252 degrees of freedom\nMultiple R-squared:  0.5405,    Adjusted R-squared:  0.5223 \nF-statistic: 29.64 on 10 and 252 DF,  p-value: &lt; 2.2e-16\n\n\n\n\\(C_p\\)\n\n\nmodselect_forw_cp &lt;- step(mod0,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"forward\"),\n                       k = 1 # Cp selection\n                       )\n\nmodselect_forw_cp %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists + League, data = Hitters_Without_NA)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-932.2 -175.4  -29.2  130.4 1897.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  135.75122   71.34623   1.903 0.058223 .  \nCRBI           0.78525    0.20978   3.743 0.000225 ***\nHits           6.92370    1.64612   4.206 3.62e-05 ***\nPutOuts        0.28941    0.07478   3.870 0.000139 ***\nDivisionW   -111.14603   39.21835  -2.834 0.004970 ** \nAtBat         -2.12775    0.53746  -3.959 9.81e-05 ***\nWalks          5.62028    1.59064   3.533 0.000488 ***\nCWalks        -0.82286    0.26361  -3.121 0.002010 ** \nCRuns          1.45533    0.39270   3.706 0.000259 ***\nCAtBat        -0.13899    0.05609  -2.478 0.013870 *  \nAssists        0.26883    0.15816   1.700 0.090430 .  \nLeagueN       43.11162   39.96612   1.079 0.281755    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 251 degrees of freedom\nMultiple R-squared:  0.5426,    Adjusted R-squared:  0.5226 \nF-statistic: 27.07 on 11 and 251 DF,  p-value: &lt; 2.2e-16\n\n\nOn voit que parmi nos modèles, le BIC semble le plus parcimonieux mais de manière général on constate encore des valeurs de \\(R^2\\) et \\(R^2_{adjusted}\\) assez faibles.\n\n\nMaintenant on va regarder en sélection stepwise. D’abord, on fait à nouveau avec la fonction regsubset.\n\nselec_seq &lt;- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"seqrep\",\n                         nvmax = 19)\n\n\npar(mfrow=c(2,2))\nplot(selec_seq, scale = 'bic') \nplot(selec_seq, scale = 'Cp') \nplot(selec_seq, scale = 'r2') \nplot(selec_seq, scale = 'adjr2') \n\n\n\n\n\nSCR &lt;- summary(selec_seq)$rss\nr2 &lt;- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a &lt;- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp &lt;- cp_fun(mod1, SCR)\naic &lt;- aic_fun(SCR)\nbic &lt;- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n\n\n\n\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\nbest_model_r2 &lt;- which.max(r2)\nselected_vars &lt;- summary(selec_seq)$which[best_model_r2,]\ncat(\"Meilleur modèle selon R2 : Modèle avec\", best_model_r2, \"variables\\n\")\n\nMeilleur modèle selon R2 : Modèle avec 19 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"HmRun\"       \"Runs\"       \n [6] \"RBI\"         \"Walks\"       \"Years\"       \"CAtBat\"      \"CHits\"      \n[11] \"CHmRun\"      \"CRuns\"       \"CRBI\"        \"CWalks\"      \"LeagueN\"    \n[16] \"DivisionW\"   \"PutOuts\"     \"Assists\"     \"Errors\"      \"NewLeagueN\" \n\n\n\nbest_model_r2a &lt;- which.max(r2a)\nselected_vars &lt;- summary(selec_seq)$which[best_model_r2a,]\ncat(\"Meilleur modèle selon R2a : Modèle avec\", best_model_r2a, \"variables\\n\")\n\nMeilleur modèle selon R2a : Modèle avec 11 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CAtBat\"     \n [6] \"CRuns\"       \"CRBI\"        \"CWalks\"      \"LeagueN\"     \"DivisionW\"  \n[11] \"PutOuts\"     \"Assists\"    \n\n\n\nbest_model_cp &lt;- which.min(cp)\nselected_vars &lt;- summary(selec_seq)$which[best_model_cp,]\ncat(\"Meilleur modèle selon Cp : Modèle avec\", best_model_cp, \"variables\\n\")\n\nMeilleur modèle selon Cp : Modèle avec 10 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CAtBat\"     \n [6] \"CRuns\"       \"CRBI\"        \"CWalks\"      \"DivisionW\"   \"PutOuts\"    \n[11] \"Assists\"    \n\n\n\nbest_model_aic &lt;- which.min(aic)\nselected_vars &lt;- summary(selec_seq)$which[best_model_aic,]\ncat(\"Meilleur modèle selon AIC : Modèle avec\", best_model_aic, \"variables\\n\")\n\nMeilleur modèle selon AIC : Modèle avec 10 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CAtBat\"     \n [6] \"CRuns\"       \"CRBI\"        \"CWalks\"      \"DivisionW\"   \"PutOuts\"    \n[11] \"Assists\"    \n\n\n\nbest_model_bic &lt;- which.min(bic)\nselected_vars &lt;- summary(selec_seq)$which[best_model_bic,]\ncat(\"Meilleur modèle selon BIC : Modèle avec\", best_model_bic, \"variables\\n\")\n\nMeilleur modèle selon BIC : Modèle avec 6 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n[1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CRBI\"       \n[6] \"DivisionW\"   \"PutOuts\"    \n\n\nOn peut également utiliser la fonction step de la library { stats }.\n\nmodselect_bic &lt;- step(mod0,\n                  scope = formula(mod1),\n                  trace = FALSE,\n                  direction = c(\"both\"),\n                  k = log(n))\nmodselect_bic %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-873.11 -181.72  -25.91  141.77 2040.47 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   91.51180   65.00006   1.408 0.160382    \nCRBI           0.64302    0.06443   9.979  &lt; 2e-16 ***\nHits           7.60440    1.66254   4.574 7.46e-06 ***\nPutOuts        0.26431    0.07477   3.535 0.000484 ***\nDivisionW   -122.95153   39.82029  -3.088 0.002239 ** \nAtBat         -1.86859    0.52742  -3.543 0.000470 ***\nWalks          3.69765    1.21036   3.055 0.002488 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 319.9 on 256 degrees of freedom\nMultiple R-squared:  0.5087,    Adjusted R-squared:  0.4972 \nF-statistic: 44.18 on 6 and 256 DF,  p-value: &lt; 2.2e-16\n\n\n\nmodselect_aic &lt;- step(mod0,\n                  scope = formula(mod1),\n                  trace = FALSE,\n                  direction = c(\"both\"),\n                  k = 2)\nmodselect_aic %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-939.11 -176.87  -34.08  130.90 1910.55 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  162.53544   66.90784   2.429 0.015830 *  \nCRBI           0.77431    0.20961   3.694 0.000271 ***\nHits           6.91802    1.64665   4.201 3.69e-05 ***\nPutOuts        0.29737    0.07444   3.995 8.50e-05 ***\nDivisionW   -112.38006   39.21438  -2.866 0.004511 ** \nAtBat         -2.16865    0.53630  -4.044 7.00e-05 ***\nWalks          5.77322    1.58483   3.643 0.000327 ***\nCWalks        -0.83083    0.26359  -3.152 0.001818 ** \nCRuns          1.40825    0.39040   3.607 0.000373 ***\nCAtBat        -0.13008    0.05550  -2.344 0.019858 *  \nAssists        0.28317    0.15766   1.796 0.073673 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.8 on 252 degrees of freedom\nMultiple R-squared:  0.5405,    Adjusted R-squared:  0.5223 \nF-statistic: 29.64 on 10 and 252 DF,  p-value: &lt; 2.2e-16\n\n\n\nmodselect_cp &lt;- step(mod0,\n                  scope = formula(mod1),\n                  trace = FALSE,\n                  direction = c(\"both\"),\n                  k = 1)\nmodselect_cp %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists + League, data = Hitters_Without_NA)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-932.2 -175.4  -29.2  130.4 1897.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  135.75122   71.34623   1.903 0.058223 .  \nCRBI           0.78525    0.20978   3.743 0.000225 ***\nHits           6.92370    1.64612   4.206 3.62e-05 ***\nPutOuts        0.28941    0.07478   3.870 0.000139 ***\nDivisionW   -111.14603   39.21835  -2.834 0.004970 ** \nAtBat         -2.12775    0.53746  -3.959 9.81e-05 ***\nWalks          5.62028    1.59064   3.533 0.000488 ***\nCWalks        -0.82286    0.26361  -3.121 0.002010 ** \nCRuns          1.45533    0.39270   3.706 0.000259 ***\nCAtBat        -0.13899    0.05609  -2.478 0.013870 *  \nAssists        0.26883    0.15816   1.700 0.090430 .  \nLeagueN       43.11162   39.96612   1.079 0.281755    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 251 degrees of freedom\nMultiple R-squared:  0.5426,    Adjusted R-squared:  0.5226 \nF-statistic: 27.07 on 11 and 251 DF,  p-value: &lt; 2.2e-16\n\n\nMalheuresement, même en sélection both nous avons encore des \\(R^2\\) et \\(R^2_{adjusted}\\) faibles.\nMais si on veut comparer le modèle initial et le modèle final, on peut utiliser la fonction ANOVA. Cela permet de voir si la sélection de variables a significativement amélioré l’ajustement.\n\nanova(mod0, modselect_bic, test = \"Chisq\")\n\nAnalysis of Variance Table\n\nModel 1: Salary ~ 1\nModel 2: Salary ~ CRBI + Hits + PutOuts + Division + AtBat + Walks\n  Res.Df      RSS Df Sum of Sq  Pr(&gt;Chi)    \n1    262 53319113                           \n2    256 26194904  6  27124209 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDe manière logique on voit donc tout de même que le modèle avec nos variable explicatives sélectionnées (ici celui avec selection via le critère BIC) propose un meilleur ajustement que celui sans variable."
  },
  {
    "objectID": "posts/Exercice_Bonus.html",
    "href": "posts/Exercice_Bonus.html",
    "title": "Exercice Bonus : Ridge vs Lasso",
    "section": "",
    "text": "Source : https://lrouviere.github.io/TUTO_GRANDE_DIM/correction/03-ridge-lasso.html\n\n\nShow the code\n# ozone &lt;- read.csv(\"~/1.Workspace/Master_IS/M2/X3MS020_Statistique_en_grande_dimension/ozone.txt\", sep=\"\")\nozone &lt;-read.table(\"https://r-stat-sc-donnees.github.io/ozone.txt\", header=TRUE)\nhead(ozone)\n\n\n         maxO3   T9  T12  T15 Ne9 Ne12 Ne15     Vx9    Vx12    Vx15 maxO3v\n20010601    87 15.6 18.5 18.4   4    4    8  0.6946 -1.7101 -0.6946     84\n20010602    82 17.0 18.4 17.7   5    5    7 -4.3301 -4.0000 -3.0000     87\n20010603    92 15.3 17.6 19.5   2    5    4  2.9544  1.8794  0.5209     82\n20010604   114 16.2 19.7 22.5   1    1    0  0.9848  0.3473 -0.1736     92\n20010605    94 17.4 20.5 20.4   8    8    7 -0.5000 -2.9544 -4.3301    114\n20010606    80 17.7 19.8 18.3   6    6    7 -5.6382 -5.0000 -6.0000     94\n          vent pluie\n20010601  Nord   Sec\n20010602  Nord   Sec\n20010603   Est   Sec\n20010604  Nord   Sec\n20010605 Ouest   Sec\n20010606 Ouest Pluie\n\n\nShow the code\nsummary(ozone)\n\n\n     maxO3              T9             T12             T15       \n Min.   : 42.00   Min.   :11.30   Min.   :14.00   Min.   :14.90  \n 1st Qu.: 70.75   1st Qu.:16.20   1st Qu.:18.60   1st Qu.:19.27  \n Median : 81.50   Median :17.80   Median :20.55   Median :22.05  \n Mean   : 90.30   Mean   :18.36   Mean   :21.53   Mean   :22.63  \n 3rd Qu.:106.00   3rd Qu.:19.93   3rd Qu.:23.55   3rd Qu.:25.40  \n Max.   :166.00   Max.   :27.00   Max.   :33.50   Max.   :35.50  \n      Ne9             Ne12            Ne15           Vx9         \n Min.   :0.000   Min.   :0.000   Min.   :0.00   Min.   :-7.8785  \n 1st Qu.:3.000   1st Qu.:4.000   1st Qu.:3.00   1st Qu.:-3.2765  \n Median :6.000   Median :5.000   Median :5.00   Median :-0.8660  \n Mean   :4.929   Mean   :5.018   Mean   :4.83   Mean   :-1.2143  \n 3rd Qu.:7.000   3rd Qu.:7.000   3rd Qu.:7.00   3rd Qu.: 0.6946  \n Max.   :8.000   Max.   :8.000   Max.   :8.00   Max.   : 5.1962  \n      Vx12             Vx15            maxO3v           vent          \n Min.   :-7.878   Min.   :-9.000   Min.   : 42.00   Length:112        \n 1st Qu.:-3.565   1st Qu.:-3.939   1st Qu.: 71.00   Class :character  \n Median :-1.879   Median :-1.550   Median : 82.50   Mode  :character  \n Mean   :-1.611   Mean   :-1.691   Mean   : 90.57                     \n 3rd Qu.: 0.000   3rd Qu.: 0.000   3rd Qu.:106.00                     \n Max.   : 6.578   Max.   : 5.000   Max.   :166.00                     \n    pluie          \n Length:112        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nShow the code\nlibrary(psych)\n\n\nWarning: le package 'psych' a été compilé avec la version R 4.2.3\n\n\nShow the code\npairs.panels(ozone)\n\n\n\n\n\n\n\n\n\nShow the code\nozone.X &lt;- model.matrix(maxO3~.,data=ozone)[,-1] #  codage des variables qualitatives avec la fonction model.matrix\nozone.Y &lt;- ozone$maxO3\n\nlibrary(glmnet)\n\n\nWarning: le package 'glmnet' a été compilé avec la version R 4.2.3\n\n\nLe chargement a nécessité le package : Matrix\n\n\nWarning: le package 'Matrix' a été compilé avec la version R 4.2.3\n\n\nLoaded glmnet 4.1-8\n\n\nShow the code\nmod.R &lt;- glmnet(ozone.X, ozone.Y, alpha=0) ## Ridge \n\nmod.L &lt;- glmnet(ozone.X, ozone.Y, alpha=1) ## Lasso\n\n# Par défaut standardize = TRUE, intercept = TRUE\n\n## Analyse Modèle Ridge\nmod.R$lambda |&gt; head()\n\n\n[1] 22007.27 20052.20 18270.82 16647.69 15168.76 13821.21\n\n\nShow the code\n# When alpha=0, the largest lambda reported does not quite give \n# the zero coefficients reported (lambda=inf would in principle).\n# Instead, the largest lambda for alpha=0.001 is used, and the sequence \n# of lambda values is derived from this.\n\n\nmod.R$beta[,1]\n\n\n           T9           T12           T15           Ne9          Ne12 \n 6.376767e-36  5.523924e-36  4.867402e-36 -6.821464e-36 -7.994984e-36 \n         Ne15           Vx9          Vx12          Vx15        maxO3v \n-5.839057e-36  5.706014e-36  4.387350e-36  3.970583e-36  6.892387e-37 \n     ventNord     ventOuest       ventSud      pluieSec \n-5.830507e-36 -1.022483e-35  1.519222e-35  2.772246e-35 \n\n\nShow the code\n# Our coefficients\n\npar(mfrow=c(1,2))\nplot(mod.R,label=TRUE)  \n# lecture du graphe : \n#   - chaque courbe c'est lévolution d'un beta\n#   - à droite on à les valeurs de beta MCO \n#   - à gauche c'est quand lambda augmente, on tend vers 0\n\nplot(mod.R,xvar=\"lambda\",label=TRUE)\n\n\n\n\n\n\n\n\n\nShow the code\npar(mfrow=c(1,1))\n\n\n\n\n\n\n\n## Analyse Modèle Lasso\nmod.L$lambda |&gt; head()\n\n\n[1] 22.00727 20.05220 18.27082 16.64769 15.16876 13.82121\n\n\nShow the code\nmod.L$beta[,1]\n\n\n       T9       T12       T15       Ne9      Ne12      Ne15       Vx9      Vx12 \n        0         0         0         0         0         0         0         0 \n     Vx15    maxO3v  ventNord ventOuest   ventSud  pluieSec \n        0         0         0         0         0         0 \n\n\nShow the code\npar(mfrow=c(1,2))\nplot(mod.L,label=TRUE)  \nplot(mod.L,xvar=\"lambda\",label=TRUE)\n\n\n\n\n\n\n\n\n\nShow the code\npar(mfrow=c(1,1))\n\n####\n# Sélection des paramètres de régularisation ####\n\nridgeCV &lt;- cv.glmnet(ozone.X, ozone.Y, alpha=0)\nplot(ridgeCV)\n\n\n\n\n\n\n\n\n\nShow the code\n# abline(v=log(ridgeCV$lambda.1se), col='red')\n# abline(v=log(ridgeCV$lambda.min), col='red')\n\n# On visualise les erreurs quadratiques calculées \n# par validation croisée 10 blocs en fonction de lambda (échelle log)\n\n# Deux traites verticaux :\n#   - celui de gauche correspond à la valeur de `lambda`\n#     qui minimise l’erreur quadratique ;\n# \n#   - celui de droite correspond à la plus grande valeur de `lambda` \n#     telle que l’erreur ne dépasse pas \n#     l’erreur minimale + 1 écart-type estimé de cette erreur.\n\n\n# D’un point de vu pratique, cela signifie que l’utilisateur\n# peut choisir n’importe quelle valeur de lambda entre \n# les deux traits verticaux. Si on veut diminuer \n# la complexité du modèle on choisira la valeur de droite.\n# On peut obtenir ces deux valeurs \n\nridgeCV$lambda.min\n\n\n[1] 9.750588\n\n\nShow the code\nridgeCV$lambda.1se\n\n\n[1] 43.20116\n\n\nShow the code\nlassoCV &lt;- cv.glmnet(ozone.X, ozone.Y, alpha=1)\nplot(lassoCV)\n\n\n\n\n\n\n\n\n\nShow the code\n# abline(v=log(lassoCV$lambda.1se), col='red')\n# abline(v=log(lassoCV$lambda.min), col='red')\n\nlassoCV$lambda.min\n\n\n[1] 1.230385\n\n\nShow the code\nlassoCV$lambda.1se\n\n\n[1] 4.967084\n\n\nShow the code\n####\n# Prédiction de la variable cible pour de nouveaux individus ####\n\n# Première approche :\n# réajuster le modèle sur toutes les données pour la valeur \n# de lambda sélectionnée.\n# Cette étape est en réalité déjà effectuée par la fonction cv.glmnet.\n# Il suffit par conséquent d’appliquer la fonction predict à l’objet \n# obtenu avec cv.glmnet en spécifiant la valeur de lambda souhaitée.\npredict(ridgeCV, newx = ozone.X[50:51,],s=\"lambda.min\")\n\n\n         lambda.min\n20010723   90.10981\n20010724   96.74374\n\n\nShow the code\npredict(ridgeCV, newx = ozone.X[50:51,],s=\"lambda.1se\")\n\n\n         lambda.1se\n20010723   93.23058\n20010724   96.21185\n\n\nShow the code\npredict(lassoCV, newx = ozone.X[50:51,],s=\"lambda.min\")\n\n\n         lambda.min\n20010723   87.18235\n20010724   98.23752\n\n\nShow the code\npredict(lassoCV, newx = ozone.X[50:51,],s=\"lambda.1se\")\n\n\n         lambda.1se\n20010723   87.44713\n20010724   95.61077\n\n\nShow the code\n# Comparaison performances MCO, ridge et lasso ####\n\n# validation croisée pour comparer les performances des estimateurs\n# MCO, ridge et lasso.\n# On pourra utiliser les données ozone_complet.txt\n# qui contiennent plus d’individus et de variables.\n\n# ozone1 &lt;- read.csv(\"~/1. Workspace/Master IS/M2/X3MS020 Statistique en grande dimension/ozone_complet.txt\", sep=\";\") |&gt; na.omit()\nozone1 &lt;-read.table(\"https://r-stat-sc-donnees.github.io/ozone.txt\", header=TRUE) |&gt; na.omit()\nozone1.X &lt;- model.matrix(maxO3~., data=ozone1)[,-1]\nozone1.Y &lt;- ozone1$maxO3\n\nlibrary(tibble)\n\n\nWarning: le package 'tibble' a été compilé avec la version R 4.2.3\n\n\nShow the code\nlibrary(dplyr)\n\n\nWarning: le package 'dplyr' a été compilé avec la version R 4.2.3\n\n\n\nAttachement du package : 'dplyr'\n\n\nLes objets suivants sont masqués depuis 'package:stats':\n\n    filter, lag\n\n\nLes objets suivants sont masqués depuis 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nShow the code\ncv.ridge.lasso &lt;- function(data,form){\n  set.seed(1234)\n  data.X &lt;- model.matrix(form,data=data)[,-1]\n  data.Y &lt;- data$maxO3\n  blocs &lt;- caret::createFolds(1:nrow(data),k=10)\n  prev &lt;- matrix(0,ncol=3,nrow=nrow(data)) |&gt; as.data.frame()\n  names(prev) &lt;- c(\"lin\",\"ridge\",\"lasso\")\n  for (k in 1:10){\n    app &lt;- data[-blocs[[k]],]\n    test &lt;- data[blocs[[k]],]\n    app.X &lt;- data.X[-blocs[[k]],]\n    app.Y &lt;- data.Y[-blocs[[k]]]\n    test.X &lt;- data.X[blocs[[k]],]\n    test.Y &lt;- data.Y[blocs[[k]]]\n    ridge &lt;- cv.glmnet(app.X,app.Y,alpha=0)\n    lasso &lt;- cv.glmnet(app.X,app.Y,alpha=1)\n    lin &lt;- lm(form,data=app)\n    prev[blocs[[k]],] &lt;- tibble(lin=predict(lin,newdata=test),\n                                ridge=as.vector(predict(ridge,newx=test.X)),\n                                lasso=as.vector(predict(lasso,newx=test.X)))\n  }\n  err &lt;- prev |&gt; mutate(obs=data$maxO3) |&gt; summarise_at(1:3,~mean((obs-.)^2))\n  return(err)\n}\n\ncv.ridge.lasso(ozone1, form=formula(maxO3~.))\n\n\n       lin    ridge    lasso\n1 247.4596 271.8111 272.9936\n\n\nShow the code\n# On remarque que les approches régularisées \n# n’apportent rien par rapport aux estimateurs MCO ici.\n# Ceci peut s’expliquer par le fait que le nombre de variables\n# n’est pas très important.\n\n# Considérons toutes les interactions d’ordre 2\ncv.ridge.lasso(ozone1, form=formula(maxO3~.^2))\n\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\n\n       lin    ridge    lasso\n1 196622.7 335.9692 268.1647\n\n\nShow the code\n# Les méthodes régularisées permettent ici de diminuer\n# les erreurs quadratiques de manière intéressante.\n# Cela vient certainement du fait du nombre de \n# variables explicatives qui est beaucoup plus \n# important lorsqu’on prend en compte toutes \n# les interactions d’ordre 2, nous en avons en effet 253 :\nozone2.X &lt;- model.matrix(maxO3~.^2,data=ozone1)[,-1]\ndim(ozone2.X)\n\n\n[1] 112 102"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistique en grande dimension",
    "section": "",
    "text": "Exercice 1\n\n\n\n\n\n\n\nTP\n\n\n\n\nIl s’agit d’une première utilisation des méthodes de regression avec selection de variable via des approches stepwise sur des données de baseball\n\n\n\n\n\n\nInvalid Date\n\n\nClément Poupelin\n\n\n\n\n\n\n  \n\n\n\n\nExercice 2\n\n\n\n\n\n\n\nTP\n\n\n\n\nIci, on commence à utilser des méthodes de regression avec selection de variable et tester le lien linéaire existant sur des données de baseball\n\n\n\n\n\n\nInvalid Date\n\n\nClément Poupelin\n\n\n\n\n\n\n  \n\n\n\n\nExercice 9\n\n\n\n\n\n\n\nTP\n\n\n\n\nComparaison de différents modèles de regression\n\n\n\n\n\n\nInvalid Date\n\n\nClément Poupelin\n\n\n\n\n\n\n  \n\n\n\n\nExercice Bonus : Ridge vs Lasso\n\n\n\n\n\n\n\nBonus\n\n\n\n\nComparaison de la regression Ridge et Lasso\n\n\n\n\n\n\nInvalid Date\n\n\nClément Poupelin\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Exercice_2.html",
    "href": "posts/Exercice_2.html",
    "title": "Exercice 2",
    "section": "",
    "text": "packagesFonctions\n\n\n\n# Données\nlibrary(ISLR)         # Hitters data \nlibrary(dplyr)        # manipulation des données"
  },
  {
    "objectID": "posts/Exercice_2.html#modèle-brut",
    "href": "posts/Exercice_2.html#modèle-brut",
    "title": "Exercice 2",
    "section": "Modèle brut",
    "text": "Modèle brut\nOn désire modéliser le salaire Salary en fonction des variables disponibles.\nOn va donc ajuster un modèle de régression linéaire en utilisant toutes les variables à disposition et analyser la qualité de cet ajustement.\n\nmod1 &lt;- lm(formula = Salary ~ .,\n           Hitters_Without_NA_18) \nmod1 %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ ., data = Hitters_Without_NA_18)\n\nResiduals:\nALL 18 residuals are 0: no residual degrees of freedom!\n\nCoefficients: (2 not defined because of singularities)\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) -223.7909        NaN     NaN      NaN\nAtBat         -3.2428        NaN     NaN      NaN\nHits          13.1990        NaN     NaN      NaN\nHmRun        -60.8834        NaN     NaN      NaN\nRuns           0.6875        NaN     NaN      NaN\nRBI           10.3993        NaN     NaN      NaN\nWalks          7.0114        NaN     NaN      NaN\nYears         -2.3702        NaN     NaN      NaN\nCAtBat         0.2643        NaN     NaN      NaN\nCHits         -1.7919        NaN     NaN      NaN\nCHmRun         5.3897        NaN     NaN      NaN\nCRuns          4.0162        NaN     NaN      NaN\nCRBI          -4.0134        NaN     NaN      NaN\nCWalks         1.5822        NaN     NaN      NaN\nLeagueN      233.6380        NaN     NaN      NaN\nDivisionW    299.1771        NaN     NaN      NaN\nPutOuts       -0.1250        NaN     NaN      NaN\nAssists       -0.8539        NaN     NaN      NaN\nErrors             NA         NA      NA       NA\nNewLeagueN         NA         NA      NA       NA\n\nResidual standard error: NaN on 0 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:    NaN \nF-statistic:   NaN on 17 and 0 DF,  p-value: NA\n\n\n\nQuelques conclusions sur le modèle :\n\n\nOn peut clairement constater que ce modèle brut ne fonctionne pas avec pourtant un \\(R^2 = 1\\). On retrouve donc le problème typique de l’analyse en grande dimension lorsque \\(p&gt;n\\) et qu’on ne peut pas trouver d’estimateur de regression linéaire.\n\nOn peut aussi s’amuser à regarder les critères AIC et BIC de ce modèles qui se retrouve à tendre vers l’infini.\n\nAIC(mod1)\n\n[1] -Inf\n\nBIC(mod1)\n\n[1] -Inf\n\n\n\nPrediction\nOn va maintenant tenter de prédire la variable Salary pour les autres joueurs.\nDéjà on peut regarder sur les 18 joueurs si la prédiction via le modèle nous donne des bonnes valeur. Et ce que l’on constate c’est qu’effectivement nous sommes vers ce qui pourrait nous faire penser que le modèle est bien ajusté.\n\nSalary_hat &lt;- predict(mod1, Hitters_Without_NA_18)\nSalary &lt;- Hitters_Without_NA_18$Salary\n\nround(mean(Salary_hat - Salary ), 2)\n\n[1] 0\n\n\nPourtant si nous regardons la prédiction obtenue par le modèle pour les autres joueurs et que nous effctuons la comparaison, nous voyons bien l’inéfficacité du modèle.\n\nHitters_Without_NA_No18 &lt;- Hitters_Without_NA[19:nrow(Hitters_Without_NA),]\nSalary_hat_No18 &lt;- predict(mod1, Hitters_Without_NA_No18)\nSalary_No18 &lt;- Hitters_Without_NA_No18$Salary\nsummary(Salary_hat_No18 - Salary_No18 )\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-2363.67  -424.10   -49.12   -70.88   294.40  2648.41"
  },
  {
    "objectID": "posts/Exercice_2.html#modèles-parcimonieux",
    "href": "posts/Exercice_2.html#modèles-parcimonieux",
    "title": "Exercice 2",
    "section": "Modèles parcimonieux",
    "text": "Modèles parcimonieux\nOn va maintenant mettre un oeuvre une méthode de sélection automatique classique pour réduire le nombre de variable explicative et tenter d’éviter les problèmes de grande dimension.\nPour cela nous allons donc partir du plus petit modèle (celui avec seulement l’intercept) puis faire grandir le nombre de variable. Il av donc s’agir d’une méthode de sélection automatique forward.\n\nmod0 &lt;- lm(Salary~1, Hitters_Without_NA_18)\nmod_forw &lt;- step(mod0,\n                 scope = formula(mod1),\n                 trace = FALSE,\n                 direction = c(\"forward\"))\nmod_forw %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ CWalks + League, data = Hitters_Without_NA_18)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-215.51  -82.67  -48.10   26.13  302.49 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  259.3539    77.1270   3.363  0.00427 ** \nCWalks         0.9699     0.1606   6.039 2.27e-05 ***\nLeagueN     -137.2850    79.1236  -1.735  0.10322    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 160.8 on 15 degrees of freedom\nMultiple R-squared:  0.7495,    Adjusted R-squared:  0.7161 \nF-statistic: 22.44 on 2 and 15 DF,  p-value: 3.095e-05\n\n\nNous obtenons maintenant un modèle avec 2 variable dont une significative. Puis nous pouvons constater des valeurs assez élevés pour le \\(R^2\\) et \\(R^2_{adjusted}\\).\nRegardons aussi les critères AIC et BIC.\n\nAIC(mod_forw)\n\n[1] 238.6917\n\nBIC(mod_forw)\n\n[1] 242.2531\n\n\nMaintenant, nous allons permuter de façon aléatoire les salaires des 18 joueurs et refaire la même analyse inférentielle. Ainsi, le lien linéaire devrait disparaitre et nous donner de mauvais résultats.\n\nSalary_permute &lt;- sample(Salary)\n\nmod1_permute &lt;- lm(Salary_permute~., Hitters_Without_NA_18)\nmod1_permute %&gt;% summary()\n\n\nCall:\nlm(formula = Salary_permute ~ ., data = Hitters_Without_NA_18)\n\nResiduals:\nALL 18 residuals are 0: no residual degrees of freedom!\n\nCoefficients: (3 not defined because of singularities)\n              Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) -3.084e+03        NaN     NaN      NaN\nAtBat        4.202e+01        NaN     NaN      NaN\nHits        -7.353e+01        NaN     NaN      NaN\nHmRun       -1.133e+02        NaN     NaN      NaN\nRuns        -2.856e+01        NaN     NaN      NaN\nRBI         -3.221e+01        NaN     NaN      NaN\nWalks       -1.019e+01        NaN     NaN      NaN\nYears        7.144e+02        NaN     NaN      NaN\nCAtBat      -1.280e+01        NaN     NaN      NaN\nCHits        2.898e+01        NaN     NaN      NaN\nCHmRun      -4.692e+01        NaN     NaN      NaN\nCRuns        1.219e+01        NaN     NaN      NaN\nCRBI         2.387e+01        NaN     NaN      NaN\nCWalks      -1.128e+00        NaN     NaN      NaN\nLeagueN     -1.696e+02        NaN     NaN      NaN\nDivisionW   -4.636e+02        NaN     NaN      NaN\nPutOuts     -1.405e-02        NaN     NaN      NaN\nAssists     -3.897e+00        NaN     NaN      NaN\nErrors              NA         NA      NA       NA\nSalary              NA         NA      NA       NA\nNewLeagueN          NA         NA      NA       NA\n\nResidual standard error: NaN on 0 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:    NaN \nF-statistic:   NaN on 17 and 0 DF,  p-value: NA\n\n\nA nouveau on peut constater l’inéfficacité d’un modèle avec toutes les variables du fait d’avoir \\(p&gt;n\\).\nUtilisons maintenant la sélection automatique.\n\nmod0_permute &lt;- lm(Salary_permute~1, Hitters_Without_NA_18)\nmod_forw_permute &lt;- step(mod0_permute, \n                         scope = formula(mod1_permute),\n                         trace = FALSE,\n                         direction = c(\"forward\"))\nmod_forw_permute %&gt;% summary()\n\n\nCall:\nlm(formula = Salary_permute ~ Walks, data = Hitters_Without_NA_18)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-372.42 -194.78  -25.54  204.02  526.92 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  611.293    133.714   4.572 0.000314 ***\nWalks         -5.458      3.107  -1.757 0.098022 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 284.9 on 16 degrees of freedom\nMultiple R-squared:  0.1617,    Adjusted R-squared:  0.1094 \nF-statistic: 3.087 on 1 and 16 DF,  p-value: 0.09802\n\n\nOn retrouve ici un modèle très différent concernant les variables sélectionnés avec de très mauvais résultats de \\(R^2\\) et \\(R^2_{adjusted}\\).\nPour finir, on va maintenant reprendre le jeu de données Hitters complet et permuter tous les salaires de façon aléatoire. Ensuite, on va ajuster le meilleur modèle de régression possible pour expliquer les salaires en fonction des autres variables.\n\nSalary_permute &lt;- sample(Hitters_Without_NA$Salary)\nHitters_Without_NA_And_Salary = Hitters_Without_NA[,-19]\n\nHitters_With_Salary_permute &lt;- cbind(Hitters_Without_NA_And_Salary, Salary_permute)\n\nmod0_permute &lt;- lm(Salary_permute~., Hitters_With_Salary_permute)\nmod1_permute &lt;- lm(Salary_permute~1, Hitters_With_Salary_permute)\n\n\nmod_permute_back &lt;- step(mod1_permute,\n                         scope = formula(mod1_permute),\n                         trace = FALSE,\n                         direction = c(\"backward\"))\nmod_permute_back %&gt;% summary()\n\n\nCall:\nlm(formula = Salary_permute ~ 1, data = Hitters_With_Salary_permute)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-468.4 -345.9 -110.9  214.1 1924.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   535.93      27.82   19.27   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 451.1 on 262 degrees of freedom\n\nmod_permute_forw &lt;- step(mod0_permute,\n                         scope = formula(mod1_permute),\n                         trace = FALSE,\n                         direction = c(\"forward\"))\nmod_permute_forw %&gt;% summary()\n\n\nCall:\nlm(formula = Salary_permute ~ AtBat + Hits + HmRun + Runs + RBI + \n    Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + \n    CWalks + League + Division + PutOuts + Assists + Errors + \n    NewLeague, data = Hitters_With_Salary_permute)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-734.84 -296.04  -93.62  156.00 1790.72 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) 295.1920   127.2997   2.319   0.0212 *\nAtBat         0.7061     0.8890   0.794   0.4278  \nHits          0.9845     3.3340   0.295   0.7680  \nHmRun        11.0696     8.6964   1.273   0.2043  \nRuns         -2.8016     4.1799  -0.670   0.5033  \nRBI          -1.1012     3.6472  -0.302   0.7630  \nWalks         0.4385     2.5641   0.171   0.8644  \nYears       -18.3420    17.4058  -1.054   0.2930  \nCAtBat        0.4730     0.1896   2.494   0.0133 *\nCHits        -1.9294     0.9459  -2.040   0.0425 *\nCHmRun       -4.7194     2.2679  -2.081   0.0385 *\nCRuns         0.5672     1.0524   0.539   0.5904  \nCRBI          1.2618     0.9713   1.299   0.1951  \nCWalks       -0.0762     0.4601  -0.166   0.8686  \nLeagueN      36.0960   111.1491   0.325   0.7456  \nDivisionW   -64.7232    56.6070  -1.143   0.2540  \nPutOuts      -0.1738     0.1086  -1.601   0.1107  \nAssists      -0.1817     0.3102  -0.586   0.5586  \nErrors       -4.6046     6.1584  -0.748   0.4554  \nNewLeagueN   77.2633   110.7863   0.697   0.4862  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 442.5 on 243 degrees of freedom\nMultiple R-squared:  0.1074,    Adjusted R-squared:  0.03766 \nF-statistic:  1.54 on 19 and 243 DF,  p-value: 0.07302\n\nmod_permute_both &lt;- step(mod0_permute,\n                         scope = formula(mod1_permute),\n                         trace = FALSE,\n                         direction = c(\"both\"))\nmod_permute_both %&gt;% summary()\n\n\nCall:\nlm(formula = Salary_permute ~ AtBat + HmRun + CAtBat + CHits + \n    CHmRun + NewLeague, data = Hitters_With_Salary_permute)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-662.0 -292.2 -102.3  184.1 1816.6 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) 188.2631    91.6800   2.053  0.04104 * \nAtBat         0.3942     0.2363   1.668  0.09654 . \nHmRun         7.6350     4.7013   1.624  0.10560   \nCAtBat        0.3538     0.1286   2.751  0.00636 **\nCHits        -1.0641     0.4389  -2.424  0.01603 * \nCHmRun       -1.7479     0.7005  -2.495  0.01322 * \nNewLeagueN  105.7343    55.4987   1.905  0.05788 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 438.2 on 256 degrees of freedom\nMultiple R-squared:  0.07803,   Adjusted R-squared:  0.05642 \nF-statistic: 3.611 on 6 and 256 DF,  p-value: 0.001867\n\n\nOn constate de très mauvais résultats de \\(R^2\\) et \\(R^2_{adjusted}\\) et au final la seule variable qui semble vraiment significative est l’intercept ce qui montre bien qu’avec la permutation aléatoire de la variable Salary, le lien linéaire qui existait à disparu."
  }
]