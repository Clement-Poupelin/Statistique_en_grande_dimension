[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/Exercice_09.html",
    "href": "posts/Exercice_09.html",
    "title": "Exercice 9",
    "section": "",
    "text": "On souhaite réaliser une petite étude par simulation pour évaluer les qualités respectives de 4 méthodes d’estimation d’un modèle de régression linéaire. On s’intéresse pour chacune d’elle à ses qualités de sélection de variables et à ses qualités prédictives. Le programme SimusReg.R permet de réaliser cette étude. Il contient deux fonctions, Simudata et la fonction principale fun, et un exemple d’utilisation en fin de programme.\n\n\nShow the code\nn = 100\np = 500\nX = matrix(rnorm(n*p), n, p)\n\n\n\n\nShow the code\nlibrary(lars)\n\n\nLoaded lars 1.3\n\n\n\nAttachement du package : 'lars'\n\n\nL'objet suivant est masqué depuis 'package:psych':\n\n    error.bars\n\n\nShow the code\nlibrary(leaps)\nlibrary(glmnet)\n\n\nLe chargement a nécessité le package : Matrix\n\n\nLoaded glmnet 4.1-8\n\n\nShow the code\nDataSimulation = function(n,p){\n  if(p &lt; 4){stop(\"p&gt;3 require\")}\n  # We create our matrix of explanatory variables\n  X = matrix(rnorm(n*p), n, p)\n  \n  # We define our coefficients of regression \n  coeff = matrix(0, p)\n  coeff[1:3] = 2\n  \n  # We build our explanatory variables\n  y = X%*%coeff + rnorm(n, sd = 2)\n  return(list(X = X, y = y, coeff = coeff))\n}\n\n\n\nfun = function(n, p, M = 100){ # By default, we make M = 100 simulation \n  \n  ## Initialization \n  #################\n  selec_method1 = NULL; selec_method2 = NULL; selec_method3 = NULL;\n  taille_method1 = NULL; taille_method2 = NULL; taille_method3 = NULL;\n  prev_method1 = NULL; prev_method2 = NULL; prev_method3 = NULL; prev_method4 = NULL;\n  temps1 = NULL; temps2 = NULL; temps3 = NULL; temps4 = NULL;\n  \n  for(i in 1:M){\n    cat(paste(i, \":\")) # counter to see progress\n    \n    # We define our train set\n    datatrain = DataSimulation(n, p)\n    Xtrain = datatrain$X\n    y = datatrain$y\n    coeff = datatrain$coeff\n    \n    # We define our test set\n    datatest = DataSimulation(n, p)\n    Xtest = datatest$X\n    ytest = datatest$y\n    \n    \n    ## Regression \n    #################\n    \n    # Method 1 : Forward-Hybrid with BIC\n    tic = proc.time()\n    tab = data.frame(y = y, X = Xtrain)\n    fit0 = lm(y~1, tab)\n    fit = lm(y~., tab)\n    tmp = step(fit0, scope = formula(fit),\n               k = log(n), # BIC criteria\n               direction = \"both\", # Hybrid\n               trace = 0)\n    noms = sort(names(tmp$model))\n    selec_method1[i] = identical(\n      noms[-length(noms)], sort(paste(\"X.\", which(coeff != 0), sep = \"\"))\n      )\n    taille_method1[i] = length(noms) - 1\n    prev_method1[i] = mean((predict(tmp,data.frame(X = Xtest)) - ytest)^2)\n    tac = proc.time() - tic\n    temps1[i] = tac[3]\n    \n    # Method 2 : Lasso\n    tic = proc.time()\n    cvglm = cv.glmnet(Xtrain, y) # By default we have Lasso\n    lambda = cvglm$lambda.min\n    coef2 = coef(cvglm, s = lambda)[-1]\n    index = which(coef2 != 0) \n    selec_method2[i] = identical(sort(index), which(coeff != 0))\n    taille_method2[i] = length(index)\n    prev_method2[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n    tac = proc.time() - tic\n    temps2[i] = tac[3]\n    \n    # Methods 3 and 4 : Adaptive Lasso and  Gauss-Lasso  \n    if(length(index) == 0){\n      selec_method3[i] = selec_method2[i]\n      taille_method3[i] = taille_method2[i]\n      prev_method3[i] = prev_method2[i]\n      prev_method4[i] = prev_method2[i]}\n    else{\n      # Adaptive Lasso part\n      cvglm = cv.glmnet(Xtrain, y,\n                        penalty.factor = 1/abs(coef2))\n      lambda = cvglm$lambda.min\n      coef3 = coef(cvglm, s = lambda)[-1]\n      index = which(coef3 != 0) \n      selec_method3[i] = identical(sort(index), which(coeff != 0))\n      taille_method3[i] = length(index)\n      prev_method3[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n      tac = proc.time() - tic\n      temps3[i] = tac[3]\n      \n      # Gauss-Lasso part\n      if(length(index) == 0){\n        prev_method4[i] = mean((mean(y) - ytest)^2)}\n      else{\n        tab = data.frame(y = y, X = Xtrain)\n        reg = lm(y~., \n                 data = tab[, c(1, index + 1)])\n        prev_method4[i] = mean((predict(reg, data.frame(X = Xtest)) - ytest)^2)\n        tac = proc.time() - tic\n        temps4[i] = tac[3]\n      }\n    }\n  }\n  \n  ## Results\n  #################\n  res = list(mean(selec_method1), mean(selec_method2), mean(selec_method3), taille_method1, taille_method2, taille_method3, prev_method1, prev_method2, prev_method3, prev_method4, mean(temps1), mean(temps2), mean(temps3), mean(temps4))\n  \n  names(res) = c(\"selec_method1\", \"selec_method2\", \"selec_method3\", \"taille_method1\", \"taille_method2\", \"taille_method3\", \"prev_method1\", \"prev_method2\", \"prev_method3\", \"prev_method4\", \"temps1\", \"temps2\", \"temps3\", \"temps4\")\n  \n  return(res)\n}\n\nfun2 = function(n, p, M = 100){ # By default, we make M = 100 simulation \n  \n  ## Initialization \n  #################\n  selec_method1 = NULL; selec_method2 = NULL; selec_method3 = NULL;\n  taille_method1 = NULL; taille_method2 = NULL; taille_method3 = NULL;\n  prev_method1 = NULL; prev_method2 = NULL; prev_method3 = NULL; prev_method4 = NULL;\n  temps1 = NULL; temps2 = NULL; temps3 = NULL; temps4 = NULL;\n  \n  for(i in 1:M){\n    cat(paste(i, \":\")) # counter to see progress\n    \n    # We define our train set\n    datatrain = DataSimulation(n, p)\n    Xtrain = datatrain$X\n    y = datatrain$y\n    coeff = datatrain$coeff\n    \n    # We define our test set\n    datatest = DataSimulation(n, p)\n    Xtest = datatest$X\n    ytest = datatest$y\n    \n    \n    ## Regression \n    #################\n    \n    # Method 2 : Lasso\n    tic = proc.time()\n    cvglm = cv.glmnet(Xtrain, y) # By default we have Lasso\n    lambda = cvglm$lambda.min\n    coef2 = coef(cvglm, s = lambda)[-1]\n    index = which(coef2 != 0) \n    selec_method2[i] = identical(sort(index), which(coeff != 0))\n    taille_method2[i] = length(index)\n    prev_method2[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n    tac = proc.time() - tic\n    temps2[i] = tac[3]\n    \n    # Methods 3 and 4 : Adaptive Lasso and  Gauss-Lasso  \n    if(length(index) == 0){\n      selec_method3[i] = selec_method2[i]\n      taille_method3[i] = taille_method2[i]\n      prev_method3[i] = prev_method2[i]\n      prev_method4[i] = prev_method2[i]}\n    else{\n      # Adaptive Lasso part\n      cvglm = cv.glmnet(Xtrain, y,\n                        penalty.factor = 1/abs(coef2))\n      lambda = cvglm$lambda.min\n      coef3 = coef(cvglm, s = lambda)[-1]\n      index = which(coef3 != 0) \n      selec_method3[i] = identical(sort(index), which(coeff != 0))\n      taille_method3[i] = length(index)\n      prev_method3[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n      tac = proc.time() - tic\n      temps3[i] = tac[3]\n      \n      # Gauss-Lasso part\n      if(length(index) == 0){\n        prev_method4[i] = mean((mean(y) - ytest)^2)}\n      else{\n        tab = data.frame(y = y, X = Xtrain)\n        reg = lm(y~., \n                 data = tab[, c(1, index + 1)])\n        prev_method4[i] = mean((predict(reg, data.frame(X = Xtest)) - ytest)^2)\n        tac = proc.time() - tic\n        temps4[i] = tac[3]\n      }\n    }\n  }\n  \n  ## Results\n  #################\n  res = list(mean(selec_method1), mean(selec_method2), mean(selec_method3), taille_method1, taille_method2, taille_method3, prev_method1, prev_method2, prev_method3, prev_method4, mean(temps1), mean(temps2), mean(temps3), mean(temps4))\n  \n  names(res) = c(\"selec_method1\", \"selec_method2\", \"selec_method3\", \"taille_method1\", \"taille_method2\", \"taille_method3\", \"prev_method1\", \"prev_method2\", \"prev_method3\", \"prev_method4\", \"temps1\", \"temps2\", \"temps3\", \"temps4\")\n  \n  return(res)\n}\n\n\n\n\nShow the code\n###### Exemple\na=fun(50,5,100)\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\n\n\nShow the code\na$selec_method1\n\n\n[1] 0.9\n\n\nShow the code\na$selec_method2\n\n\n[1] 0.16\n\n\nShow the code\na$selec_method3\n\n\n[1] 0.7\n\n\nShow the code\na$taille_method1\n\n\n  [1] 3 3 4 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3\n [38] 3 3 4 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 4 3 3 3 3 3\n [75] 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 4 3 3\n\n\nShow the code\na$taille_method2\n\n\n  [1] 5 5 5 4 4 5 3 5 3 5 5 5 5 4 4 4 3 4 4 4 5 4 3 4 5 5 4 4 3 5 5 4 4 4 5 4 4\n [38] 5 4 5 5 5 5 4 5 5 4 4 5 3 5 4 5 5 5 3 3 4 5 4 4 5 4 3 5 4 5 3 5 4 4 4 5 5\n [75] 5 3 4 5 3 4 5 5 5 5 5 5 5 5 3 3 5 5 3 4 5 5 4 4 3 5\n\n\nShow the code\na$taille_method3\n\n\n  [1] 3 3 5 3 3 5 3 3 3 3 3 3 5 3 3 3 3 3 4 3 3 3 3 3 5 3 3 3 3 4 5 4 3 3 4 3 3\n [38] 4 3 4 3 3 3 3 5 5 3 3 3 3 3 4 3 4 3 3 3 3 5 3 4 4 3 3 4 3 3 3 4 4 3 3 3 4\n [75] 4 3 3 4 3 3 3 5 3 4 3 3 4 3 3 3 5 4 3 3 3 3 3 4 3 3\n\n\nShow the code\nboxplot(sqrt(a$prev_method1),sqrt(a$prev_method2),sqrt(a$prev_method3),sqrt(a$prev_method4),names=c(\"Method1\",\"Method2\",\"Method3\",\"Method4\"),main=\"Title\")\n\n\n\n\n\n\n\n\n\nShow the code\nmean(a$prev_method1)\n\n\n[1] 4.317454\n\n\nShow the code\nmean(a$prev_method2)\n\n\n[1] 4.482734\n\n\nShow the code\nmean(a$prev_method3)\n\n\n[1] 4.405399\n\n\nShow the code\nmean(a$prev_method4)\n\n\n[1] 4.397463\n\n\nShow the code\na$temps1\n\n\n[1] 0.01149\n\n\nShow the code\na$temps2\n\n\n[1] 0.02251\n\n\nShow the code\na$temps3\n\n\n[1] 0.04536\n\n\nShow the code\na$temps4\n\n\n[1] 0.04648\n\n\n\nQuestion 1\nQuel modèle génère la fonction Simudata ? Combien de variables explicatives sont générées ? Parmi elles, lesquelles sont pertinentes pour la modélisation ? Ecrire l’équation du modèle.\n\n\nQuestion 2\nIdentifier les 4 méthodes d’estimation mises en oeuvre dans la fonction fun.\n\n\nQuestion 3\nDétailler les différentes sorties proposées par la fonction fun.\n\n\nQuestion 4\nRemplacer la valeur des options names et title du boxplot réalisé dans l’exemple par les bonnes informations.\n\n\nShow the code\nboxplot(sqrt(a$prev_method1),sqrt(a$prev_method2),sqrt(a$prev_method3),sqrt(a$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", 100,\"et p=\", 10),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"),\n        ylim = c(1,3))\n\n\n\n\n\n\n\n\n\n\n\nQuestion 5\nRéaliser une étude comparative des méthodes lorsque \\(n = 50\\) et \\(p = n/10\\), \\(p = n\\), \\(p = 2n\\), \\(p = 10n\\). Pour chaque situation, on considèrera \\(100\\) simulations afin de calculer les différents critères. On synthétisera les résultats en terme de qualité de sélection, nombre de variables sélectionnées, erreurs de prévision et temps de calcul.\n\n\nShow the code\n#parallelisation\nfuture::plan(multisession, workers = 2)\n\nn = 50\np_list = c(n/10, n, 2*n, 10*n)\n\nr_cas1 = fun(n, p_list[1])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nShow the code\nr_cas2 = fun(n, p_list[2])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nShow the code\nr_cas3 = fun(n, p_list[3])\n\n\n1 :2 :\n\n\n3 :\n\n\n4 :\n\n\n5 :\n\n\n6 :\n\n\n7 :\n\n\n8 :\n\n\n9 :\n\n\n10 :\n\n\n11 :\n\n\n12 :\n\n\n13 :14 :15 :\n\n\n16 :17 :\n\n\n18 :\n\n\n19 :\n\n\n20 :21 :\n\n\n22 :23 :\n\n\n24 :25 :\n\n\n26 :\n\n\n27 :28 :\n\n\n29 :\n\n\n30 :\n\n\n31 :\n\n\n32 :\n\n\n33 :\n\n\n34 :\n\n\n35 :\n\n\n36 :\n\n\n37 :\n\n\n38 :\n\n\n39 :\n\n\n40 :\n\n\n41 :\n\n\n42 :\n\n\n43 :\n\n\n44 :\n\n\n45 :\n\n\n46 :47 :\n\n\n48 :\n\n\n49 :50 :\n\n\n51 :\n\n\n52 :\n\n\n53 :54 :\n\n\n55 :\n\n\n56 :57 :\n\n\n58 :\n\n\n59 :\n\n\n60 :\n\n\n61 :\n\n\n62 :63 :\n\n\n64 :\n\n\n65 :\n\n\n66 :\n\n\n67 :\n\n\n68 :69 :\n\n\n70 :\n\n\n71 :\n\n\n72 :\n\n\n73 :74 :\n\n\n75 :76 :\n\n\n77 :78 :79 :80 :\n\n\n81 :\n\n\n82 :\n\n\n83 :\n\n\n84 :\n\n\n85 :\n\n\n86 :\n\n\n87 :\n\n\n88 :\n\n\n89 :\n\n\n90 :\n\n\n91 :\n\n\n92 :93 :\n\n\n94 :\n\n\n95 :\n\n\n96 :97 :\n\n\n98 :99 :\n\n\n100 :\n\n\nShow the code\nr_cas4 = fun(n, p_list[4],1)\n\n\n1 :\n\n\nShow the code\nr_cas4bis = fun2(n, p_list[4])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nShow the code\n# file_path &lt;- file.path(\"../Data/r_cas1.rds\")\n# saveRDS(r_cas1, file = file_path)\n\n# quit parallelisation\nfuture::plan(\"sequential\")\n\n\n\n\nShow the code\n# file_path &lt;- file.path(\"../Data/r_cas1.rds\")\n# r_cas1 &lt;- readRDS(file_path)\n\n\n\n\nShow the code\nres_cas1 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas1$selec_method1,r_cas1$selec_method2,r_cas1$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas1$taille_method1),mean(r_cas1$taille_method2),mean(r_cas1$taille_method3),NA),\n  Prevision_error = c(mean(r_cas1$prev_method1),mean(r_cas1$prev_method2),mean(r_cas1$prev_method3),mean(r_cas1$prev_method4)),\n  Running_time = c(r_cas1$temps1,r_cas1$temps2,r_cas1$temps3,r_cas1$temps4)\n)\nt(res_cas1)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.95\"     \"0.24\"     \"0.76\"             NA           \nMean_nb_selected_var \"3.05\"     \"4.19\"     \"3.29\"             NA           \nPrevision_error      \"4.267999\" \"4.372448\" \"4.311278\"         \"4.298561\"   \nRunning_time         \"0.01006\"  \"0.02122\"  \"0.04285\"          \"0.04382\"    \n\n\nShow the code\nboxplot(sqrt(r_cas1$prev_method1),sqrt(r_cas1$prev_method2),sqrt(r_cas1$prev_method3),sqrt(r_cas1$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[1]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres_cas2 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas2$selec_method1,r_cas2$selec_method2,r_cas2$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas2$taille_method1),mean(r_cas2$taille_method2),mean(r_cas2$taille_method3),NA),\n  Prevision_error = c(mean(r_cas2$prev_method1),mean(r_cas2$prev_method2),mean(r_cas2$prev_method3),mean(r_cas2$prev_method4)),\n  Running_time = c(r_cas2$temps1,r_cas2$temps2,r_cas2$temps3,r_cas2$temps4)\n)\nt(res_cas2)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.06\"     \"0.01\"     \"0.09\"             NA           \nMean_nb_selected_var \" 7.92\"    \"12.88\"    \" 8.17\"            NA           \nPrevision_error      \"7.050225\" \"5.609938\" \"5.487207\"         \"6.401796\"   \nRunning_time         \"0.07149\"  \"0.04010\"  \"0.06590\"          \"0.06738\"    \n\n\nShow the code\nboxplot(sqrt(r_cas2$prev_method1),sqrt(r_cas2$prev_method2),sqrt(r_cas2$prev_method3),sqrt(r_cas2$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[2]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres_cas3 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas3$selec_method1,r_cas3$selec_method2,r_cas3$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas3$taille_method1),mean(r_cas3$taille_method2),mean(r_cas3$taille_method3),NA),\n  Prevision_error = c(mean(r_cas3$prev_method1),mean(r_cas3$prev_method2),mean(r_cas3$prev_method3),mean(r_cas3$prev_method4)),\n  Running_time = c(r_cas3$temps1,r_cas3$temps2,r_cas3$temps3,r_cas3$temps4)\n)\nt(res_cas3)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.00\"      \"0.00\"      \"0.06\"             NA           \nMean_nb_selected_var \"40.57\"     \"15.80\"     \" 9.09\"            NA           \nPrevision_error      \"16.207790\" \" 6.138163\" \" 5.738140\"        \" 6.723044\"  \nRunning_time         \"0.71804\"   \"0.04013\"   \"0.06882\"          \"0.07045\"    \n\n\nShow the code\nboxplot(sqrt(r_cas3$prev_method1),sqrt(r_cas3$prev_method2),sqrt(r_cas3$prev_method3),sqrt(r_cas3$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres_cas4 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4$selec_method1,r_cas4$selec_method2,r_cas4$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4$taille_method1),mean(r_cas4$taille_method2),mean(r_cas4$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4$prev_method1),mean(r_cas4$prev_method2),mean(r_cas4$prev_method3),mean(r_cas4$prev_method4)),\n  Running_time = c(r_cas4$temps1,r_cas4$temps2,r_cas4$temps3,r_cas4$temps4)\n)\nt(res_cas4)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \" 0\"        \" 0\"        \" 0\"               NA           \nMean_nb_selected_var \"49\"        \"41\"        \"19\"               NA           \nPrevision_error      \"11.762266\" \" 4.734249\" \" 4.562205\"        \" 5.403622\"  \nRunning_time         \"6.500\"     \"0.041\"     \"0.077\"            \"0.080\"      \n\n\nShow the code\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4$prev_method2),sqrt(r_cas4$prev_method3),sqrt(r_cas4$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres_cas4bis = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4bis$selec_method1,r_cas4bis$selec_method2,r_cas4bis$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4bis$taille_method1),mean(r_cas4bis$taille_method2),mean(r_cas4bis$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4bis$prev_method1),mean(r_cas4bis$prev_method2),mean(r_cas4bis$prev_method3),mean(r_cas4bis$prev_method4)),\n  Running_time = c(r_cas4bis$temps1,r_cas4bis$temps2,r_cas4bis$temps3,r_cas4bis$temps4)\n)\n\n\nWarning in mean.default(r_cas4bis$taille_method1): l'argument n'est ni\nnumérique, ni logique : renvoi de NA\n\n\nWarning in mean.default(r_cas4bis$prev_method1): l'argument n'est ni numérique,\nni logique : renvoi de NA\n\n\nShow the code\nt(res_cas4bis)\n\n\n                     [,1]      [,2]       [,3]               [,4]         \nMethod               \"Forward\" \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection NA        \"0.00\"     \"0.04\"             NA           \nMean_nb_selected_var NA        \"24.87\"    \"12.34\"            NA           \nPrevision_error      NA        \"7.230664\" \"6.781834\"         \"7.861071\"   \nRunning_time         NA        \"0.04820\"  \"0.08404\"          \"0.08697\"    \n\n\nShow the code\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4bis$prev_method2),sqrt(r_cas4bis$prev_method3),sqrt(r_cas4bis$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[4]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nQuestion 6\nRéaliser la même étude pour \\(n = 100\\) et \\(p = n/10\\), \\(p = n\\), \\(p = 2n\\), toujours basée sur \\(100\\) simulations dans chaque cas. Considérer de plus le cas \\(p = 10n\\) en ne faisant qu’une seule simulation afin d’en évaluer le temps de calcul. Une fois ce temps analysé, lancer \\(100\\) simulations pour \\(p = 10n\\) mais en omettant la méthode la plus couteuse en temps de calcul.\n\n\nShow the code\n#parallelisation\nfuture::plan(multisession, workers = 2)\n\nn = 100\np_list = c(n/10, n, 2*n, 10*n)\n\nr_cas1 = fun(n, p_list[1])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nShow the code\nr_cas2 = fun(n, p_list[2])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nShow the code\nr_cas3 = fun(n, p_list[3])\n\n\n1 :\n\n\n2 :3 :4 :5 :6 :\n\n\n7 :8 :9 :\n\n\n10 :11 :\n\n\n12 :\n\n\n13 :14 :15 :16 :17 :18 :\n\n\n19 :20 :\n\n\n21 :\n\n\n22 :23 :24 :25 :\n\n\n26 :27 :\n\n\n28 :29 :30 :\n\n\n31 :\n\n\n32 :33 :34 :\n\n\n35 :\n\n\n36 :37 :38 :39 :\n\n\n40 :41 :42 :43 :\n\n\n44 :\n\n\n45 :46 :47 :\n\n\n48 :\n\n\n49 :\n\n\n50 :51 :52 :\n\n\n53 :54 :55 :56 :\n\n\n57 :58 :\n\n\n59 :\n\n\n60 :61 :\n\n\n62 :63 :\n\n\n64 :\n\n\n65 :66 :\n\n\n67 :68 :\n\n\n69 :\n\n\n70 :71 :72 :73 :74 :\n\n\n75 :\n\n\n76 :77 :78 :\n\n\n79 :80 :81 :82 :83 :\n\n\n84 :85 :86 :87 :88 :89 :90 :\n\n\n91 :\n\n\n92 :93 :\n\n\n94 :\n\n\n95 :96 :97 :98 :\n\n\n99 :100 :\n\n\nShow the code\nr_cas4 = fun(n, p_list[4],1)\n\n\n1 :\n\n\nShow the code\nr_cas4bis = fun2(n, p_list[4])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nShow the code\n# quit parallelisation\nfuture::plan(\"sequential\")\n\n\n\n\nShow the code\nres_cas1 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas1$selec_method1,r_cas1$selec_method2,r_cas1$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas1$taille_method1),mean(r_cas1$taille_method2),mean(r_cas1$taille_method3),NA),\n  Prevision_error = c(mean(r_cas1$prev_method1),mean(r_cas1$prev_method2),mean(r_cas1$prev_method3),mean(r_cas1$prev_method4)),\n  Running_time = c(r_cas1$temps1,r_cas1$temps2,r_cas1$temps3,r_cas1$temps4)\n)\nt(res_cas1)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.71\"     \"0.08\"     \"0.42\"             NA           \nMean_nb_selected_var \"3.30\"     \"6.35\"     \"4.15\"             NA           \nPrevision_error      \"4.270127\" \"4.367182\" \"4.300236\"         \"4.347811\"   \nRunning_time         \"0.01367\"  \"0.02255\"  \"0.04586\"          \"0.04690\"    \n\n\nShow the code\nboxplot(sqrt(r_cas1$prev_method1),sqrt(r_cas1$prev_method2),sqrt(r_cas1$prev_method3),sqrt(r_cas1$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[1]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres_cas2 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas2$selec_method1,r_cas2$selec_method2,r_cas2$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas2$taille_method1),mean(r_cas2$taille_method2),mean(r_cas2$taille_method3),NA),\n  Prevision_error = c(mean(r_cas2$prev_method1),mean(r_cas2$prev_method2),mean(r_cas2$prev_method3),mean(r_cas2$prev_method4)),\n  Running_time = c(r_cas2$temps1,r_cas2$temps2,r_cas2$temps3,r_cas2$temps4)\n)\nt(res_cas2)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.01\"     \"0.01\"     \"0.10\"             NA           \nMean_nb_selected_var \" 8.11\"    \"14.59\"    \" 7.61\"            NA           \nPrevision_error      \"5.682778\" \"4.824673\" \"4.588443\"         \"5.223387\"   \nRunning_time         \"0.13837\"  \"0.06476\"  \"0.09358\"          \"0.09517\"    \n\n\nShow the code\nboxplot(sqrt(r_cas2$prev_method1),sqrt(r_cas2$prev_method2),sqrt(r_cas2$prev_method3),sqrt(r_cas2$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[2]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres_cas3 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas3$selec_method1,r_cas3$selec_method2,r_cas3$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas3$taille_method1),mean(r_cas3$taille_method2),mean(r_cas3$taille_method3),NA),\n  Prevision_error = c(mean(r_cas3$prev_method1),mean(r_cas3$prev_method2),mean(r_cas3$prev_method3),mean(r_cas3$prev_method4)),\n  Running_time = c(r_cas3$temps1,r_cas3$temps2,r_cas3$temps3,r_cas3$temps4)\n)\nt(res_cas3)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.00\"      \"0.01\"      \"0.16\"             NA           \nMean_nb_selected_var \"48.66\"     \"17.34\"     \" 7.73\"            NA           \nPrevision_error      \"11.428807\" \" 5.016189\" \" 4.523595\"        \" 5.243494\"  \nRunning_time         \"2.67996\"   \"0.06936\"   \"0.10052\"          \"0.10242\"    \n\n\nShow the code\nboxplot(sqrt(r_cas3$prev_method1),sqrt(r_cas3$prev_method2),sqrt(r_cas3$prev_method3),sqrt(r_cas3$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nres_cas4 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4$selec_method1,r_cas4$selec_method2,r_cas4$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4$taille_method1),mean(r_cas4$taille_method2),mean(r_cas4$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4$prev_method1),mean(r_cas4$prev_method2),mean(r_cas4$prev_method3),mean(r_cas4$prev_method4)),\n  Running_time = c(r_cas4$temps1,r_cas4$temps2,r_cas4$temps3,r_cas4$temps4)\n)\nt(res_cas4)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \" 0\"        \" 0\"        \" 0\"               NA           \nMean_nb_selected_var \"99\"        \"11\"        \" 6\"               NA           \nPrevision_error      \"11.946047\" \" 5.699005\" \" 4.413508\"        \" 5.439750\"  \nRunning_time         \"61.347\"    \" 0.088\"    \" 0.129\"           \" 0.133\"     \n\n\nShow the code\nres_cas4bis = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4bis$selec_method1,r_cas4bis$selec_method2,r_cas4bis$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4bis$taille_method1),mean(r_cas4bis$taille_method2),mean(r_cas4bis$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4bis$prev_method1),mean(r_cas4bis$prev_method2),mean(r_cas4bis$prev_method3),mean(r_cas4bis$prev_method4)),\n  Running_time = c(r_cas4bis$temps1,r_cas4bis$temps2,r_cas4bis$temps3,r_cas4bis$temps4)\n)\n\n\nWarning in mean.default(r_cas4bis$taille_method1): l'argument n'est ni\nnumérique, ni logique : renvoi de NA\n\n\nWarning in mean.default(r_cas4bis$prev_method1): l'argument n'est ni numérique,\nni logique : renvoi de NA\n\n\nShow the code\nt(res_cas4bis)\n\n\n                     [,1]      [,2]       [,3]               [,4]         \nMethod               \"Forward\" \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection NA        \"0.00\"     \"0.03\"             NA           \nMean_nb_selected_var NA        \"30.92\"    \"11.07\"            NA           \nPrevision_error      NA        \"5.260876\" \"4.776523\"         \"5.836417\"   \nRunning_time         NA        \"0.08522\"  \"0.13196\"          \"0.13632\"    \n\n\nShow the code\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4$prev_method2),sqrt(r_cas4$prev_method3),sqrt(r_cas4$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\nShow the code\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4bis$prev_method2),sqrt(r_cas4bis$prev_method3),sqrt(r_cas4bis$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[4]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\n\n\n\n\nQuestion 7\nConclure sur les mérites respectifs de chaque méthode dans le contexte de l’étude.\n\n\nQuestion 8\nQuelles autres types de simulations pourrait-on envisager pour confirmer ou affiner ces conclusions ?"
  },
  {
    "objectID": "posts/Exercice_03.html",
    "href": "posts/Exercice_03.html",
    "title": "Exercice 03",
    "section": "",
    "text": "Setup\n\nPackagesFonctionsSeed\n\n\n\n\nShow the code\n# Données\nlibrary(dplyr)        # manipulation des données\n\nlibrary(boot) ## CV\n\n\n# Plots\n## ggplot\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n\n\n\n\nboxplotpairs.panelsLOO\n\n\n\n\nShow the code\nmy_boxplot &lt;- function(data) {\n  # Transformer les données en format long pour ggplot\n  data_long &lt;- reshape2::melt(data)\n  \n  ggplot(data_long, aes(x = variable, y = value, fill = variable)) +\n    geom_boxplot() +\n    scale_fill_viridis_d() +  # Palette de couleurs harmonieuse\n    labs(title = \"Distribution des Variables (Boxplot)\", x = \"Variables\", y = \"Valeurs\") +\n    theme_minimal() +  # Thème épuré\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotation des étiquettes\n}\n\n\n\n\n\n\nShow the code\nmy_pairs.panels &lt;- function(data) {\n  psych::pairs.panels(\n    data,\n    method = \"pearson\",\n    # Méthode de corrélation\n    hist.col = RColorBrewer::brewer.pal(9, \"Set3\"),\n    # Couleurs des histogrammes\n    density = TRUE,\n    # Ajout des courbes de densité\n    ellipses = TRUE,\n    # Ajout d'ellipses\n    smooth = TRUE,\n    # Ajout de régressions lissées\n    lm = TRUE,\n    # Ajout des droites de régression\n    col = \"#69b3a2\",\n    # Couleur des points\n    alpha = 0.5              # Transparence\n  )\n}\n\n\n\n\nPremière fonction LOO\n\n\nShow the code\nloo &lt;- function(mod) {\n  n &lt;- nrow(mod$model)\n  Call &lt;- mod$call\n  erreur &lt;- 1:n\n  for (i in 1:n) {\n    Call$data &lt;- mod$model[-i, ] # mod$call$data transforme en data.frame\n    fit &lt;- eval.parent(Call)\n    pred = predict(fit, mod$model[i, ])\n    erreur[i] &lt;- (pred - mod$model[i, 1])^2\n  }\n  return(round(mean(erreur), 3))\n}\n\n\nDeuxième fonction LOO\n\n\nShow the code\nloo2 &lt;- function(mod) {\n  round(mean((residuals(mod) / (1 - hatvalues(mod)))^2), 3)\n}\n\n\nFonction pour obtenir les résultats\n\n\nShow the code\nget_loo_results &lt;- function(model, func) {\n  start_time &lt;- Sys.time()        \n  result &lt;- func(model)          \n  end_time &lt;- Sys.time()         \n  time_taken &lt;- round(end_time - start_time, 3)  \n  \n  return(list(result = result, time = time_taken))\n}\n\n\n\n\n\n\n\n\n\nShow the code\nset.seed(140400)\n\n\n\n\n\n\n\nDonnées\nPour cette exercice, on va générer un modèle de régression linéaire classique :\n\\[y = X\\beta + \\mathcal{E}\\]\n\n\\(y \\in \\mathbb{R}^{n}\\) la variable réponse ou variable à expliquer\n\\(X \\in \\mathbb{R}^{n\\times p}\\) la matrice contenant nos variables explicatives\n\\(\\beta \\in \\mathbb{R}^{p}\\) le vecteur composée des coefficients de régression\n\\(\\mathcal{E} \\in \\mathbb{R}^{n}\\) le vecteur d’erreur suivant une loi \\(\\mathcal{N}(0, 1)\\)\n\nPour la génération de nos données, nous allons alors poser que \\(\\beta = (1, -2)'\\) et \\(X = [x, x^2]\\), \\(x \\in \\mathbb{R}^n\\) suivant une loi \\(\\mathcal{N}(0,1)\\).\nOn aura alors que \\(y = x - 2x^2 + \\mathcal{E}\\).\n\n\nShow the code\nx &lt;- rnorm(1000)\ny &lt;- x - 2*(x^2) + rnorm(1000)\nSimu_data &lt;- data.frame(y = y, x = x)\n\n\n\n\n\n\n\n\nNote\n\n\n\npour des raisons de repouctibilité, une graine ou seed a été défini dans le setup afin que la génération aléatoire reste identique.\n\n\nOn va ainsi supposer avoir observé les deux vecteurs \\(x\\) et \\(y\\) précédents, sans connaître le lien théorique précédent qui lie \\(x\\) et \\(y\\).\nEt donc on cherchera à estimer ce lien.\n\n\nAnalyse descriptive\n\nBoxplotCorrelation panel\n\n\nOn peut regarder un peu la distribution de nos différents variables quantitatives via des boxplots.\n\n\nShow the code\nmy_boxplot(Simu_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn voit bien que notre variable \\(x\\) a une distribution normale centré réduite mais quelle n’est pas non plus parfaitement symétrique (forcément entre la “perfection” de la théorie et la génération par ordinateur il y a toujours une légère différence).\nEt concernant \\(y\\), de manière logique avec le modèle simulé, on peut voir d’avantages de valeurs négatives.\n\n\n\nOn regarde ici la corrélation calculée entre chacune de nos variables.\n\n\nShow the code\nmy_pairs.panels(Simu_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nTout d’abord, on peut remarquer une corrélation faible de 34% entre \\(x\\) et \\(y\\). Pourtant le nuage de point semble quand à lui témoigner d’une influence de \\(x\\) sur \\(y\\) pouvant justifier d’un lien linéaire.\nAussi on retrouve un belle histogramme de distibution \\(\\mathcal{N}(0, 1)\\) pour notre variable \\(x\\).\n\n\n\n\n\n\nAnalyse inférentielle\nMaintenant, on va ajuster différents modèles à tester :\n\nmod1 : \\(y = \\beta_0 + \\beta_1x + \\mathcal{E}\\)\nmod2 : \\(y = \\beta_0 + \\beta_1x + \\beta_2x^2 + \\mathcal{E}\\)\nmod3 : \\(y = \\beta_0 + \\beta_1x + \\beta_2x^2 + \\beta_3x^3 + \\mathcal{E}\\)\nmod4 : \\(y = \\beta_0 + \\beta_1x + \\beta_2x^2 + \\beta_3x^3 + \\beta_4x^4 + \\mathcal{E}\\)\n\nOn va donc commencer par compléter notre data frame avec des variables correspondant à \\(x^2\\), \\(x^3\\) et \\(x^4\\). Puis nous pourrons ajuster les différents modèles.\n\n\nShow the code\nSimu_data_complete &lt;- cbind(Simu_data, x^2, x^3, x^4)\ncolnames(Simu_data_complete) &lt;- c(\"y\", \"x1\", \"x2\", \"x3\", \"x4\")\n\n\n\n\nShow the code\nmod1 &lt;- lm(y ~ x1, Simu_data_complete)\nmod2 &lt;- lm(y ~ x1 + x2, Simu_data_complete)\nmod3 &lt;- lm(y ~ x1 + x2 + x3, Simu_data_complete)\nmod4 &lt;- lm(y ~ x1 + x2 + x3 + x4, Simu_data_complete)\n\n\n\n\n\n\n\n\nNote\n\n\n\nThéoriquement, on est dans une situation où le \\(R^2\\) pour le modèle 1 est égale à la corrélation de pearson au carré de \\(x\\) et \\(y\\).\n\n\\(R^2 =\\) 0.116\n\\(\\rho^2 =\\) 0.116\n\n\n\nEnsuite, partir du summary() et de différentes fonctions R, on est capable capable d’obtenir différents critères permettant de comparer la qualité de nos modèles.\n\n\nShow the code\nmodels &lt;- list(mod1, mod2, mod3, mod4)\nmodel_names &lt;- c(\"mod1\", \"mod2\", \"mod3\", \"mod4\")\n\nresults &lt;- data.frame(\n  Model = model_names,\n  R2 = unlist(lapply(models, function(m) round(summary(m)$r.squared, 3))),\n  R2adj = unlist(lapply(models, function(m) round(summary(m)$adj.r.squared, 3))),\n  AIC = unlist(lapply(models, function(m) round(AIC(m), 1))),\n  BIC = unlist(lapply(models, function(m) round(BIC(m), 1)))\n)\n\n\nresults %&gt;% DT::datatable()\n\n\n\n\n\n\nOn peut voir ici que c’est mod2 qui ressort comme étant le meilleur modèle avec de forte valeur de \\(R^2\\) et \\(R^2_{adjusted}\\) puis des critères AIC et BIC minimisés.\n\n\nShow the code\nmod2 %&gt;% summary()\n\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = Simu_data_complete)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1117 -0.7078 -0.0106  0.6605  3.3936 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.03778    0.03820   0.989    0.323    \nx1           1.02939    0.03105  33.151   &lt;2e-16 ***\nx2          -2.01737    0.02107 -95.725   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.995 on 997 degrees of freedom\nMultiple R-squared:  0.9133,    Adjusted R-squared:  0.9131 \nF-statistic:  5248 on 2 and 997 DF,  p-value: &lt; 2.2e-16\n\n\nOn constate en plus avec le summary() que toutes nos variables sont significatives sauf l’intercept.\n\n\nValidation croisée\n\nRappel validation croiséeValidation “manuelle”Library boot\n\n\nLe principe de la validation croisée (cross validation) est d’estimer le risque de prédiction en confrontant notre modèle à un échantillon test qui n’a pas été utilisé pour l’ajustement de celui ci.\nLa validation croisée possède ainsi de nombreux avantages mais a comme principal inconvénient son temps de calcul qui peut rapidement devenir important.\n\nDans le cas du K-fold, on coupe l’échantillon de taille \\(n\\) en environ K parties égales. Ensuite, on fait l’ajustement du modèle sur K-1 échantillons et on garde le K-ième comme échantillon test pour calculer l’erreur de prédiction. On répète alors le procédé de telle sorte à ce que chaque échantillon serve une fois de test. Cela nous fait donc calculer K erreurs.\nA savoir que selon la valeur de K, on peut se retrouver dans des cas particuliers très utilisés.\n\nLorsque K = n, il s’agit de la procédure Leave One Out (LOO).\nLorsque K = 2, on est sur une procédure Hold out ou testset\n\nLa validation croisée par K-fold est donc un outil couramment utilisé. Le choix de K est quant à lui très important et il faut penser que si K est trop grand, le biais sera faible mais à contrario, la variance deviendra très grande. Par contre, si K est trop petit, l’estimation risque de posséder un grand biais puisque notre taille d’échantillon test sera beaucoup plus grande que celle de l’échantillon d’apprentissage. On a donc ici un bel exemple de compromis entre biais et variance pour trouver le K le plus judicieux.\n\n\nDans un premier temps et pour bien comprendre la méthode, on va utiliser deux fonctions (construite pour l’occasion et dont le code se trouve dans la partie fonction du Setup) permettant d’estimer l’erreur test par une validation croisée LOO (Leave-one-out) pour un modèle ajusté par la fonction lm :\n\nla première, loo, en utilisant le principe général de cette méthode qui nécessite donc l’estimation de n modèles différents\nla seconde, loo2, en utilisant la formule adaptée à la régression linéaire donnant directement le risque LOO à partir de la seule estimation du modèle complet (on pourra utiliser la fonction hatvalues)\n\nAinsi, en testant sur nos quatre modèle, on obtient les résultats suivants :\n\n\nShow the code\nloo_results &lt;- lapply(models, function(m) get_loo_results(m, loo))\nloo2_results &lt;- lapply(models, function(m) get_loo_results(m, loo2))\n\nresults &lt;- data.frame(\n  Model = model_names,\n  LOO = unlist(lapply(loo_results, function(x) x$result)),       \n  Time_LOO = unlist(lapply(loo_results, function(x) x$time)),    \n  LOO2 = unlist(lapply(loo2_results, function(x) x$result)),     \n  Time_LOO2 = unlist(lapply(loo2_results, function(x) x$time))   \n)\n\nresults %&gt;% DT::datatable()\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn voit que les résultats donnés par nos deux fonctions coincident bien. Mais la première semble tout de même plus lente pour le calcul.\nEt en terme de qualité de modèle, c’est bien mod2 qui minimise l’erreur de la cross validation par loo.\n\n\n\nOn va donc maintenant utiliser la fonction cv.glm de la library { boot } permettant d’estimer l’erreur test par validation croisée K-fold. Cela va nécessité de recalculer le modèle mais cette fois ci avec la fonction glm en spécifiant que l’on veut un modèle gaussien (ce qui nous donnera le même résultat qu’avec lm).\n\n\n\n\n\n\nNote\n\n\n\nOn spécifi ici dans glm que le modèle est gaussien mais dans la pratique ce n’est pas nécéssaire pusiqu’il s’agit de la valeur par défaut de la fonction.\n\n\nDe plus, nous utiliserons \\(K=10\\) qui est une valeurs assez communément utilisé sachant que si on voulait reproduire la procédure LOO il faudrait utiliser \\(K=n\\) (cf rappel).\n\n\nShow the code\nmod1_glm &lt;- glm(formula = formula(mod1) ,\n                family = gaussian,\n                data = Simu_data_complete)\nmod2_glm &lt;- glm(formula = formula(mod2) ,\n                family = gaussian,\n                data = Simu_data_complete)\nmod3_glm &lt;- glm(formula = formula(mod3) ,\n                family = gaussian,\n                data = Simu_data_complete)\nmod4_glm &lt;- glm(formula = formula(mod4) ,\n                family = gaussian,\n                data = Simu_data_complete)\n\n\ncvmod1 &lt;- cv.glm(data = Simu_data_complete, glmfit = mod1_glm, K = 10)\ncvmod2 &lt;- cv.glm(data = Simu_data_complete, glmfit = mod2_glm, K = 10)\ncvmod3 &lt;- cv.glm(data = Simu_data_complete, glmfit = mod3_glm, K = 10)\ncvmod4 &lt;- cv.glm(data = Simu_data_complete, glmfit = mod4_glm, K = 10) \n\nresults &lt;- data.frame(\n  Model = model_names,\n  CV_Mean = round( c(mean(cvmod1$delta), mean(cvmod2$delta), mean(cvmod3$delta), mean(cvmod4$delta)), 3),\n  LOO2 = c(loo2(mod1), loo2(mod2), loo2(mod3), loo2(mod4))\n)\n\n\nresults %&gt;% DT::datatable()\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn voit qu’en moyenne cv.glm nous donne des résultats qui sont du même ordre de grandeur que notre fonction loo2.\nEt en terme de qualité de modèle, c’est bien mod2 qui minimise l’erreur de la cross validation.\n\n\n\n\n\n\nAjustement du meilleur modèle\nD’après tout ce que l’on a pu voir durant cette étude, jusqu’à présent le meilleur modèle semble être mod2.\n\n\nShow the code\nmod2 %&gt;% summary()\n\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = Simu_data_complete)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1117 -0.7078 -0.0106  0.6605  3.3936 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.03778    0.03820   0.989    0.323    \nx1           1.02939    0.03105  33.151   &lt;2e-16 ***\nx2          -2.01737    0.02107 -95.725   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.995 on 997 degrees of freedom\nMultiple R-squared:  0.9133,    Adjusted R-squared:  0.9131 \nF-statistic:  5248 on 2 and 997 DF,  p-value: &lt; 2.2e-16\n\n\nDe manière naturelle, l’intercept ne semblant pas significatif il conviendrait de tester sans.\nAinsi nous allons essayer le modèle \\(y \\sim x + x^2\\).\n\n\nShow the code\nmod2_without_intercept &lt;- lm(y ~ 0 + x1 + x2, Simu_data_complete)\nmod2_without_intercept %&gt;% summary()\n\n\n\nCall:\nlm(formula = y ~ 0 + x1 + x2, data = Simu_data_complete)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0785 -0.6834  0.0212  0.6855  3.4288 \n\nCoefficients:\n   Estimate Std. Error t value Pr(&gt;|t|)    \nx1  1.02988    0.03105   33.17   &lt;2e-16 ***\nx2 -2.00555    0.01736 -115.54   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.995 on 998 degrees of freedom\nMultiple R-squared:  0.9364,    Adjusted R-squared:  0.9363 \nF-statistic:  7352 on 2 and 998 DF,  p-value: &lt; 2.2e-16\n\n\nOn voit un modèle avec de très bon résultats et qui à toutes ces variables significatives. Comparons le avec mod2 :\n\n\nShow the code\nmodels &lt;- list(mod2, mod2_without_intercept)\nmodel_names &lt;- c(\"mod2\", \"mod2_without_intercept\")\n\nresults &lt;- data.frame(\n  Model = model_names,\n  R2 = unlist(lapply(models, function(m)\n    round(summary(m)$r.squared, 3))),\n  R2adj = unlist(lapply(models, function(m)\n    round(summary(m)$adj.r.squared, 3))),\n  AIC = unlist(lapply(models, function(m)\n    round(AIC(\n      m\n    ), 1))),\n  BIC = unlist(lapply(models, function(m)\n    round(BIC(\n      m\n    ), 1))),\n  LOO2 = c(loo2(mod2), loo2(mod2_without_intercept)),\n  CV_Mean = round(c(\n    mean(cv.glm(\n      data = Simu_data_complete,\n      glmfit = glm(\n        formula = formula(mod2),\n        data = Simu_data_complete\n      ),\n      K = 10\n    )$delta), mean(cv.glm(\n      data = Simu_data_complete,\n      glmfit = glm(\n        formula = formula(mod2_without_intercept),\n        data = Simu_data_complete\n      ),\n      K = 10\n    )$delta)\n  ), 3)\n)\n\n\nresults %&gt;% DT::datatable()\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn voit bien avec tout nos critère qu’enlever l’intercept à apporté une amélioration à notre modèle.\nAinsi, si l’on se base sur les résultat de ce nouveau modèle, on obtient la relation linéaire suivante :\n\n\\(y =\\) 1.03\\(x\\) + -2.006\\(x^2 + \\mathcal{E}\\)\n\nAlors que pour rappel, on a le lien linéaire théorique qui est:\n\n\\(y = x - 2x^2 + \\mathcal{E}\\).\n\nDonc je pense que l’on peut dire sans prendre trop de risques que notre estimation et notre méthode de sélection est bonne.\n\n\n\nConclusion\nOn voit qu’on a bien réussi à retrouver le lien théorique via le test de pluseurs modèle et l’utilisation de plusieurs critères couplés à de la validation croisée pour affiner notre recherche du modèle le mieux ajusté.\nAinsi, il est important d’avancer étape par étape car ici chaques étapes était importante pour trouver le meilleur modèle. Et ici on se basait sur un modèle généré par nous même et possédant un lien linéaire bien défini ce qui nous permettait tout de même si bien orienter nos recherche. La réalité nous offre souvent des situations plus compliquées et tout ces outils deviennent donc cruciaux pour bien avancer.\n\n\nSession info\n\n\nShow the code\nsessioninfo::session_info(pkgs = \"attached\")\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       Ubuntu 24.04.1 LTS\n system   x86_64, linux-gnu\n ui       X11\n language (EN)\n collate  fr_FR.UTF-8\n ctype    fr_FR.UTF-8\n tz       Europe/Paris\n date     2025-02-21\n pandoc   3.2 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/x86_64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package   * version date (UTC) lib source\n boot      * 1.3-31  2024-08-28 [4] CRAN (R 4.3.3)\n dplyr     * 1.1.4   2023-11-17 [1] CRAN (R 4.4.2)\n ggplot2   * 3.5.1   2024-04-23 [1] CRAN (R 4.4.2)\n gridExtra * 2.3     2017-09-09 [1] CRAN (R 4.4.2)\n\n [1] /home/clement/R/x86_64-pc-linux-gnu-library/4.4\n [2] /usr/local/lib/R/site-library\n [3] /usr/lib/R/site-library\n [4] /usr/lib/R/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/Exercice_02.html",
    "href": "posts/Exercice_02.html",
    "title": "Exercice 02",
    "section": "",
    "text": "Clément Poupelin, clementjc.poupelin@gmail.com"
  },
  {
    "objectID": "posts/Exercice_02.html#modèle-brut",
    "href": "posts/Exercice_02.html#modèle-brut",
    "title": "Exercice 02",
    "section": "Modèle brut",
    "text": "Modèle brut\nOn désire modéliser le salaire Salary en fonction des variables disponibles.\nOn va donc ajuster un modèle de régression linéaire en utilisant toutes les variables à disposition et analyser la qualité de cet ajustement.\n\n\nShow the code\nmod1 &lt;- lm(formula = Salary ~ .,\n           Hitters_Without_NA_18) \nmod1 %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ ., data = Hitters_Without_NA_18)\n\nResiduals:\nALL 18 residuals are 0: no residual degrees of freedom!\n\nCoefficients: (2 not defined because of singularities)\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) -223.7909        NaN     NaN      NaN\nAtBat         -3.2428        NaN     NaN      NaN\nHits          13.1990        NaN     NaN      NaN\nHmRun        -60.8834        NaN     NaN      NaN\nRuns           0.6875        NaN     NaN      NaN\nRBI           10.3993        NaN     NaN      NaN\nWalks          7.0114        NaN     NaN      NaN\nYears         -2.3702        NaN     NaN      NaN\nCAtBat         0.2643        NaN     NaN      NaN\nCHits         -1.7919        NaN     NaN      NaN\nCHmRun         5.3897        NaN     NaN      NaN\nCRuns          4.0162        NaN     NaN      NaN\nCRBI          -4.0134        NaN     NaN      NaN\nCWalks         1.5822        NaN     NaN      NaN\nLeagueN      233.6380        NaN     NaN      NaN\nDivisionW    299.1771        NaN     NaN      NaN\nPutOuts       -0.1250        NaN     NaN      NaN\nAssists       -0.8539        NaN     NaN      NaN\nErrors             NA         NA      NA       NA\nNewLeagueN         NA         NA      NA       NA\n\nResidual standard error: NaN on 0 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:    NaN \nF-statistic:   NaN on 17 and 0 DF,  p-value: NA\n\n\n\n\n\n\nRésultats\n\n\nOn peut clairement constater que ce modèle brut ne fonctionne pas avec pourtant un \\(R^2 = 1\\). On retrouve donc le problème typique de l’analyse en grande dimension lorsque \\(p&gt;n\\) (fléau de la dimensionalité).\n\nOn peut aussi s’amuser à regarder les critères AIC et BIC de ce modèles qui théoriquement se retrouve à tendre vers l’infini.\n\n\nShow the code\ncat( \"AIC = \", AIC(mod1), \"et BIC = \", BIC(mod1))\n\n\nAIC =  -Inf et BIC =  -Inf\n\n\n\nPrediction\nOn va maintenant tenter de prédire la variable Salary pour les autres joueurs.\nDéjà on peut regarder sur les 18 joueurs si la prédiction via le modèle nous donne des bonnes valeur.\n\n\nShow the code\nSalary_hat &lt;- predict(mod1, Hitters_Without_NA_18)\nSalary &lt;- Hitters_Without_NA_18$Salary\n\n\n\n\\(\\widehat{Salary^{(1:18)}} - Salary^{(1:18)} =\\) 0\n\nCe que l’on constate c’est qu’effectivement nous sommes avec un résultat qui pourrait nous faire penser que le modèle est bien ajusté avec une prédiction quasiment égale à la variable à prédire.\nPourtant si nous regardons la prédiction obtenue par le modèle pour les autres joueurs et que nous effectuons la même soustraction pour comparer la qualité de prediction, nous voyons bien l’inéfficacité du modèle.\n\n\nShow the code\nHitters_Without_NA_No18 &lt;- Hitters_Without_NA[19:nrow(Hitters_Without_NA),]\nSalary_hat_No18 &lt;- predict(mod1, Hitters_Without_NA_No18)\nSalary_No18 &lt;- Hitters_Without_NA_No18$Salary\n\n\n\n\\(\\widehat{Salary^{(\\neg 1:18)}} - Salary^{(\\neg 1:18)} =\\) -70.88\n\nEn effet on voit bien au dessus que les valeurs ne sont en moyennes pas proche de 0."
  },
  {
    "objectID": "posts/Exercice_02.html#modèles-parcimonieux",
    "href": "posts/Exercice_02.html#modèles-parcimonieux",
    "title": "Exercice 02",
    "section": "Modèles parcimonieux",
    "text": "Modèles parcimonieux\nOn va maintenant mettre un oeuvre une méthode de sélection automatique classique pour réduire le nombre de variable explicative et tenter d’éviter les problèmes de grande dimension.\nPour cela nous allons donc partir du plus petit modèle (celui avec seulement l’intercept) puis faire grandir le nombre de variable. Il va donc s’agir d’une méthode de sélection automatique forward.\n\n\nShow the code\nmod0 &lt;- lm(Salary~1, Hitters_Without_NA_18)\nmod_forw &lt;- step(mod0,\n                 scope = formula(mod1),\n                 trace = FALSE,\n                 direction = c(\"forward\"))\nmod_forw %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ CWalks + League, data = Hitters_Without_NA_18)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-215.51  -82.67  -48.10   26.13  302.49 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  259.3539    77.1270   3.363  0.00427 ** \nCWalks         0.9699     0.1606   6.039 2.27e-05 ***\nLeagueN     -137.2850    79.1236  -1.735  0.10322    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 160.8 on 15 degrees of freedom\nMultiple R-squared:  0.7495,    Adjusted R-squared:  0.7161 \nF-statistic: 22.44 on 2 and 15 DF,  p-value: 3.095e-05\n\n\n\n\n\n\nRésultats\n\n\nNous obtenons maintenant un modèle avec 2 variable dont une significative. Puis nous pouvons constater des valeurs assez élevés pour le \\(R^2\\) et \\(R^2_{adjusted}\\).\nEt on a AIC = 238.692 et BIC = 242.253.\nDonc sans aller tester si c’est un bon modèle prédictif, on constate déjà qu’il va s’agir d’un modèle descriptif fonctionnel avec \\(n&lt;p\\)"
  },
  {
    "objectID": "posts/Exercice_01.html",
    "href": "posts/Exercice_01.html",
    "title": "Exercice 01",
    "section": "",
    "text": "Clément Poupelin, clementjc.poupelin@gmail.com"
  },
  {
    "objectID": "posts/Exercice_01.html#modèle-brut",
    "href": "posts/Exercice_01.html#modèle-brut",
    "title": "Exercice 01",
    "section": "Modèle brut",
    "text": "Modèle brut\nOn désire modéliser le salaire Salary en fonction des variables disponibles.\nOn va donc ajuster un modèle de régression linéaire en utilisant toutes les variables à disposition et analyser la qualité de cet ajustement.\n\n\nShow the code\nmod1 &lt;- lm(formula = Salary ~ .,\n           Hitters_Without_NA) \nmod1 %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ ., data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-907.62 -178.35  -31.11  139.09 1877.04 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  163.10359   90.77854   1.797 0.073622 .  \nAtBat         -1.97987    0.63398  -3.123 0.002008 ** \nHits           7.50077    2.37753   3.155 0.001808 ** \nHmRun          4.33088    6.20145   0.698 0.485616    \nRuns          -2.37621    2.98076  -0.797 0.426122    \nRBI           -1.04496    2.60088  -0.402 0.688204    \nWalks          6.23129    1.82850   3.408 0.000766 ***\nYears         -3.48905   12.41219  -0.281 0.778874    \nCAtBat        -0.17134    0.13524  -1.267 0.206380    \nCHits          0.13399    0.67455   0.199 0.842713    \nCHmRun        -0.17286    1.61724  -0.107 0.914967    \nCRuns          1.45430    0.75046   1.938 0.053795 .  \nCRBI           0.80771    0.69262   1.166 0.244691    \nCWalks        -0.81157    0.32808  -2.474 0.014057 *  \nLeagueN       62.59942   79.26140   0.790 0.430424    \nDivisionW   -116.84925   40.36695  -2.895 0.004141 ** \nPutOuts        0.28189    0.07744   3.640 0.000333 ***\nAssists        0.37107    0.22120   1.678 0.094723 .  \nErrors        -3.36076    4.39163  -0.765 0.444857    \nNewLeagueN   -24.76233   79.00263  -0.313 0.754218    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 315.6 on 243 degrees of freedom\nMultiple R-squared:  0.5461,    Adjusted R-squared:  0.5106 \nF-statistic: 15.39 on 19 and 243 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNote\n\n\n\nNous sommes sur un modèle comprenant des variables quantitatives et qualitative ce qui le rapproche d’une modélisation ANOVA.\n\n\n\n\n\n\nRésultats\n\n\nCe qu’on peut remarquer en premier sur ce modèle c’est que beaucoup de variables ont un effet non significatif.\nAussi, ce modèle offre des valeurs de \\(R^2\\) et \\(R^2_{adjusted}\\) autour de 0.5 ce qui témoigne d’une mauvaise qualité d’ajustament du modèle\nEt enfin, l’écart type résiduel est de 315.6 ce qui est assez important et témoigne d’un modèle peu précis\n\nPour tenter de trouver un meilleur ajustment, il est important d’analyser d’avantage le lien entre toutes les variables explicatives. On utilise alors comunément le VIF (variance inflation factor).\nOn obtient alors pour chacune de nos variable une valeur qui, plus elle est élevé, témoigne de la multicolinéarité entre nos variables explicatives.\n\n\nShow the code\nvif(mod1) \n\n\n     AtBat       Hits      HmRun       Runs        RBI      Walks      Years \n 22.944366  30.281255   7.758668  15.246418  11.921715   4.148712   9.313280 \n    CAtBat      CHits     CHmRun      CRuns       CRBI     CWalks     League \n251.561160 502.954289  46.488462 162.520810 131.965858  19.744105   4.134115 \n  Division    PutOuts    Assists     Errors  NewLeague \n  1.075398   1.236317   2.709341   2.214543   4.099063 \n\n\nShow the code\nmy_VIFplot(vif(mod1))\n\n\n\n\n\n\n\n\n\nOn remarque ainsi que beaucoup de valeurs sont supérieur à 10 ce qui s’interprète communément comme la précence d’une forte colinéarité sur nos variables explicatives.\n\n\n\n\n\n\nNote\n\n\n\nCette colinéarité se constatait déjà durant les analyses descriptive via les graphes de corrélations (d’où l’importance de ne pas se lancer trop rapidement dans les analyses inférentielles)."
  },
  {
    "objectID": "posts/Exercice_01.html#modèles-parcimonieux",
    "href": "posts/Exercice_01.html#modèles-parcimonieux",
    "title": "Exercice 01",
    "section": "Modèles parcimonieux",
    "text": "Modèles parcimonieux\nMaintenant, on va donc tenter de trouver le meilleur sous-modèle possible. Pour cela on va suivre la procédure suivante :\n\nmettre en oeuvre une méthode de sélection automatique exhaustive et observer l’évolution des SCR (Sommes de Carrés Résiduels) pour les modèles retenus en fonction de leur taille.\ndéduire de ces SCR le \\(R^2\\), \\(R^2_{adjusted}\\), AIC, BIC et \\(C_p\\) correspondants. Les comparer avec les valeurs fournies dans le summary de regsubsets et tracer leur évolution en fonction de la taille du modèle.\n\nPuis reproduire la même procédure avec des séléctions backward, forward et stepwise\nTout d’abord, on va définir un nouveau modèle simple ne comprenant que l’intercept.\n\n\nShow the code\nmod0 &lt;- lm(Salary~1,\n           Hitters_Without_NA)\nsummary(mod0)$call\n\n\nlm(formula = Salary ~ 1, data = Hitters_Without_NA)\n\n\nLe principe de ces méthodes de régression avec sélection de variables est de tester et comparer les différents modèles possibles avec nos variables en allant du modèle le plus simple \\(y \\sim 1\\) jusqu’au modèle le plus complet \\(y \\sim .\\) ou l’inverse. Puis à chaque étape de rajout ou de suppression d’une variable dans le modèles, on sélectionne le meilleur modèle via le critère de notre choix.\n\n\n\n\n\n\nNote\n\n\n\nUn rappel sur nos critère se trouve dans la partie Setup, onglet Fonction, de ce document avec la création de fonction pour les calculer.\n\n\n\nExhaustiveBackwardForwardStepwise\n\n\n\nModèleEvolution des critèresMeilleur modèle\n\n\n\n\nShow the code\nselec_auto &lt;- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"exhaustive\",\n                         nvmax = 19 # maximum size of subsets to examine\n                         )\n# selec_auto %&gt;% summary()\n\n\nOn va déjà commencer par regarder la valeur du critère en fonction des variables des différents modèles testés.\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(selec_auto, scale = 'bic') \nplot(selec_auto, scale = 'Cp') \nplot(selec_auto, scale = 'r2') \nplot(selec_auto, scale = 'adjr2') \n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nIci on remarque clairement que toutes nos variables ne sont pas gardés lorsque l’on cherche à optimiser nos critères.\nAussi, on peut voir encore de faibles valeurs pour les \\(R^2\\) et \\(R^2_{adjusted}\\) pouvant témoignés d’un mauvais ajustement de modèle.\n\n\n\n\n\n\n\nNote\n\n\n\nplot.regsubsets de {leaps} ne prend pas directement “aic” comme option de scale. Pour une sélection basée sur AIC, une approche alternative consiste à utiliser la fonction stepAIC du package {MASS}, qui permet une sélection pas à pas basée sur AIC.\n\n\n\n\nRegardons un peut l’évolution de la Somme des Carrés Résiduels (SCR).\n\n\nShow the code\nSCR &lt;- summary(selec_auto)$rss\nCriteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\")\n\n\n\n\n\n\n\n\n\nMaintenant regardons les autres critères mentionné précédemment\n\n\nShow the code\nr2 &lt;- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a &lt;- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp &lt;- cp_fun(mod1, SCR)\naic &lt;- aic_fun(SCR)\nbic &lt;- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n\n\n\n\n\n\n\n\n\nOn peut ainsi voir que ce sont plutot des modèles entre 5 et 10 variables qui optimisent nos critères (donc pas un modèle avec toutes nos variables).\n\n\n\n\n\n\nRésultats\n\n\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\n\nShow the code\ncriteria_df &lt;- data.frame(r2, r2a, cp, aic, bic)\nBest_model(selec_auto, criteria_df)\n\n\nMeilleur modèle selon r2  =  0.546  : Modèle avec 19 variables\n (Intercept) AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN \n \nMeilleur modèle selon r2a  =  0.523  : Modèle avec 11 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists \n \nMeilleur modèle selon cp  =  5.009  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon aic  =  3031.258  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon bic  =  3065.851  : Modèle avec 6 variables\n (Intercept) AtBat Hits Walks CRBI DivisionW PutOuts \n \n\n\n\n\n\n\n\n\nCette fois ci on va regarder en sélection backward. D’abord, on fait à nouveau avec la fonction regsubset.\n\nModèleEvolution des critèresMeilleur modèle\n\n\n\n\nShow the code\nselec_back &lt;- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"backward\",\n                         nvmax = 19)\n\n\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(selec_back, scale = 'bic') \nplot(selec_back, scale = 'Cp') \nplot(selec_back, scale = 'r2') \nplot(selec_back, scale = 'adjr2') \n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn remarque à nouveau une importante sélection de variables.\nMais ici aussi on a encore de faibles valeurs pour les \\(R^2\\) et \\(R^2_{adjusted}\\) pouvant témoignés d’un mauvais ajustement de modèle.\n\n\n\n\n\nShow the code\nSCR &lt;- summary(selec_back)$rss\nr2 &lt;- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a &lt;- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp &lt;- cp_fun(mod1, SCR)\naic &lt;- aic_fun(SCR)\nbic &lt;- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\n\nShow the code\ncriteria_df &lt;- data.frame(r2, r2a, cp, aic, bic)\nBest_model(selec_back, criteria_df)\n\n\nMeilleur modèle selon r2  =  0.546  : Modèle avec 19 variables\n (Intercept) AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN \n \nMeilleur modèle selon r2a  =  0.523  : Modèle avec 11 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists \n \nMeilleur modèle selon cp  =  5.009  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon aic  =  3031.258  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon bic  =  3066.386  : Modèle avec 8 variables\n (Intercept) AtBat Hits Walks CRuns CRBI CWalks DivisionW PutOuts \n \n\n\n\n\n\n\n\nUtilisation de la fonction step\n\nOn peut également utiliser la fonction step de la library {stats}. Pour cela, on part du plus gros modèle défini précédemment par mod1.\nLa fonction step nous propose quel critère nous voulons utiliser pour la sélection entre le BIC, AIC et \\(C_p\\).\n\nBICAIC\\(C_p\\)\n\n\n\n\nShow the code\nn &lt;- nrow(Hitters_Without_NA)\nmodselect_back_bic &lt;- step(mod1,\n                       scope = formula(mod1),\n                       trace = FALSE, # trace = TRUE permet de voir le détail des étapes\n                       direction = c(\"backward\"),\n                       k = log(n) # BIC selection\n                       )\n\n\nPuis on peut regarder le modèle qui optimise le critère utilisé pour la selection.\n\n\nShow the code\nmodselect_back_bic %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CRuns + CRBI + CWalks + \n    Division + PutOuts, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-794.06 -171.94  -28.48  133.36 2017.83 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  117.15204   65.07016   1.800 0.072985 .  \nAtBat         -2.03392    0.52282  -3.890 0.000128 ***\nHits           6.85491    1.65215   4.149 4.56e-05 ***\nWalks          6.44066    1.52212   4.231 3.25e-05 ***\nCRuns          0.70454    0.24869   2.833 0.004981 ** \nCRBI           0.52732    0.18861   2.796 0.005572 ** \nCWalks        -0.80661    0.26395  -3.056 0.002483 ** \nDivisionW   -123.77984   39.28749  -3.151 0.001824 ** \nPutOuts        0.27539    0.07431   3.706 0.000259 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 314.7 on 254 degrees of freedom\nMultiple R-squared:  0.5281,    Adjusted R-squared:  0.5133 \nF-statistic: 35.54 on 8 and 254 DF,  p-value: &lt; 2.2e-16\n\n\nLa fonction step propose aussi une selection avec AIC et Cp.\n\n\n\n\nShow the code\nmodselect_back_aic &lt;- step(mod1,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"backward\"),\n                       k = 2 # AIC selection\n                       )\n\nmodselect_back_aic %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + \n    CRBI + CWalks + Division + PutOuts + Assists, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-939.11 -176.87  -34.08  130.90 1910.55 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  162.53544   66.90784   2.429 0.015830 *  \nAtBat         -2.16865    0.53630  -4.044 7.00e-05 ***\nHits           6.91802    1.64665   4.201 3.69e-05 ***\nWalks          5.77322    1.58483   3.643 0.000327 ***\nCAtBat        -0.13008    0.05550  -2.344 0.019858 *  \nCRuns          1.40825    0.39040   3.607 0.000373 ***\nCRBI           0.77431    0.20961   3.694 0.000271 ***\nCWalks        -0.83083    0.26359  -3.152 0.001818 ** \nDivisionW   -112.38006   39.21438  -2.866 0.004511 ** \nPutOuts        0.29737    0.07444   3.995 8.50e-05 ***\nAssists        0.28317    0.15766   1.796 0.073673 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.8 on 252 degrees of freedom\nMultiple R-squared:  0.5405,    Adjusted R-squared:  0.5223 \nF-statistic: 29.64 on 10 and 252 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nShow the code\nmodselect_back_cp &lt;- step(mod1,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"backward\"),\n                       k = 1 # Cp selection\n                       )\n\nmodselect_back_cp %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + \n    CRBI + CWalks + League + Division + PutOuts + Assists, data = Hitters_Without_NA)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-932.2 -175.4  -29.2  130.4 1897.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  135.75122   71.34623   1.903 0.058223 .  \nAtBat         -2.12775    0.53746  -3.959 9.81e-05 ***\nHits           6.92370    1.64612   4.206 3.62e-05 ***\nWalks          5.62028    1.59064   3.533 0.000488 ***\nCAtBat        -0.13899    0.05609  -2.478 0.013870 *  \nCRuns          1.45533    0.39270   3.706 0.000259 ***\nCRBI           0.78525    0.20978   3.743 0.000225 ***\nCWalks        -0.82286    0.26361  -3.121 0.002010 ** \nLeagueN       43.11162   39.96612   1.079 0.281755    \nDivisionW   -111.14603   39.21835  -2.834 0.004970 ** \nPutOuts        0.28941    0.07478   3.870 0.000139 ***\nAssists        0.26883    0.15816   1.700 0.090430 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 251 degrees of freedom\nMultiple R-squared:  0.5426,    Adjusted R-squared:  0.5226 \nF-statistic: 27.07 on 11 and 251 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nAvec la fonction step nous avons le modèle utilisant le critère BIC qui nous permet d’avoir toutes nos variables significatives (sauf l’intercept ce qui pourrait nous donner envie de faire des modèles sans).\nPar contre, nos valeurs de \\(R^2\\) et \\(R^2_{adjusted}\\) sont encore assez faible pour considérer ces modèles comme étant de très bonne qualité.\n\n\n\n\n\n\n\nNote\n\n\n\nAussi, si on veut comparer le modèle initial et le modèle final, on peut utiliser la fonction anova. Cela permet de voir si la sélection de variables a significativement amélioré l’ajustement.\n\n\nShow the code\nanova(mod0, modselect_back_bic, test = \"Chisq\")\n\n\nAnalysis of Variance Table\n\nModel 1: Salary ~ 1\nModel 2: Salary ~ AtBat + Hits + Walks + CRuns + CRBI + CWalks + Division + \n    PutOuts\n  Res.Df      RSS Df Sum of Sq  Pr(&gt;Chi)    \n1    262 53319113                           \n2    254 25159234  8  28159879 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDe manière logique on voit donc tout de même que le modèle avec nos variable explicatives sélectionnées (ici celui avec selection via le critère BIC) propose un meilleur ajustement que celui sans variable.\n\n\n\n\n\nCette fois ci on va regarder en sélection forward. D’abord, on fait à nouveau avec la fonction regsubset.\n\nModèleEvolution des critèresMeilleur modèle\n\n\n\n\nShow the code\nselec_forw &lt;- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"forward\",\n                         nvmax = 19)\n\n\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(selec_forw, scale = 'bic') \nplot(selec_forw, scale = 'Cp') \nplot(selec_forw, scale = 'r2') \nplot(selec_forw, scale = 'adjr2') \n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn remarque à nouveau une importante sélection de variables.\nMais ici aussi on a encore de faibles valeurs pour les \\(R^2\\) et \\(R^2_{adjusted}\\) pouvant témoignés d’un mauvais ajustement de modèle.\n\n\n\n\n\nShow the code\nSCR &lt;- summary(selec_forw)$rss\nr2 &lt;- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a &lt;- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp &lt;- cp_fun(mod1, SCR)\naic &lt;- aic_fun(SCR)\nbic &lt;- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\n\nShow the code\ncriteria_df &lt;- data.frame(r2, r2a, cp, aic, bic)\nBest_model(selec_forw, criteria_df)\n\n\nMeilleur modèle selon r2  =  0.546  : Modèle avec 19 variables\n (Intercept) AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN \n \nMeilleur modèle selon r2a  =  0.523  : Modèle avec 11 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists \n \nMeilleur modèle selon cp  =  5.009  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon aic  =  3031.258  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon bic  =  3065.851  : Modèle avec 6 variables\n (Intercept) AtBat Hits Walks CRBI DivisionW PutOuts \n \n\n\n\n\n\n\n\nUtilisation de la fonction step\n\nOn peut également utiliser la fonction step de la library {stats}. Cette fois ci il faut définir en modèle de départ le plus petit modèle (celui composé seulement de l’intercept).\nLa fonction step nous propose quel critère nous voulons utiliser pour la sélection entre le BIC, AIC et \\(C_p\\).\n\nBICAIC\\(C_p\\)\n\n\n\n\nShow the code\nmodselect_forw_bic &lt;- step(mod0,\n                       scope = formula(mod1),\n                       trace = FALSE, # trace = TRUE permet de voir le détail des étapes\n                       direction = c(\"forward\"),\n                       k = log(n) # BIC selection\n                       )\n\n\nPuis on peut regarder le modèle qui optimise le critère utilisé pour la selection.\n\n\nShow the code\nmodselect_forw_bic %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-873.11 -181.72  -25.91  141.77 2040.47 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   91.51180   65.00006   1.408 0.160382    \nCRBI           0.64302    0.06443   9.979  &lt; 2e-16 ***\nHits           7.60440    1.66254   4.574 7.46e-06 ***\nPutOuts        0.26431    0.07477   3.535 0.000484 ***\nDivisionW   -122.95153   39.82029  -3.088 0.002239 ** \nAtBat         -1.86859    0.52742  -3.543 0.000470 ***\nWalks          3.69765    1.21036   3.055 0.002488 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 319.9 on 256 degrees of freedom\nMultiple R-squared:  0.5087,    Adjusted R-squared:  0.4972 \nF-statistic: 44.18 on 6 and 256 DF,  p-value: &lt; 2.2e-16\n\n\nLa fonction step propose aussi une selection avec AIC et Cp.\n\n\n\n\nShow the code\nmodselect_forw_aic &lt;- step(mod0,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"forward\"),\n                       k = 2 # AIC selection\n                       )\n\nmodselect_forw_aic %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-939.11 -176.87  -34.08  130.90 1910.55 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  162.53544   66.90784   2.429 0.015830 *  \nCRBI           0.77431    0.20961   3.694 0.000271 ***\nHits           6.91802    1.64665   4.201 3.69e-05 ***\nPutOuts        0.29737    0.07444   3.995 8.50e-05 ***\nDivisionW   -112.38006   39.21438  -2.866 0.004511 ** \nAtBat         -2.16865    0.53630  -4.044 7.00e-05 ***\nWalks          5.77322    1.58483   3.643 0.000327 ***\nCWalks        -0.83083    0.26359  -3.152 0.001818 ** \nCRuns          1.40825    0.39040   3.607 0.000373 ***\nCAtBat        -0.13008    0.05550  -2.344 0.019858 *  \nAssists        0.28317    0.15766   1.796 0.073673 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.8 on 252 degrees of freedom\nMultiple R-squared:  0.5405,    Adjusted R-squared:  0.5223 \nF-statistic: 29.64 on 10 and 252 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nShow the code\nmodselect_forw_cp &lt;- step(mod0,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"forward\"),\n                       k = 1 # Cp selection\n                       )\n\nmodselect_forw_cp %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists + League, data = Hitters_Without_NA)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-932.2 -175.4  -29.2  130.4 1897.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  135.75122   71.34623   1.903 0.058223 .  \nCRBI           0.78525    0.20978   3.743 0.000225 ***\nHits           6.92370    1.64612   4.206 3.62e-05 ***\nPutOuts        0.28941    0.07478   3.870 0.000139 ***\nDivisionW   -111.14603   39.21835  -2.834 0.004970 ** \nAtBat         -2.12775    0.53746  -3.959 9.81e-05 ***\nWalks          5.62028    1.59064   3.533 0.000488 ***\nCWalks        -0.82286    0.26361  -3.121 0.002010 ** \nCRuns          1.45533    0.39270   3.706 0.000259 ***\nCAtBat        -0.13899    0.05609  -2.478 0.013870 *  \nAssists        0.26883    0.15816   1.700 0.090430 .  \nLeagueN       43.11162   39.96612   1.079 0.281755    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 251 degrees of freedom\nMultiple R-squared:  0.5426,    Adjusted R-squared:  0.5226 \nF-statistic: 27.07 on 11 and 251 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nAvec la fonction step nous avons le modèle utilisant le critère BIC qui nous permet d’avoir toutes nos variables significatives (sauf l’intercept ce qui pourrait nous donner envie de faire des modèles sans).\nPar contre, nos valeurs de \\(R^2\\) et \\(R^2_{adjusted}\\) sont encore assez faible pour considérer ces modèles comme étant de très bonne qualité.\n\n\n\n\n\n\n\nNote\n\n\n\nAussi, si on veut comparer le modèle initial et le modèle final, on peut utiliser la fonction anova. Cela permet de voir si la sélection de variables a significativement amélioré l’ajustement.\n\n\nShow the code\nanova(mod0, modselect_forw_bic, test = \"Chisq\")\n\n\nAnalysis of Variance Table\n\nModel 1: Salary ~ 1\nModel 2: Salary ~ CRBI + Hits + PutOuts + Division + AtBat + Walks\n  Res.Df      RSS Df Sum of Sq  Pr(&gt;Chi)    \n1    262 53319113                           \n2    256 26194904  6  27124209 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDe manière logique on voit donc tout de même que le modèle avec nos variable explicatives sélectionnées (ici celui avec selection via le critère BIC) propose un meilleur ajustement que celui sans variable.\n\n\n\n\n\nMaintenant on va regarder en sélection stepwise. D’abord, on fait à nouveau avec la fonction regsubset.\n\nModèleEvolution des critèresMeilleur modèle\n\n\n\n\nShow the code\nselec_seq &lt;- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"seqrep\",\n                         nvmax = 19)\n\n\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(selec_seq, scale = 'bic') \nplot(selec_seq, scale = 'Cp') \nplot(selec_seq, scale = 'r2') \nplot(selec_seq, scale = 'adjr2') \n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn remarque à nouveau une importante sélection de variables.\nMais ici aussi on a encore de faibles valeurs pour les \\(R^2\\) et \\(R^2_{adjusted}\\) pouvant témoignés d’un mauvais ajustement de modèle.\n\n\n\n\n\nShow the code\nSCR &lt;- summary(selec_seq)$rss\nr2 &lt;- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a &lt;- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp &lt;- cp_fun(mod1, SCR)\naic &lt;- aic_fun(SCR)\nbic &lt;- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\n\nShow the code\ncriteria_df &lt;- data.frame(r2, r2a, cp, aic, bic)\nBest_model(selec_seq, criteria_df)\n\n\nMeilleur modèle selon r2  =  0.546  : Modèle avec 19 variables\n (Intercept) AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN \n \nMeilleur modèle selon r2a  =  0.523  : Modèle avec 11 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists \n \nMeilleur modèle selon cp  =  5.009  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon aic  =  3031.258  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon bic  =  3065.851  : Modèle avec 6 variables\n (Intercept) AtBat Hits Walks CRBI DivisionW PutOuts \n \n\n\n\n\n\n\n\nUtilisation de la fonction step\n\nOn peut également utiliser la fonction step de la library {stats}.\nLa fonction step nous propose quel critère nous voulons utiliser pour la sélection entre le BIC, AIC et \\(C_p\\).\n\nBICAIC\\(C_p\\)\n\n\n\n\nShow the code\nmodselect_seq_bic &lt;- step(mod0,\n                  scope = formula(mod1),\n                  trace = FALSE,\n                  direction = c(\"both\"),\n                  k = log(n))\nmodselect_seq_bic %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-873.11 -181.72  -25.91  141.77 2040.47 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   91.51180   65.00006   1.408 0.160382    \nCRBI           0.64302    0.06443   9.979  &lt; 2e-16 ***\nHits           7.60440    1.66254   4.574 7.46e-06 ***\nPutOuts        0.26431    0.07477   3.535 0.000484 ***\nDivisionW   -122.95153   39.82029  -3.088 0.002239 ** \nAtBat         -1.86859    0.52742  -3.543 0.000470 ***\nWalks          3.69765    1.21036   3.055 0.002488 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 319.9 on 256 degrees of freedom\nMultiple R-squared:  0.5087,    Adjusted R-squared:  0.4972 \nF-statistic: 44.18 on 6 and 256 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nShow the code\nmodselect_seq_aic &lt;- step(mod0,\n                  scope = formula(mod1),\n                  trace = FALSE,\n                  direction = c(\"both\"),\n                  k = 2)\nmodselect_seq_aic %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-939.11 -176.87  -34.08  130.90 1910.55 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  162.53544   66.90784   2.429 0.015830 *  \nCRBI           0.77431    0.20961   3.694 0.000271 ***\nHits           6.91802    1.64665   4.201 3.69e-05 ***\nPutOuts        0.29737    0.07444   3.995 8.50e-05 ***\nDivisionW   -112.38006   39.21438  -2.866 0.004511 ** \nAtBat         -2.16865    0.53630  -4.044 7.00e-05 ***\nWalks          5.77322    1.58483   3.643 0.000327 ***\nCWalks        -0.83083    0.26359  -3.152 0.001818 ** \nCRuns          1.40825    0.39040   3.607 0.000373 ***\nCAtBat        -0.13008    0.05550  -2.344 0.019858 *  \nAssists        0.28317    0.15766   1.796 0.073673 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.8 on 252 degrees of freedom\nMultiple R-squared:  0.5405,    Adjusted R-squared:  0.5223 \nF-statistic: 29.64 on 10 and 252 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nShow the code\nmodselect_seq_cp &lt;- step(mod0,\n                  scope = formula(mod1),\n                  trace = FALSE,\n                  direction = c(\"both\"),\n                  k = 1)\nmodselect_seq_cp %&gt;% summary()\n\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists + League, data = Hitters_Without_NA)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-932.2 -175.4  -29.2  130.4 1897.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  135.75122   71.34623   1.903 0.058223 .  \nCRBI           0.78525    0.20978   3.743 0.000225 ***\nHits           6.92370    1.64612   4.206 3.62e-05 ***\nPutOuts        0.28941    0.07478   3.870 0.000139 ***\nDivisionW   -111.14603   39.21835  -2.834 0.004970 ** \nAtBat         -2.12775    0.53746  -3.959 9.81e-05 ***\nWalks          5.62028    1.59064   3.533 0.000488 ***\nCWalks        -0.82286    0.26361  -3.121 0.002010 ** \nCRuns          1.45533    0.39270   3.706 0.000259 ***\nCAtBat        -0.13899    0.05609  -2.478 0.013870 *  \nAssists        0.26883    0.15816   1.700 0.090430 .  \nLeagueN       43.11162   39.96612   1.079 0.281755    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 251 degrees of freedom\nMultiple R-squared:  0.5426,    Adjusted R-squared:  0.5226 \nF-statistic: 27.07 on 11 and 251 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nAvec la fonction step nous avons le modèle utilisant le critère BIC qui nous permet d’avoir toutes nos variables significatives (sauf l’intercept ce qui pourrait nous donner envie de faire des modèles sans).\nPar contre, nos valeurs de \\(R^2\\) et \\(R^2_{adjusted}\\) sont encore assez faible pour considérer ces modèles comme étant de très bonne qualité.\n\n\n\n\n\n\n\nNote\n\n\n\nAussi, si on veut comparer le modèle initial et le modèle final, on peut utiliser la fonction anova. Cela permet de voir si la sélection de variables a significativement amélioré l’ajustement.\n\n\nShow the code\nanova(mod0, modselect_seq_bic, test = \"Chisq\")\n\n\nAnalysis of Variance Table\n\nModel 1: Salary ~ 1\nModel 2: Salary ~ CRBI + Hits + PutOuts + Division + AtBat + Walks\n  Res.Df      RSS Df Sum of Sq  Pr(&gt;Chi)    \n1    262 53319113                           \n2    256 26194904  6  27124209 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDe manière logique on voit donc tout de même que le modèle avec nos variable explicatives sélectionnées (ici celui avec selection via le critère BIC) propose un meilleur ajustement que celui sans variable."
  },
  {
    "objectID": "posts/Exercice_05.html",
    "href": "posts/Exercice_05.html",
    "title": "Exercice 05",
    "section": "",
    "text": "Clément Poupelin, clementjc.poupelin@gmail.com"
  },
  {
    "objectID": "posts/Exercice_05.html#corrélation",
    "href": "posts/Exercice_05.html#corrélation",
    "title": "Exercice 05",
    "section": "Corrélation",
    "text": "Corrélation\nMaintenant, nous pouvons déjà souligner que, théoriquement, il ne devrait pas y avoir de lien entre \\(y\\) et \\(X\\) puisque les simulations sont faites indépendament.\nPour visualiser cela, il suffit simplement de créer un vecteur qui stockera les différentes valeurs de corrélation entre \\(y\\) et \\(x^i\\) pour \\(i\\) allant de 1 à 5000.\n\n\nShow the code\ncor_vect &lt;- unlist(lapply(x, function(col) cor(col, y)))\nmy_hist(cor_vect)\n\n\n\n\n\n\n\n\n\n\nTextePreuve\n\n\nDe manière général, il faut savoir qu’une méthode de prévision de \\(y\\) basée sur les variables explicatives s’exprime nécessairement sous la forme \\(\\hat{y} = f(x^1, ..., x^{5000})\\). La forme de la fonction \\(f\\) étant généralement obtenue grâce à une estimation sur un échantillon d’apprentissage. Il faut alors découper notre jeu de données en deux échantillons, un pour l’apprentissage et un pour le test.\n\nDans ces méthodes, nous nous intéressons principalement au taux d’erreur de classification “test”, c’est-à-dire à la probabilité que \\(\\hat{y}\\) soit différent de \\(y\\), lorsque \\(y\\) et \\(x^1, ..., x^{5000}\\) sont dans l’échantillon test et donc indépendants de l’échantillon d’apprentissage.\nOn peut facilement démontrer que cette probabilité est de 50% quelle que soit la méthode utilisée (cf Preuve).\nPourtant, pour illustrer nos problèmes, supposons que nous avons observé le jeu de données simulé ci-dessus, sans connaître les liens théoriques entre les variables. Nous souhaitons alors ajuster un modèle expliquant au mieux \\(y\\) en fonction des variables à disposition, et estimer le taux d’erreur des prévisions associées.\n\n\nNous remarquons déjà que, \\(\\hat{y}\\) étant une combinaisons de nos variables \\(x^1, ..., x^{5000}\\) qui sont indépendantes de \\(y\\), on a \\(\\hat{y}\\) et y sont deux variables indépendantes l’une de l’autre.\n\nAinsi \\[\\mathbb{P}(\\hat{y} \\neq y) = \\mathbb{P}(\\hat{y}=0, y=1) + \\mathbb{P}(\\hat{y}=1, y=0)\\] \\[ \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad = \\mathbb{P}(\\hat{y}=0)\\mathbb{P}(y=1) + \\mathbb{P}(\\hat{y}=1)\\mathbb{P}(y=0) \\quad  ^{(*)}\\] \\[ \\quad \\quad \\quad \\quad = 0.5\\mathbb{P}(\\hat{y}=0) + 0.5\\mathbb{P}(\\hat{y}=1)  \\quad  ^{(**)} \\] \\[ \\quad \\quad = 0.5 \\left( \\mathbb{P}(\\hat{y}=0) + \\mathbb{P}(\\hat{y}=1) \\right)\\]\nNous reconnaissons ici une somme sur l’univers des possible de la densité discrète de \\(\\hat{y}\\).\nCelle ci est donc égale à 1 et on obtient\n\\[\\mathbb{P}(\\hat{y} \\neq y) = 0.5\\]\n\n\\(^{(*)} \\quad \\text{par indépendance de} \\quad \\hat{y} \\quad \\text{et} \\quad y\\)\n\\(^{(**)} \\quad \\text{car} \\quad y \\quad \\text{suit une loi de Bernoulli de paramètre} \\quad 0.5\\)"
  },
  {
    "objectID": "posts/Exercice_06Bonus.html",
    "href": "posts/Exercice_06Bonus.html",
    "title": "Exercice 6 Bonus : Ridge vs Lasso",
    "section": "",
    "text": "Dans cette partie et avant de passer à l’exercice 7, nous allons faire la section 3.1 sur la gression Ridge et Lasso avec glmnet sous R du tutoriel de Laurent Rouvière\n\nRappels sur Ridge et Lasso\nOn se base encore ici sur notre modèle classique de régression linéaire :\n\\[y = X\\beta + \\mathcal{E} \\quad \\text{ou} \\quad y = \\beta_0 + \\beta_1X^1 + ... + \\beta_pX^p + \\mathcal{E}\\]\n\n\\(y \\in \\mathbb{R}^{n}\\) la variable réponse ou variable à expliquer\n\\(X \\in \\mathbb{R}^{n\\times (p+1)}\\) la matrice déterministe contenant nos \\(p\\) variables explicatives\n\\(\\beta \\in \\mathbb{R}^{p+1}\\) le vecteur qui contient les coefficients de régression \\(\\beta_0, ..., \\beta_p\\) que nous cherchons à estimer\n\\(\\mathcal{E} \\in \\mathbb{R}^{n}\\) le vecteur d’erreur qui n’est pas corrélé à nos variables explicatives. C’est la part d’aléa que nous n’arrivons pas à déterminer\n\nPour l’estimation des coefficients de regression de ce type de modèle, nous utilisons souvent la méthodes des moindres carrées ordinaire (MCO) qui nous donne\n\\[\\hat{\\beta} = \\underset{\\beta}{argmin}||y-X\\beta||^2\\] Malheureusement, lorsque \\(p\\) est grand ou que les variables sont linéairement dépendantes, les estimateurs des moindres carrées peuvent être mis en défaut. Les méthodes pénalisées ou sous contraintes consistent alors à restreindre l’espace sur lequel on minimise ce critère.\n\nL’idée principale de ces méthodes est de contraindre la valeur des estimateurs MCO pour réduire la variance, quitte à augmenter un peu le biais (d’où la terminologie de “régression biaisée”). Nous obtenons donc, pour un certain \\(t&gt;0\\), des estimations de la forme suivante : \\[ \\hat{\\beta}^{pen} = \\underset{\\beta}{argmin}||y-X\\beta||^2 \\quad \\text{sous la contrainte} \\quad ||\\beta||? \\leq t\\]\n\nRidgeLasso\n\n\nLa régression Ridge contraint la norme \\(\\ell^2\\) des coefficients \\(\\beta\\) à ne pas exploser, i.e \\(||\\beta||_2 = \\sum_{j=0}^{p} \\beta_j^2 \\leq t\\). Cela conduit à la solution d’optimisation suivante :\n\\[\n\\hat{\\beta}_{Ridge} = \\underset{\\beta}{\\operatorname{argmin}} \\ ||y - X\\beta||^2 \\quad \\text{sous la contrainte} \\quad \\sum_{j=0}^{p} \\beta_j^2 \\leq t\n\\]\noù \\(\\hat{\\beta}_{Ridge}\\) est unique, contrairement à Lasso qui peut produire plusieurs solutions.\nContrairement à Lasso, Ridge ne met pas exactement à zéro certains coefficients, mais réduit leur valeur. Il n’y a donc pas de sélection de variable effectué.\nCette méthode est tout de même robuste en grande dimension et particulièrement utile lorsque les variables sont fortement corrélées. Il empêche les coefficients de devenir trop grands, ce qui réduit la variance du modèle.\n\n\n\nLa régression Lasso (pour Least Absolute Shrinkage and Selection Operator) contraint la norme \\(\\ell^1\\) de \\(\\beta\\) à ne pas exploser, i.e \\(||\\beta||_1 = \\sum_{j=0}^{p} |\\beta_j| \\leq t\\). Nous obtenons donc\n\\[\\hat{\\beta}_{Lasso} = \\underset{\\beta}{argmin}||y-X\\beta||^2 \\quad \\text{sous la contrainte} \\quad \\sum_{j=0}^{p} |\\beta_j| \\leq t  \\]\nOù \\(\\hat{\\beta}_{Lasso}\\) n’est pas nécessairement unique mais la prévision \\(\\hat{y} = X\\hat{\\beta}_{Lasso}\\) est unique.\n\nCette méthode est principalement caractérisée par le fait qu’elle est robuste à la grande dimension en sélectionnant les variables les plus pertinentes. En effet, elle nous permet de réduire les coefficients MCO des variables sélectionnées en rapprochant leur valeur de 0, ce qui est appelé la propriété de “seuillage doux” du Lasso.\n\n\n\nIci, il sera donc présenté les étapes principales qui permettent de faire ce type de régression avec R. Le package le plus souvent utilisé est glmnet.\n\n\nSetup\n\npackagesfonctions\n\n\n\n\nShow the code\n# PCA\nlibrary(FactoMineR)\nlibrary(factoextra)\n\n\nLe chargement a nécessité le package : ggplot2\n\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\n\nShow the code\n# Plots\n## ggplot\nlibrary(ggplot2)\nlibrary(reshape2)     # transformer les données en format long\nlibrary(gridExtra)\n\n## for pairs panel\nlibrary(psych)\n\n\n\nAttachement du package : 'psych'\n\n\nLes objets suivants sont masqués depuis 'package:ggplot2':\n\n    %+%, alpha\n\n\nShow the code\nlibrary(RColorBrewer)\n\n\n\n\n\nboxplotpairs.panels\n\n\n\n\nShow the code\nmy_boxplot &lt;- function(data) {\n  # Transformer les données en format long pour ggplot\n  data_long &lt;- melt(data)\n  \n  ggplot(data_long, aes(x = variable, y = value, fill = variable)) +\n    geom_boxplot() +\n    scale_fill_viridis_d() +  # Palette de couleurs harmonieuse\n    labs(title = \"Distribution des Variables (Boxplot)\", x = \"Variables\", y = \"Valeurs\") +\n    theme_minimal() +  # Thème épuré\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotation des étiquettes\n}\n\n\n\n\n\n\nShow the code\nmy_pairs.panels &lt;- function(data){\n  pairs.panels(\n    data,\n    method = \"pearson\",      # Méthode de corrélation \n    hist.col = brewer.pal(9, \"Set3\"), # Couleurs des histogrammes\n    density = TRUE,          # Ajout des courbes de densité\n    ellipses = TRUE,         # Ajout d'ellipses \n    smooth = TRUE,           # Ajout de régressions lissées\n    lm = TRUE,               # Ajout des droites de régression\n    col = \"#69b3a2\",         # Couleur des points\n    alpha = 0.5              # Transparence \n    )\n}\n\n\n\n\n\n\n\n\n\n\nDonnées\nOn considère le jeu de données ozone.txt où on cherche à expliquer la concentration maximale en ozone relevée sur une journée (variable maxO3) par d’autres variables essentiellement météorologiques.\nLa base de données d’origine ozone.txt répertorie 112 données météorologiques mesurées durant l’été 2001 à Rennes. Celles-ci sont caractérisées par les 13 variables suivantes :\n\n\n\n\n\nmaxO3\nconcentration maximale d'ozone (en DU)\n\n\nT9\ntempérature à 9H (en °C)\n\n\nT12\ntempérature à 12H (en °C)\n\n\nT15\ntempérature à 15H (en °C)\n\n\nNe9\nnébulosité à 9H (en octa)\n\n\nNe12\nnébulosité à 12H (en octa)\n\n\nNe15\nnébulosité à 15H (en octa)\n\n\nVx9\nvitesse du vent à 9H\n\n\nVx12\nvitesse du vent à 12H\n\n\nVx15\nvitesse du vent à 15H\n\n\nmaxO3v\nconcentration maximale d'ozone de la veille (en DU)\n\n\nvent\ndirection principale du vent (Nord / Ouest / Sud / Est)\n\n\npluie\nprésence ou non de pluie (Sec / Pluie)\n\n\n\n\n\n\n\nOn identifie le regroupement de toutes les données météorologiques récoltées en une journée par la date à laquelle les relevés ont été effectués.\n\n\nShow the code\nozone &lt;-read.table(\"https://r-stat-sc-donnees.github.io/ozone.txt\", header=TRUE)\nozone %&gt;% DT::datatable()\n\n\n\n\n\n\n\n\nShow the code\nozone %&gt;% summary()\n\n\n     maxO3              T9             T12             T15       \n Min.   : 42.00   Min.   :11.30   Min.   :14.00   Min.   :14.90  \n 1st Qu.: 70.75   1st Qu.:16.20   1st Qu.:18.60   1st Qu.:19.27  \n Median : 81.50   Median :17.80   Median :20.55   Median :22.05  \n Mean   : 90.30   Mean   :18.36   Mean   :21.53   Mean   :22.63  \n 3rd Qu.:106.00   3rd Qu.:19.93   3rd Qu.:23.55   3rd Qu.:25.40  \n Max.   :166.00   Max.   :27.00   Max.   :33.50   Max.   :35.50  \n      Ne9             Ne12            Ne15           Vx9         \n Min.   :0.000   Min.   :0.000   Min.   :0.00   Min.   :-7.8785  \n 1st Qu.:3.000   1st Qu.:4.000   1st Qu.:3.00   1st Qu.:-3.2765  \n Median :6.000   Median :5.000   Median :5.00   Median :-0.8660  \n Mean   :4.929   Mean   :5.018   Mean   :4.83   Mean   :-1.2143  \n 3rd Qu.:7.000   3rd Qu.:7.000   3rd Qu.:7.00   3rd Qu.: 0.6946  \n Max.   :8.000   Max.   :8.000   Max.   :8.00   Max.   : 5.1962  \n      Vx12             Vx15            maxO3v           vent          \n Min.   :-7.878   Min.   :-9.000   Min.   : 42.00   Length:112        \n 1st Qu.:-3.565   1st Qu.:-3.939   1st Qu.: 71.00   Class :character  \n Median :-1.879   Median :-1.550   Median : 82.50   Mode  :character  \n Mean   :-1.611   Mean   :-1.691   Mean   : 90.57                     \n 3rd Qu.: 0.000   3rd Qu.: 0.000   3rd Qu.:106.00                     \n Max.   : 6.578   Max.   : 5.000   Max.   :166.00                     \n    pluie          \n Length:112        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\n\n\nAnalyse descriptive\n\nBoxplotCorrelation panelPCA\n\n\nOn peut regarder un peu la distribution de nos différents variables quantitatives via des boxplots.\n\n\nShow the code\nmy_boxplot(ozone)\n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn remarque bien que les variabeles qui sont de même nature mais à des points de temps différents sont d’avantages similaires.\n\nPour confirmer cela, on peut faire des boxplot pour uniquement une varibale et ses différents points de temps.\n\nTempératureNébulositéVitesse du vent\n\n\n\n\nShow the code\nsubset(ozone, select = c(\"T9\", \"T12\", \"T15\"))  %&gt;% my_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nsubset(ozone, select = c(\"Ne9\", \"Ne12\", \"Ne15\"))  %&gt;% my_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nsubset(ozone, select = c(\"Vx9\", \"Vx12\", \"Vx15\"))  %&gt;% my_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn regarde ici la corrélation calculée entre chacune de nos variables.\n\n\nShow the code\nmy_pairs.panels(ozone)\n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn voit la présence de plusieurs fortes corrélations qui peut déjà nous alerter si l’on veut faire des modèles de regressions linéaires car on risque d’avoir un problème de colinéarité entre les varibales explicatives.\nCependant ces corrélation fortes sont surtout présentes pour les variables qui sont à différents points de temps ce qui est logique.\n\n\n\nAvec une Analyse en Composantes Principales (PCA) on peut regarder un peu le comportement de nos données.\nEn effet, Cette méthode respose sur la transformation des variables d’origine en nouvelles variables non corrélées, appelées composantes principales, qui capturent successivement la plus grande variance possible des données.\n\n\nShow the code\nres_pca &lt;- PCA(ozone, \n               quali.sup = c(which(colnames(ozone) %in% c(\"vent\", \"pluie\"))),\n               quanti.sup = c(which(colnames(ozone) %in% c(\"max03\", \"max03v\"))),\n               graph = FALSE)\n\n\nIci, on spécifi nos varibales qualitatives et on décide de mettre la variable max03 et max03v en variable supplémentaire, ce qui veut d’ire qu’elles ne seront pas considérés pour la formation de nos composantes principales (variable que l’on cherchera à estimer plus tard).\n\nBarplot des variancesIndividusVariables\n\n\nTout d’abord, on peut commencer par regarder le pourcentage de variance expliqué par nos différentes composantes principales.\n\n\nShow the code\nfviz_eig(res_pca, \n         ncp = 10,\n         addlabels = TRUE, \n         barfill = \"coral\",\n         barcolor = \"coral\",\n         ylim = c(0, 60),\n         main = \"Percentage of variance of the 10 first components\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nOn voit ainsi que la majorité de la variance est expliquée par nos deux premières composantes principales.\n\n\n\nLe plan des individus est une projection des observations sur les axes principaux de la PCA. Cette visualisation permet d’identifier des regroupements, tendances et anomalies au sein des données.\nAinsi, des individus proches sur le graphique ont des caractéristiques similaires par rapport aux variables utilisées.\nPuis, le placement d’un individu en fonction des axes peut permettre de savoir comment le jouer se caractérise par rapport aux variables qui contribuent le plus à ces axes.\n\nPluievent\n\n\n\n\nShow the code\nfviz_pca_ind(res_pca,\n             label=\"none\", \n             pointsize = 2,\n             habillage=as.factor(ozone$pluie),\n             addEllipses=TRUE,\n             ellipse.level=0.95)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nfviz_pca_ind(res_pca,\n             label=\"none\",\n             pointsize = 2,\n             habillage=as.factor(ozone$vent),\n             addEllipses=TRUE,\n             ellipse.level=0.95)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nIci on voit une repartition plutot uniforme sur le plan qui ne semble pas permettre de distinguer une séparation forte correspodant à nos variables qualitatives.\n\n\n\nLe cercle des variables est une représentation graphique qui permet d’analyser les relations entre les variables initiales et les composantes principales qui forment nos axes. Il est basé sur les corrélations entre les variables et les axes principaux.\nAinsi, plus une variable est proche du bord du cercle, plus elle est bien représentée sur le plan factoriel et contribue fortement à la formation des axes. Ici, on utilise le cos2 pour le gradient de couleur qui va aider à l’indentifictation de ces différentes qualitées de représentation.\nDe plus, selon l’angle entre deux varibles, on peut faire des suppositions sur leur corrélation :\n\nSi deux variables ont des vecteurs proches (petit angle), elles sont fortement corrélées positivement\nSi deux variables ont des vecteurs opposés (angle proche de 180°), elles sont corrélées négativement\nSi l’angle est proche de 90°, alors les variables ne sont pas corrélées\n\n\n\nShow the code\nfviz_pca_var(res_pca, \n             col.var = \"cos2\",\n             gradient.cols = rainbow(n = 8, start = .6, end = .9),\n             repel = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nRésultats\n\n\nDans notre cas, ce que l’on peut voir c’est que la majorité de nos variables sont bien représentées par nos deux axes (cumulant plus de 70% d’explication). Mais beaucoup semblent aussi fortement corrélées avecla formation de trois groupes. Cette corrélation ayant déjà pu être observé précédemment et touours logique du fait du côté longitudinale de nos données.\nCe que l’on peut tout de même ajouté c’est que les variables max03 et surtout max03v semblent plutot corrélées aux variables température. Constat qui peut se confirmer avec le pairs.panels précédent.\n\n\n\n\n\n\n\n\n\nAnalyse inférentielle\n\n\nShow the code\n# ozone &lt;- read.csv(\"~/1.Workspace/Master_IS/M2/X3MS020_Statistique_en_grande_dimension/ozone.txt\", sep=\"\")\nozone &lt;-read.table(\"https://r-stat-sc-donnees.github.io/ozone.txt\", header=TRUE)\nhead(ozone)\n\n\n         maxO3   T9  T12  T15 Ne9 Ne12 Ne15     Vx9    Vx12    Vx15 maxO3v\n20010601    87 15.6 18.5 18.4   4    4    8  0.6946 -1.7101 -0.6946     84\n20010602    82 17.0 18.4 17.7   5    5    7 -4.3301 -4.0000 -3.0000     87\n20010603    92 15.3 17.6 19.5   2    5    4  2.9544  1.8794  0.5209     82\n20010604   114 16.2 19.7 22.5   1    1    0  0.9848  0.3473 -0.1736     92\n20010605    94 17.4 20.5 20.4   8    8    7 -0.5000 -2.9544 -4.3301    114\n20010606    80 17.7 19.8 18.3   6    6    7 -5.6382 -5.0000 -6.0000     94\n          vent pluie\n20010601  Nord   Sec\n20010602  Nord   Sec\n20010603   Est   Sec\n20010604  Nord   Sec\n20010605 Ouest   Sec\n20010606 Ouest Pluie\n\n\nShow the code\nsummary(ozone)\n\n\n     maxO3              T9             T12             T15       \n Min.   : 42.00   Min.   :11.30   Min.   :14.00   Min.   :14.90  \n 1st Qu.: 70.75   1st Qu.:16.20   1st Qu.:18.60   1st Qu.:19.27  \n Median : 81.50   Median :17.80   Median :20.55   Median :22.05  \n Mean   : 90.30   Mean   :18.36   Mean   :21.53   Mean   :22.63  \n 3rd Qu.:106.00   3rd Qu.:19.93   3rd Qu.:23.55   3rd Qu.:25.40  \n Max.   :166.00   Max.   :27.00   Max.   :33.50   Max.   :35.50  \n      Ne9             Ne12            Ne15           Vx9         \n Min.   :0.000   Min.   :0.000   Min.   :0.00   Min.   :-7.8785  \n 1st Qu.:3.000   1st Qu.:4.000   1st Qu.:3.00   1st Qu.:-3.2765  \n Median :6.000   Median :5.000   Median :5.00   Median :-0.8660  \n Mean   :4.929   Mean   :5.018   Mean   :4.83   Mean   :-1.2143  \n 3rd Qu.:7.000   3rd Qu.:7.000   3rd Qu.:7.00   3rd Qu.: 0.6946  \n Max.   :8.000   Max.   :8.000   Max.   :8.00   Max.   : 5.1962  \n      Vx12             Vx15            maxO3v           vent          \n Min.   :-7.878   Min.   :-9.000   Min.   : 42.00   Length:112        \n 1st Qu.:-3.565   1st Qu.:-3.939   1st Qu.: 71.00   Class :character  \n Median :-1.879   Median :-1.550   Median : 82.50   Mode  :character  \n Mean   :-1.611   Mean   :-1.691   Mean   : 90.57                     \n 3rd Qu.: 0.000   3rd Qu.: 0.000   3rd Qu.:106.00                     \n Max.   : 6.578   Max.   : 5.000   Max.   :166.00                     \n    pluie          \n Length:112        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nShow the code\nlibrary(psych)\npairs.panels(ozone)\n\n\n\n\n\n\n\n\n\nShow the code\nozone.X &lt;- model.matrix(maxO3~.,data=ozone)[,-1] #  codage des variables qualitatives avec la fonction model.matrix\nozone.Y &lt;- ozone$maxO3\n\nlibrary(glmnet)\n\n\nLe chargement a nécessité le package : Matrix\n\n\n\nAttachement du package : 'Matrix'\n\n\nLes objets suivants sont masqués depuis 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-8\n\n\nShow the code\nmod.R &lt;- glmnet(ozone.X, ozone.Y, alpha=0) ## Ridge \n\nmod.L &lt;- glmnet(ozone.X, ozone.Y, alpha=1) ## Lasso\n\n# Par défaut standardize = TRUE, intercept = TRUE\n\n## Analyse Modèle Ridge\nmod.R$lambda |&gt; head()\n\n\n[1] 22007.27 20052.20 18270.82 16647.69 15168.76 13821.21\n\n\nShow the code\n# When alpha=0, the largest lambda reported does not quite give \n# the zero coefficients reported (lambda=inf would in principle).\n# Instead, the largest lambda for alpha=0.001 is used, and the sequence \n# of lambda values is derived from this.\n\n\nmod.R$beta[,1]\n\n\n           T9           T12           T15           Ne9          Ne12 \n 6.376767e-36  5.523924e-36  4.867402e-36 -6.821464e-36 -7.994984e-36 \n         Ne15           Vx9          Vx12          Vx15        maxO3v \n-5.839057e-36  5.706014e-36  4.387350e-36  3.970583e-36  6.892387e-37 \n     ventNord     ventOuest       ventSud      pluieSec \n-5.830507e-36 -1.022483e-35  1.519222e-35  2.772246e-35 \n\n\nShow the code\n# Our coefficients\n\npar(mfrow=c(1,2))\nplot(mod.R,label=TRUE)  \n# lecture du graphe : \n#   - chaque courbe c'est lévolution d'un beta\n#   - à droite on à les valeurs de beta MCO \n#   - à gauche c'est quand lambda augmente, on tend vers 0\n\nplot(mod.R,xvar=\"lambda\",label=TRUE)\n\n\n\n\n\n\n\n\n\nShow the code\npar(mfrow=c(1,1))\n\n\n\n\n\n\n\n## Analyse Modèle Lasso\nmod.L$lambda |&gt; head()\n\n\n[1] 22.00727 20.05220 18.27082 16.64769 15.16876 13.82121\n\n\nShow the code\nmod.L$beta[,1]\n\n\n       T9       T12       T15       Ne9      Ne12      Ne15       Vx9      Vx12 \n        0         0         0         0         0         0         0         0 \n     Vx15    maxO3v  ventNord ventOuest   ventSud  pluieSec \n        0         0         0         0         0         0 \n\n\nShow the code\npar(mfrow=c(1,2))\nplot(mod.L,label=TRUE)  \nplot(mod.L,xvar=\"lambda\",label=TRUE)\n\n\n\n\n\n\n\n\n\nShow the code\npar(mfrow=c(1,1))\n\n####\n# Sélection des paramètres de régularisation ####\n\nridgeCV &lt;- cv.glmnet(ozone.X, ozone.Y, alpha=0)\nplot(ridgeCV)\n\n\n\n\n\n\n\n\n\nShow the code\n# abline(v=log(ridgeCV$lambda.1se), col='red')\n# abline(v=log(ridgeCV$lambda.min), col='red')\n\n# On visualise les erreurs quadratiques calculées \n# par validation croisée 10 blocs en fonction de lambda (échelle log)\n\n# Deux traites verticaux :\n#   - celui de gauche correspond à la valeur de `lambda`\n#     qui minimise l’erreur quadratique ;\n# \n#   - celui de droite correspond à la plus grande valeur de `lambda` \n#     telle que l’erreur ne dépasse pas \n#     l’erreur minimale + 1 écart-type estimé de cette erreur.\n\n\n# D’un point de vu pratique, cela signifie que l’utilisateur\n# peut choisir n’importe quelle valeur de lambda entre \n# les deux traits verticaux. Si on veut diminuer \n# la complexité du modèle on choisira la valeur de droite.\n# On peut obtenir ces deux valeurs \n\nridgeCV$lambda.min\n\n\n[1] 7.375962\n\n\nShow the code\nridgeCV$lambda.1se\n\n\n[1] 57.1094\n\n\nShow the code\nlassoCV &lt;- cv.glmnet(ozone.X, ozone.Y, alpha=1)\nplot(lassoCV)\n\n\n\n\n\n\n\n\n\nShow the code\n# abline(v=log(lassoCV$lambda.1se), col='red')\n# abline(v=log(lassoCV$lambda.min), col='red')\n\nlassoCV$lambda.min\n\n\n[1] 1.626496\n\n\nShow the code\nlassoCV$lambda.1se\n\n\n[1] 5.98287\n\n\nShow the code\n####\n# Prédiction de la variable cible pour de nouveaux individus ####\n\n# Première approche :\n# réajuster le modèle sur toutes les données pour la valeur \n# de lambda sélectionnée.\n# Cette étape est en réalité déjà effectuée par la fonction cv.glmnet.\n# Il suffit par conséquent d’appliquer la fonction predict à l’objet \n# obtenu avec cv.glmnet en spécifiant la valeur de lambda souhaitée.\npredict(ridgeCV, newx = ozone.X[50:51,],s=\"lambda.min\")\n\n\n         lambda.min\n20010723   89.39929\n20010724   96.81660\n\n\nShow the code\npredict(ridgeCV, newx = ozone.X[50:51,],s=\"lambda.1se\")\n\n\n         lambda.1se\n20010723   93.50409\n20010724   96.00444\n\n\nShow the code\npredict(lassoCV, newx = ozone.X[50:51,],s=\"lambda.min\")\n\n\n         lambda.min\n20010723   87.19995\n20010724   97.82825\n\n\nShow the code\npredict(lassoCV, newx = ozone.X[50:51,],s=\"lambda.1se\")\n\n\n         lambda.1se\n20010723   87.71031\n20010724   94.98276\n\n\nShow the code\n# Comparaison performances MCO, ridge et lasso ####\n\n# validation croisée pour comparer les performances des estimateurs\n# MCO, ridge et lasso.\n# On pourra utiliser les données ozone_complet.txt\n# qui contiennent plus d’individus et de variables.\n\n# ozone1 &lt;- read.csv(\"~/1. Workspace/Master IS/M2/X3MS020 Statistique en grande dimension/ozone_complet.txt\", sep=\";\") |&gt; na.omit()\nozone1 &lt;-read.table(\"https://r-stat-sc-donnees.github.io/ozone.txt\", header=TRUE) |&gt; na.omit()\nozone1.X &lt;- model.matrix(maxO3~., data=ozone1)[,-1]\nozone1.Y &lt;- ozone1$maxO3\n\nlibrary(tibble)\nlibrary(dplyr)\n\ncv.ridge.lasso &lt;- function(data,form){\n  set.seed(1234)\n  data.X &lt;- model.matrix(form,data=data)[,-1]\n  data.Y &lt;- data$maxO3\n  blocs &lt;- caret::createFolds(1:nrow(data),k=10)\n  prev &lt;- matrix(0,ncol=3,nrow=nrow(data)) |&gt; as.data.frame()\n  names(prev) &lt;- c(\"lin\",\"ridge\",\"lasso\")\n  for (k in 1:10){\n    app &lt;- data[-blocs[[k]],]\n    test &lt;- data[blocs[[k]],]\n    app.X &lt;- data.X[-blocs[[k]],]\n    app.Y &lt;- data.Y[-blocs[[k]]]\n    test.X &lt;- data.X[blocs[[k]],]\n    test.Y &lt;- data.Y[blocs[[k]]]\n    ridge &lt;- cv.glmnet(app.X,app.Y,alpha=0)\n    lasso &lt;- cv.glmnet(app.X,app.Y,alpha=1)\n    lin &lt;- lm(form,data=app)\n    prev[blocs[[k]],] &lt;- tibble(lin=predict(lin,newdata=test),\n                                ridge=as.vector(predict(ridge,newx=test.X)),\n                                lasso=as.vector(predict(lasso,newx=test.X)))\n  }\n  err &lt;- prev |&gt; mutate(obs=data$maxO3) |&gt; summarise_at(1:3,~mean((obs-.)^2))\n  return(err)\n}\n\ncv.ridge.lasso(ozone1, form=formula(maxO3~.))\n\n\n       lin    ridge    lasso\n1 247.4596 271.8111 272.9936\n\n\nShow the code\n# On remarque que les approches régularisées \n# n’apportent rien par rapport aux estimateurs MCO ici.\n# Ceci peut s’expliquer par le fait que le nombre de variables\n# n’est pas très important.\n\n# Considérons toutes les interactions d’ordre 2\ncv.ridge.lasso(ozone1, form=formula(maxO3~.^2))\n\n\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\nWarning in predict.lm(lin, newdata = test): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\n\n\n       lin    ridge    lasso\n1 196622.7 335.9692 268.1647\n\n\nShow the code\n# Les méthodes régularisées permettent ici de diminuer\n# les erreurs quadratiques de manière intéressante.\n# Cela vient certainement du fait du nombre de \n# variables explicatives qui est beaucoup plus \n# important lorsqu’on prend en compte toutes \n# les interactions d’ordre 2, nous en avons en effet 253 :\nozone2.X &lt;- model.matrix(maxO3~.^2,data=ozone1)[,-1]\ndim(ozone2.X)\n\n\n[1] 112 102"
  },
  {
    "objectID": "posts/Exercice_04.html",
    "href": "posts/Exercice_04.html",
    "title": "Exercice 4",
    "section": "",
    "text": "PackagesFonctions\n\n\n\n\nShow the code\n# Données\nlibrary(ISLR)         # Caravan data \nlibrary(dplyr)        # manipulation des données\n\n\nlibrary(car)          # pour VIF\n\n\n\n\n\n# Plots\n## ggplot\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n\n\n\n\nboxplotHeatmapVIF plot\n\n\n\n\nShow the code\nmy_boxplot &lt;- function(data) {\n  # Transformer les données en format long pour ggplot\n  data_long &lt;- reshape2::melt(data)\n  \n  ggplot(data_long, aes(x = variable, y = value, fill = variable)) +\n    geom_boxplot() +\n    scale_fill_viridis_d() +  # Palette de couleurs harmonieuse\n    labs(title = \"Distribution des Variables (Boxplot)\", x = \"Variables\", y = \"Valeurs\") +\n    theme_minimal() +  # Thème épuré\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotation des étiquettes\n}\n\n\n\n\n\n\n\n\n\nShow the code\nmy_VIFplot &lt;- function(vif) {\n  vif_df &lt;- data.frame(Variable = names(vif), VIF = vif)\n  \n  p &lt;- ggplot(vif_df, aes(\n    x = reorder(Variable, VIF),\n    y = pmin(VIF, 15),\n    fill = VIF &gt; 10\n  )) +\n    geom_bar(stat = \"identity\") +\n    geom_text(aes(label = ifelse(VIF &gt; 10, round(VIF, 1), \"\")), hjust = -0.2, size = 6) +\n    coord_flip() +\n    scale_fill_manual(values = c(\"FALSE\" = \"#0072B2\", \"TRUE\" = \"#D55E00\")) +\n    labs(title = \"Variance Inflation Factor (VIF)\", x = \"Variables\", y = \"VIF (limité à 15)\") +\n    theme_minimal() +\n    theme(\n      axis.title = element_text(size = 34, face = \"bold\"),\n      plot.title = element_text(\n        size = 54,\n        face = \"bold\",\n        hjust = 0.5\n      ),\n      axis.text.x = element_text(size = 26),\n      axis.text.y = element_text(size = 18),\n      legend.text = element_text(size = 30),\n      legend.title = element_text(size = 38, face = \"bold\")\n    )\n  \n  return(p)\n}"
  },
  {
    "objectID": "posts/Exercice_04.html#modèle-brut",
    "href": "posts/Exercice_04.html#modèle-brut",
    "title": "Exercice 4",
    "section": "Modèle brut",
    "text": "Modèle brut\nAjustons un modèle de régression logistique modélisant la probabilité de souscrire une assurance caravane en fonction de toutes les autres variables à disposition\n\n\nShow the code\nmod1 &lt;- glm(Caravan$Purchase~.,\n                family = binomial,\n                Caravan)\n\n\nWarning: glm.fit: des probabilités ont été ajustées numériquement à 0 ou 1\n\n\nShow the code\nmod1 %&gt;% summary()\n\n\n\nCall:\nglm(formula = Caravan$Purchase ~ ., family = binomial, data = Caravan)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.542e+02  1.116e+04   0.023  0.98183    \nMOSTYPE      6.580e-02  4.624e-02   1.423  0.15468    \nMAANTHUI    -1.832e-01  1.927e-01  -0.951  0.34157    \nMGEMOMV     -2.696e-02  1.399e-01  -0.193  0.84723    \nMGEMLEEF     2.096e-01  1.016e-01   2.063  0.03911 *  \nMOSHOOFD    -2.767e-01  2.076e-01  -1.333  0.18247    \nMGODRK      -1.142e-01  1.069e-01  -1.068  0.28535    \nMGODPR      -1.910e-02  1.177e-01  -0.162  0.87112    \nMGODOV      -1.618e-02  1.055e-01  -0.153  0.87818    \nMGODGE      -6.817e-02  1.113e-01  -0.612  0.54024    \nMRELGE       2.310e-01  1.566e-01   1.475  0.14031    \nMRELSA       8.509e-02  1.466e-01   0.580  0.56169    \nMRELOV       1.467e-01  1.562e-01   0.939  0.34759    \nMFALLEEN    -8.291e-02  1.311e-01  -0.633  0.52702    \nMFGEKIND    -1.154e-01  1.337e-01  -0.863  0.38813    \nMFWEKIND    -8.140e-02  1.417e-01  -0.575  0.56561    \nMOPLHOOG     9.717e-04  1.311e-01   0.007  0.99408    \nMOPLMIDD    -9.077e-02  1.365e-01  -0.665  0.50605    \nMOPLLAAG    -1.994e-01  1.376e-01  -1.449  0.14740    \nMBERHOOG     8.883e-02  9.349e-02   0.950  0.34204    \nMBERZELF     3.918e-02  9.897e-02   0.396  0.69219    \nMBERBOER    -1.169e-01  1.104e-01  -1.059  0.28951    \nMBERMIDD     1.353e-01  9.191e-02   1.472  0.14106    \nMBERARBG     3.976e-02  9.067e-02   0.438  0.66104    \nMBERARBO     9.954e-02  9.143e-02   1.089  0.27628    \nMSKA         2.690e-02  1.035e-01   0.260  0.79502    \nMSKB1       -8.801e-03  1.011e-01  -0.087  0.93064    \nMSKB2        1.200e-02  9.081e-02   0.132  0.89485    \nMSKC         9.016e-02  9.958e-02   0.905  0.36527    \nMSKD        -2.468e-02  9.724e-02  -0.254  0.79967    \nMHHUUR      -1.472e+01  8.140e+02  -0.018  0.98557    \nMHKOOP      -1.469e+01  8.140e+02  -0.018  0.98561    \nMAUT1        1.819e-01  1.514e-01   1.202  0.22953    \nMAUT2        1.507e-01  1.371e-01   1.099  0.27162    \nMAUT0        9.325e-02  1.436e-01   0.649  0.51603    \nMZFONDS     -1.445e+01  9.359e+02  -0.015  0.98768    \nMZPART      -1.451e+01  9.359e+02  -0.016  0.98763    \nMINKM30      1.181e-01  1.006e-01   1.174  0.24039    \nMINK3045     1.366e-01  9.650e-02   1.415  0.15694    \nMINK4575     1.009e-01  9.667e-02   1.043  0.29678    \nMINK7512     1.144e-01  1.027e-01   1.114  0.26513    \nMINK123M    -1.607e-01  1.449e-01  -1.109  0.26738    \nMINKGEM      9.214e-02  9.945e-02   0.927  0.35417    \nMKOOPKLA     6.856e-02  4.642e-02   1.477  0.13966    \nPWAPART      5.954e-01  3.901e-01   1.526  0.12693    \nPWABEDR     -2.757e-01  4.635e-01  -0.595  0.55196    \nPWALAND     -4.405e-01  1.035e+00  -0.425  0.67052    \nPPERSAUT     2.306e-01  4.199e-02   5.491 4.01e-08 ***\nPBESAUT      1.215e+01  4.029e+02   0.030  0.97595    \nPMOTSCO     -8.101e-02  1.147e-01  -0.706  0.48006    \nPVRAAUT     -2.106e+00  2.557e+03  -0.001  0.99934    \nPAANHANG     1.014e+00  9.371e-01   1.082  0.27917    \nPTRACTOR     7.229e-01  4.278e-01   1.690  0.09107 .  \nPWERKT      -5.525e+00  4.805e+03  -0.001  0.99908    \nPBROM        2.170e-01  4.865e-01   0.446  0.65559    \nPLEVEN      -2.382e-01  1.170e-01  -2.036  0.04173 *  \nPPERSONG    -4.523e-01  2.094e+00  -0.216  0.82901    \nPGEZONG      1.444e+00  1.029e+00   1.404  0.16033    \nPWAOREG      8.239e-01  5.943e-01   1.386  0.16565    \nPBRAND       2.401e-01  7.714e-02   3.113  0.00185 ** \nPZEILPL     -8.658e+00  3.261e+03  -0.003  0.99788    \nPPLEZIER    -1.886e-01  3.259e-01  -0.579  0.56289    \nPFIETS       3.664e-01  8.325e-01   0.440  0.65985    \nPINBOED     -1.068e+00  8.764e-01  -1.219  0.22301    \nPBYSTAND    -1.676e-01  3.321e-01  -0.505  0.61373    \nAWAPART     -9.293e-01  7.802e-01  -1.191  0.23364    \nAWABEDR      4.197e-01  1.082e+00   0.388  0.69824    \nAWALAND      2.762e-01  3.528e+00   0.078  0.93758    \nAPERSAUT    -3.902e-02  1.772e-01  -0.220  0.82566    \nABESAUT     -7.298e+01  2.417e+03  -0.030  0.97591    \nAMOTSCO      2.418e-01  3.772e-01   0.641  0.52142    \nAVRAAUT     -4.490e+00  1.078e+04   0.000  0.99967    \nAAANHANG    -1.351e+00  1.687e+00  -0.801  0.42322    \nATRACTOR    -2.376e+00  1.524e+00  -1.559  0.11899    \nAWERKT      -8.749e-01  9.682e+03   0.000  0.99993    \nABROM       -1.060e+00  1.549e+00  -0.684  0.49367    \nALEVEN       4.789e-01  2.245e-01   2.133  0.03291 *  \nAPERSONG     3.997e-01  4.329e+00   0.092  0.92644    \nAGEZONG     -3.163e+00  2.706e+00  -1.169  0.24247    \nAWAOREG     -3.212e+00  3.433e+00  -0.936  0.34939    \nABRAND      -4.118e-01  2.787e-01  -1.477  0.13956    \nAZEILPL      1.047e+01  3.261e+03   0.003  0.99744    \nAPLEZIER     2.516e+00  1.010e+00   2.490  0.01276 *  \nAFIETS       2.318e-01  5.699e-01   0.407  0.68420    \nAINBOED      1.947e+00  1.412e+00   1.378  0.16812    \nABYSTAND     1.078e+00  1.103e+00   0.977  0.32870    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2635.5  on 5821  degrees of freedom\nResidual deviance: 2243.5  on 5736  degrees of freedom\nAIC: 2415.5\n\nNumber of Fisher Scoring iterations: 17\n\n\non a ici un modèle avec beaucoup de variable. Mais si on analyse le summary, on constate que seulement 6 varaibales sont significative.\nRegardons un peu le VIF pour toutes les variables.\n\n\nShow the code\nmy_VIFplot(vif(mod1))\n\n\n\n\n\n\n\n\n\nOn constate la présence de beaucoup de variables avec un VIF très élevé et donc une forte colinéarité indiquant bien qu’il va falloir sélectionner les variables à garder dans notre modèle."
  },
  {
    "objectID": "posts/Exercice_04.html#sélecion-automatique",
    "href": "posts/Exercice_04.html#sélecion-automatique",
    "title": "Exercice 4",
    "section": "Sélecion automatique",
    "text": "Sélecion automatique\n\nAICBIC\n\n\n\nForwardBackwardBoth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nForwardBackwardBoth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAprès toute ces modélisations, rappelons nous tout de même l’objectif de l’assureur est de démarcher des clients de manière ciblée pour leurs faire souscrire une assurance caravane. On pourrait alors de demander : s’il démarchait les clients de façon aléatoire, sans tenir compte de leurs caractéristiques, quel serait environ son taux de réussite ?\nPour cela il suffit juste de ce rappeler du pourcentage donné précédemment qui nous disait la proportion de oui actuellement.\n\n\nShow the code\nround(table(Caravan$Purchase)*100/nrow(Caravan), 3)\n\n\n\n    No    Yes \n94.023  5.977 \n\n\nLe pourcentage étant très bas, on va souhaiter utiliser l’un des 3 modèles estimés ci-dessus (le global, un de ceux sélectionnés par AIC et un de ceux sélectionnés par BIC) pour cibler les clients à démarcher.\nAinsi on regardera\nSi l’on choisissait de démarcher tous les clients ayant une probabilité de souscrire l’assurance supérieure à 0.5, quel pourcentage de clients cela représenterait il pour chacun des 3 modèles estimés ? Quel seuil faudrait-il choisir à la place de 0.5 pour que ce pourcentage corresponde à environ 6% des clients ? On décide dans la suite de fixer ce seuil à 0.2 et on cherche à sélectionner le meilleur modèle parmi les 3 précédents."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistique en grande dimension",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n         \n          Modified - Oldest\n        \n         \n          Modified - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nExercice 01\n\n\n33 min\n\n\n\nregression linéaire\n\n\nselection de variable\n\n\n\nIl s’agit d’une première utilisation des méthodes de regression avec selection de variable via des approches stepwise sur des données de baseball\n\n\n\nClément Poupelin\n\n\nFeb 17, 2025\n\n\n\n\n\n2/21/25, 12:06:58 PM\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 02\n\n\n8 min\n\n\n\nregression linéaire\n\n\nselection de variable\n\n\n\nIci, on continu sur des données de baseball à utilser des méthodes de regression avec selection de variable en testant cette fois ci le lien linéaire existant et en mettant…\n\n\n\nClément Poupelin\n\n\nFeb 17, 2025\n\n\n\n\n\n2/21/25, 12:07:21 PM\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 03\n\n\n12 min\n\n\n\nregression linéaire\n\n\nvalidation croisée\n\n\n\nPremière essais de techniques de validations croisées sur des données générées manuellement\n\n\n\nClément Poupelin\n\n\nFeb 17, 2025\n\n\n\n\n\n2/21/25, 12:08:58 PM\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 04\n\n\n14 min\n\n\n\nTP\n\n\n\nUtilisation des précédentes techniques de selections de variable et de validation croisée dans le cadre de données de grandes dimension avec le jeu de données Caravan\n\n\n\nClément Poupelin\n\n\nInvalid Date\n\n\n\n\n\n2/20/25, 1:27:34 PM\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 05\n\n\n14 min\n\n\n\nregression logistique\n\n\nbiais de sélection\n\n\nCorrelations fortuites\n\n\nvalidation croisée\n\n\n\nOn va illustrer dans ce document les problèmes de biais de séléction et de corrélation fortuite pour des données simulé\n\n\n\nClément Poupelin\n\n\nFeb 21, 2025\n\n\n\n\n\n2/21/25, 12:03:43 PM\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 06\n\n\n1 min\n\n\n\nTP\n\n\n\nDescription\n\n\n\nClément Poupelin\n\n\nInvalid Date\n\n\n\n\n\n2/20/25, 1:27:53 PM\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 06 Bonus : Ridge vs Lasso\n\n\n14 min\n\n\n\nBonus\n\n\n\nComparaison de la regression Ridge et Lasso via le github de Laurent Rouvière\n\n\n\nClément Poupelin\n\n\nInvalid Date\n\n\n\n\n\n2/20/25, 1:27:59 PM\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 07\n\n\n1 min\n\n\n\nTP\n\n\n\nDescription\n\n\n\nClément Poupelin\n\n\nInvalid Date\n\n\n\n\n\n2/20/25, 1:28:12 PM\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 08\n\n\n1 min\n\n\n\nTP\n\n\n\nDescription\n\n\n\nClément Poupelin\n\n\nInvalid Date\n\n\n\n\n\n2/20/25, 1:28:19 PM\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 09\n\n\n14 min\n\n\n\nTP\n\n\n\nComparaison de différents modèles de regression\n\n\n\nClément Poupelin\n\n\nInvalid Date\n\n\n\n\n\n2/20/25, 1:28:25 PM\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 10\n\n\n1 min\n\n\n\nTP\n\n\n\nDescription\n\n\n\nClément Poupelin\n\n\nInvalid Date\n\n\n\n\n\n2/20/25, 12:13:19 PM\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 11\n\n\n1 min\n\n\n\nTP\n\n\n\nDescription\n\n\n\nClément Poupelin\n\n\nInvalid Date\n\n\n\n\n\n2/20/25, 12:13:42 PM\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 12\n\n\n1 min\n\n\n\nTP\n\n\n\nDescription\n\n\n\nClément Poupelin\n\n\nInvalid Date\n\n\n\n\n\n2/20/25, 12:14:00 PM\n\n\n\n\n\n\n\nNo matching items"
  }
]