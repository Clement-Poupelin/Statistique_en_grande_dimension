[
  {
    "objectID": "posts/Exercice_Bonus.html",
    "href": "posts/Exercice_Bonus.html",
    "title": "Exercice Bonus : Ridge vs Lasso",
    "section": "",
    "text": "Source : https://lrouviere.github.io/TUTO_GRANDE_DIM/correction/03-ridge-lasso.html\n\n\nCode\n# ozone &lt;- read.csv(\"~/1.Workspace/Master_IS/M2/X3MS020_Statistique_en_grande_dimension/ozone.txt\", sep=\"\")\nozone &lt;-read.table(\"https://r-stat-sc-donnees.github.io/ozone.txt\", header=TRUE)\nhead(ozone)\n\n\n         maxO3   T9  T12  T15 Ne9 Ne12 Ne15     Vx9    Vx12    Vx15 maxO3v\n20010601    87 15.6 18.5 18.4   4    4    8  0.6946 -1.7101 -0.6946     84\n20010602    82 17.0 18.4 17.7   5    5    7 -4.3301 -4.0000 -3.0000     87\n20010603    92 15.3 17.6 19.5   2    5    4  2.9544  1.8794  0.5209     82\n20010604   114 16.2 19.7 22.5   1    1    0  0.9848  0.3473 -0.1736     92\n20010605    94 17.4 20.5 20.4   8    8    7 -0.5000 -2.9544 -4.3301    114\n20010606    80 17.7 19.8 18.3   6    6    7 -5.6382 -5.0000 -6.0000     94\n          vent pluie\n20010601  Nord   Sec\n20010602  Nord   Sec\n20010603   Est   Sec\n20010604  Nord   Sec\n20010605 Ouest   Sec\n20010606 Ouest Pluie\n\n\nCode\nsummary(ozone)\n\n\n     maxO3              T9             T12             T15       \n Min.   : 42.00   Min.   :11.30   Min.   :14.00   Min.   :14.90  \n 1st Qu.: 70.75   1st Qu.:16.20   1st Qu.:18.60   1st Qu.:19.27  \n Median : 81.50   Median :17.80   Median :20.55   Median :22.05  \n Mean   : 90.30   Mean   :18.36   Mean   :21.53   Mean   :22.63  \n 3rd Qu.:106.00   3rd Qu.:19.93   3rd Qu.:23.55   3rd Qu.:25.40  \n Max.   :166.00   Max.   :27.00   Max.   :33.50   Max.   :35.50  \n      Ne9             Ne12            Ne15           Vx9         \n Min.   :0.000   Min.   :0.000   Min.   :0.00   Min.   :-7.8785  \n 1st Qu.:3.000   1st Qu.:4.000   1st Qu.:3.00   1st Qu.:-3.2765  \n Median :6.000   Median :5.000   Median :5.00   Median :-0.8660  \n Mean   :4.929   Mean   :5.018   Mean   :4.83   Mean   :-1.2143  \n 3rd Qu.:7.000   3rd Qu.:7.000   3rd Qu.:7.00   3rd Qu.: 0.6946  \n Max.   :8.000   Max.   :8.000   Max.   :8.00   Max.   : 5.1962  \n      Vx12             Vx15            maxO3v           vent          \n Min.   :-7.878   Min.   :-9.000   Min.   : 42.00   Length:112        \n 1st Qu.:-3.565   1st Qu.:-3.939   1st Qu.: 71.00   Class :character  \n Median :-1.879   Median :-1.550   Median : 82.50   Mode  :character  \n Mean   :-1.611   Mean   :-1.691   Mean   : 90.57                     \n 3rd Qu.: 0.000   3rd Qu.: 0.000   3rd Qu.:106.00                     \n Max.   : 6.578   Max.   : 5.000   Max.   :166.00                     \n    pluie          \n Length:112        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nCode\nlibrary(psych)\n\n\nWarning: le package 'psych' a été compilé avec la version R 4.2.3\n\n\nCode\npairs.panels(ozone)\n\n\n\n\n\nCode\nozone.X &lt;- model.matrix(maxO3~.,data=ozone)[,-1] #  codage des variables qualitatives avec la fonction model.matrix\nozone.Y &lt;- ozone$maxO3\n\nlibrary(glmnet)\n\n\nWarning: le package 'glmnet' a été compilé avec la version R 4.2.3\n\n\nLe chargement a nécessité le package : Matrix\n\n\nWarning: le package 'Matrix' a été compilé avec la version R 4.2.3\n\n\nLoaded glmnet 4.1-8\n\n\nCode\nmod.R &lt;- glmnet(ozone.X, ozone.Y, alpha=0) ## Ridge \n\nmod.L &lt;- glmnet(ozone.X, ozone.Y, alpha=1) ## Lasso\n\n# Par défaut standardize = TRUE, intercept = TRUE\n\n## Analyse Modèle Ridge\nmod.R$lambda |&gt; head()\n\n\n[1] 22007.27 20052.20 18270.82 16647.69 15168.76 13821.21\n\n\nCode\n# When alpha=0, the largest lambda reported does not quite give \n# the zero coefficients reported (lambda=inf would in principle).\n# Instead, the largest lambda for alpha=0.001 is used, and the sequence \n# of lambda values is derived from this.\n\n\nmod.R$beta[,1]\n\n\n           T9           T12           T15           Ne9          Ne12 \n 6.376767e-36  5.523924e-36  4.867402e-36 -6.821464e-36 -7.994984e-36 \n         Ne15           Vx9          Vx12          Vx15        maxO3v \n-5.839057e-36  5.706014e-36  4.387350e-36  3.970583e-36  6.892387e-37 \n     ventNord     ventOuest       ventSud      pluieSec \n-5.830507e-36 -1.022483e-35  1.519222e-35  2.772246e-35 \n\n\nCode\n# Our coefficients\n\npar(mfrow=c(1,2))\nplot(mod.R,label=TRUE)  \n# lecture du graphe : \n#   - chaque courbe c'est lévolution d'un beta\n#   - à droite on à les valeurs de beta MCO \n#   - à gauche c'est quand lambda augmente, on tend vers 0\n\nplot(mod.R,xvar=\"lambda\",label=TRUE)\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\n\n\n\n\n\n\n\n## Analyse Modèle Lasso\nmod.L$lambda |&gt; head()\n\n\n[1] 22.00727 20.05220 18.27082 16.64769 15.16876 13.82121\n\n\nCode\nmod.L$beta[,1]\n\n\n       T9       T12       T15       Ne9      Ne12      Ne15       Vx9      Vx12 \n        0         0         0         0         0         0         0         0 \n     Vx15    maxO3v  ventNord ventOuest   ventSud  pluieSec \n        0         0         0         0         0         0 \n\n\nCode\npar(mfrow=c(1,2))\nplot(mod.L,label=TRUE)  \nplot(mod.L,xvar=\"lambda\",label=TRUE)\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\n\n####\n# Sélection des paramètres de régularisation ####\n\nridgeCV &lt;- cv.glmnet(ozone.X, ozone.Y, alpha=0)\nplot(ridgeCV)\n\n\n\n\n\nCode\n# abline(v=log(ridgeCV$lambda.1se), col='red')\n# abline(v=log(ridgeCV$lambda.min), col='red')\n\n# On visualise les erreurs quadratiques calculées \n# par validation croisée 10 blocs en fonction de lambda (échelle log)\n\n# Deux traites verticaux :\n#   - celui de gauche correspond à la valeur de `lambda`\n#     qui minimise l’erreur quadratique ;\n# \n#   - celui de droite correspond à la plus grande valeur de `lambda` \n#     telle que l’erreur ne dépasse pas \n#     l’erreur minimale + 1 écart-type estimé de cette erreur.\n\n\n# D’un point de vu pratique, cela signifie que l’utilisateur\n# peut choisir n’importe quelle valeur de lambda entre \n# les deux traits verticaux. Si on veut diminuer \n# la complexité du modèle on choisira la valeur de droite.\n# On peut obtenir ces deux valeurs \n\nridgeCV$lambda.min\n\n\n[1] 9.750588\n\n\nCode\nridgeCV$lambda.1se\n\n\n[1] 43.20116\n\n\nCode\nlassoCV &lt;- cv.glmnet(ozone.X, ozone.Y, alpha=1)\nplot(lassoCV)\n\n\n\n\n\nCode\n# abline(v=log(lassoCV$lambda.1se), col='red')\n# abline(v=log(lassoCV$lambda.min), col='red')\n\nlassoCV$lambda.min\n\n\n[1] 1.230385\n\n\nCode\nlassoCV$lambda.1se\n\n\n[1] 4.967084\n\n\nCode\n####\n# Prédiction de la variable cible pour de nouveaux individus ####\n\n# Première approche :\n# réajuster le modèle sur toutes les données pour la valeur \n# de lambda sélectionnée.\n# Cette étape est en réalité déjà effectuée par la fonction cv.glmnet.\n# Il suffit par conséquent d’appliquer la fonction predict à l’objet \n# obtenu avec cv.glmnet en spécifiant la valeur de lambda souhaitée.\npredict(ridgeCV, newx = ozone.X[50:51,],s=\"lambda.min\")\n\n\n         lambda.min\n20010723   90.10981\n20010724   96.74374\n\n\nCode\npredict(ridgeCV, newx = ozone.X[50:51,],s=\"lambda.1se\")\n\n\n         lambda.1se\n20010723   93.23058\n20010724   96.21185\n\n\nCode\npredict(lassoCV, newx = ozone.X[50:51,],s=\"lambda.min\")\n\n\n         lambda.min\n20010723   87.18235\n20010724   98.23752\n\n\nCode\npredict(lassoCV, newx = ozone.X[50:51,],s=\"lambda.1se\")\n\n\n         lambda.1se\n20010723   87.44713\n20010724   95.61077\n\n\nCode\n# Comparaison performances MCO, ridge et lasso ####\n\n# validation croisée pour comparer les performances des estimateurs\n# MCO, ridge et lasso.\n# On pourra utiliser les données ozone_complet.txt\n# qui contiennent plus d’individus et de variables.\n\n# ozone1 &lt;- read.csv(\"~/1. Workspace/Master IS/M2/X3MS020 Statistique en grande dimension/ozone_complet.txt\", sep=\";\") |&gt; na.omit()\nozone1 &lt;-read.table(\"https://r-stat-sc-donnees.github.io/ozone.txt\", header=TRUE) |&gt; na.omit()\nozone1.X &lt;- model.matrix(maxO3~., data=ozone1)[,-1]\nozone1.Y &lt;- ozone1$maxO3\n\nlibrary(tibble)\n\n\nWarning: le package 'tibble' a été compilé avec la version R 4.2.3\n\n\nCode\nlibrary(dplyr)\n\n\nWarning: le package 'dplyr' a été compilé avec la version R 4.2.3\n\n\n\nAttachement du package : 'dplyr'\n\n\nLes objets suivants sont masqués depuis 'package:stats':\n\n    filter, lag\n\n\nLes objets suivants sont masqués depuis 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\ncv.ridge.lasso &lt;- function(data,form){\n  set.seed(1234)\n  data.X &lt;- model.matrix(form,data=data)[,-1]\n  data.Y &lt;- data$maxO3\n  blocs &lt;- caret::createFolds(1:nrow(data),k=10)\n  prev &lt;- matrix(0,ncol=3,nrow=nrow(data)) |&gt; as.data.frame()\n  names(prev) &lt;- c(\"lin\",\"ridge\",\"lasso\")\n  for (k in 1:10){\n    app &lt;- data[-blocs[[k]],]\n    test &lt;- data[blocs[[k]],]\n    app.X &lt;- data.X[-blocs[[k]],]\n    app.Y &lt;- data.Y[-blocs[[k]]]\n    test.X &lt;- data.X[blocs[[k]],]\n    test.Y &lt;- data.Y[blocs[[k]]]\n    ridge &lt;- cv.glmnet(app.X,app.Y,alpha=0)\n    lasso &lt;- cv.glmnet(app.X,app.Y,alpha=1)\n    lin &lt;- lm(form,data=app)\n    prev[blocs[[k]],] &lt;- tibble(lin=predict(lin,newdata=test),\n                                ridge=as.vector(predict(ridge,newx=test.X)),\n                                lasso=as.vector(predict(lasso,newx=test.X)))\n  }\n  err &lt;- prev |&gt; mutate(obs=data$maxO3) |&gt; summarise_at(1:3,~mean((obs-.)^2))\n  return(err)\n}\n\ncv.ridge.lasso(ozone1, form=formula(maxO3~.))\n\n\n       lin    ridge    lasso\n1 247.4596 271.8111 272.9936\n\n\nCode\n# On remarque que les approches régularisées \n# n’apportent rien par rapport aux estimateurs MCO ici.\n# Ceci peut s’expliquer par le fait que le nombre de variables\n# n’est pas très important.\n\n# Considérons toutes les interactions d’ordre 2\ncv.ridge.lasso(ozone1, form=formula(maxO3~.^2))\n\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\nWarning in predict.lm(lin, newdata = test): les prédictions venant d'un modèle\nde rang faible peuvent être trompeuses\n\n\n       lin    ridge    lasso\n1 196622.7 335.9692 268.1647\n\n\nCode\n# Les méthodes régularisées permettent ici de diminuer\n# les erreurs quadratiques de manière intéressante.\n# Cela vient certainement du fait du nombre de \n# variables explicatives qui est beaucoup plus \n# important lorsqu’on prend en compte toutes \n# les interactions d’ordre 2, nous en avons en effet 253 :\nozone2.X &lt;- model.matrix(maxO3~.^2,data=ozone1)[,-1]\ndim(ozone2.X)\n\n\n[1] 112 102"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistique en grande dimension",
    "section": "",
    "text": "Exercice 9\n\n\n\n\n\n\n\nTP\n\n\n\n\nComparaison de différents modèles de regression\n\n\n\n\n\n\nInvalid Date\n\n\nClément Poupelin\n\n\n\n\n\n\n  \n\n\n\n\nExercice Bonus : Ridge vs Lasso\n\n\n\n\n\n\n\nBonus\n\n\n\n\nComparaison de la regression Ridge et Lasso\n\n\n\n\n\n\nInvalid Date\n\n\nClément Poupelin\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/Exercice_9.html",
    "href": "posts/Exercice_9.html",
    "title": "Exercice 9",
    "section": "",
    "text": "On souhaite réaliser une petite étude par simulation pour évaluer les qualités respectives de 4 méthodes d’estimation d’un modèle de régression linéaire. On s’intéresse pour chacune d’elle à ses qualités de sélection de variables et à ses qualités prédictives. Le programme SimusReg.R permet de réaliser cette étude. Il contient deux fonctions, Simudata et la fonction principale fun, et un exemple d’utilisation en fin de programme.\n\n\nCode\nn = 100\np = 500\nX = matrix(rnorm(n*p), n, p)\n\n\n\n\nCode\nlibrary(lars)\n\n\nLoaded lars 1.3\n\n\n\nAttachement du package : 'lars'\n\n\nL'objet suivant est masqué depuis 'package:psych':\n\n    error.bars\n\n\nCode\nlibrary(leaps)\nlibrary(glmnet)\n\n\nWarning: le package 'glmnet' a été compilé avec la version R 4.2.3\n\n\nLe chargement a nécessité le package : Matrix\n\n\nWarning: le package 'Matrix' a été compilé avec la version R 4.2.3\n\n\nLoaded glmnet 4.1-8\n\n\nCode\nDataSimulation = function(n,p){\n  if(p &lt; 4){stop(\"p&gt;3 require\")}\n  # We create our matrix of explanatory variables\n  X = matrix(rnorm(n*p), n, p)\n  \n  # We define our coefficients of regression \n  coeff = matrix(0, p)\n  coeff[1:3] = 2\n  \n  # We build our explanatory variables\n  y = X%*%coeff + rnorm(n, sd = 2)\n  return(list(X = X, y = y, coeff = coeff))\n}\n\n\n\nfun = function(n, p, M = 100){ # By default, we make M = 100 simulation \n  \n  ## Initialization \n  #################\n  selec_method1 = NULL; selec_method2 = NULL; selec_method3 = NULL;\n  taille_method1 = NULL; taille_method2 = NULL; taille_method3 = NULL;\n  prev_method1 = NULL; prev_method2 = NULL; prev_method3 = NULL; prev_method4 = NULL;\n  temps1 = NULL; temps2 = NULL; temps3 = NULL; temps4 = NULL;\n  \n  for(i in 1:M){\n    cat(paste(i, \":\")) # counter to see progress\n    \n    # We define our train set\n    datatrain = DataSimulation(n, p)\n    Xtrain = datatrain$X\n    y = datatrain$y\n    coeff = datatrain$coeff\n    \n    # We define our test set\n    datatest = DataSimulation(n, p)\n    Xtest = datatest$X\n    ytest = datatest$y\n    \n    \n    ## Regression \n    #################\n    \n    # Method 1 : Forward-Hybrid with BIC\n    tic = proc.time()\n    tab = data.frame(y = y, X = Xtrain)\n    fit0 = lm(y~1, tab)\n    fit = lm(y~., tab)\n    tmp = step(fit0, scope = formula(fit),\n               k = log(n), # BIC criteria\n               direction = \"both\", # Hybrid\n               trace = 0)\n    noms = sort(names(tmp$model))\n    selec_method1[i] = identical(\n      noms[-length(noms)], sort(paste(\"X.\", which(coeff != 0), sep = \"\"))\n      )\n    taille_method1[i] = length(noms) - 1\n    prev_method1[i] = mean((predict(tmp,data.frame(X = Xtest)) - ytest)^2)\n    tac = proc.time() - tic\n    temps1[i] = tac[3]\n    \n    # Method 2 : Lasso\n    tic = proc.time()\n    cvglm = cv.glmnet(Xtrain, y) # By default we have Lasso\n    lambda = cvglm$lambda.min\n    coef2 = coef(cvglm, s = lambda)[-1]\n    index = which(coef2 != 0) \n    selec_method2[i] = identical(sort(index), which(coeff != 0))\n    taille_method2[i] = length(index)\n    prev_method2[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n    tac = proc.time() - tic\n    temps2[i] = tac[3]\n    \n    # Methods 3 and 4 : Adaptive Lasso and  Gauss-Lasso  \n    if(length(index) == 0){\n      selec_method3[i] = selec_method2[i]\n      taille_method3[i] = taille_method2[i]\n      prev_method3[i] = prev_method2[i]\n      prev_method4[i] = prev_method2[i]}\n    else{\n      # Adaptive Lasso part\n      cvglm = cv.glmnet(Xtrain, y,\n                        penalty.factor = 1/abs(coef2))\n      lambda = cvglm$lambda.min\n      coef3 = coef(cvglm, s = lambda)[-1]\n      index = which(coef3 != 0) \n      selec_method3[i] = identical(sort(index), which(coeff != 0))\n      taille_method3[i] = length(index)\n      prev_method3[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n      tac = proc.time() - tic\n      temps3[i] = tac[3]\n      \n      # Gauss-Lasso part\n      if(length(index) == 0){\n        prev_method4[i] = mean((mean(y) - ytest)^2)}\n      else{\n        tab = data.frame(y = y, X = Xtrain)\n        reg = lm(y~., \n                 data = tab[, c(1, index + 1)])\n        prev_method4[i] = mean((predict(reg, data.frame(X = Xtest)) - ytest)^2)\n        tac = proc.time() - tic\n        temps4[i] = tac[3]\n      }\n    }\n  }\n  \n  ## Results\n  #################\n  res = list(mean(selec_method1), mean(selec_method2), mean(selec_method3), taille_method1, taille_method2, taille_method3, prev_method1, prev_method2, prev_method3, prev_method4, mean(temps1), mean(temps2), mean(temps3), mean(temps4))\n  \n  names(res) = c(\"selec_method1\", \"selec_method2\", \"selec_method3\", \"taille_method1\", \"taille_method2\", \"taille_method3\", \"prev_method1\", \"prev_method2\", \"prev_method3\", \"prev_method4\", \"temps1\", \"temps2\", \"temps3\", \"temps4\")\n  \n  return(res)\n}\n\nfun2 = function(n, p, M = 100){ # By default, we make M = 100 simulation \n  \n  ## Initialization \n  #################\n  selec_method1 = NULL; selec_method2 = NULL; selec_method3 = NULL;\n  taille_method1 = NULL; taille_method2 = NULL; taille_method3 = NULL;\n  prev_method1 = NULL; prev_method2 = NULL; prev_method3 = NULL; prev_method4 = NULL;\n  temps1 = NULL; temps2 = NULL; temps3 = NULL; temps4 = NULL;\n  \n  for(i in 1:M){\n    cat(paste(i, \":\")) # counter to see progress\n    \n    # We define our train set\n    datatrain = DataSimulation(n, p)\n    Xtrain = datatrain$X\n    y = datatrain$y\n    coeff = datatrain$coeff\n    \n    # We define our test set\n    datatest = DataSimulation(n, p)\n    Xtest = datatest$X\n    ytest = datatest$y\n    \n    \n    ## Regression \n    #################\n    \n    # Method 2 : Lasso\n    tic = proc.time()\n    cvglm = cv.glmnet(Xtrain, y) # By default we have Lasso\n    lambda = cvglm$lambda.min\n    coef2 = coef(cvglm, s = lambda)[-1]\n    index = which(coef2 != 0) \n    selec_method2[i] = identical(sort(index), which(coeff != 0))\n    taille_method2[i] = length(index)\n    prev_method2[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n    tac = proc.time() - tic\n    temps2[i] = tac[3]\n    \n    # Methods 3 and 4 : Adaptive Lasso and  Gauss-Lasso  \n    if(length(index) == 0){\n      selec_method3[i] = selec_method2[i]\n      taille_method3[i] = taille_method2[i]\n      prev_method3[i] = prev_method2[i]\n      prev_method4[i] = prev_method2[i]}\n    else{\n      # Adaptive Lasso part\n      cvglm = cv.glmnet(Xtrain, y,\n                        penalty.factor = 1/abs(coef2))\n      lambda = cvglm$lambda.min\n      coef3 = coef(cvglm, s = lambda)[-1]\n      index = which(coef3 != 0) \n      selec_method3[i] = identical(sort(index), which(coeff != 0))\n      taille_method3[i] = length(index)\n      prev_method3[i] = mean((predict(cvglm, Xtest, s = lambda) - ytest)^2)\n      tac = proc.time() - tic\n      temps3[i] = tac[3]\n      \n      # Gauss-Lasso part\n      if(length(index) == 0){\n        prev_method4[i] = mean((mean(y) - ytest)^2)}\n      else{\n        tab = data.frame(y = y, X = Xtrain)\n        reg = lm(y~., \n                 data = tab[, c(1, index + 1)])\n        prev_method4[i] = mean((predict(reg, data.frame(X = Xtest)) - ytest)^2)\n        tac = proc.time() - tic\n        temps4[i] = tac[3]\n      }\n    }\n  }\n  \n  ## Results\n  #################\n  res = list(mean(selec_method1), mean(selec_method2), mean(selec_method3), taille_method1, taille_method2, taille_method3, prev_method1, prev_method2, prev_method3, prev_method4, mean(temps1), mean(temps2), mean(temps3), mean(temps4))\n  \n  names(res) = c(\"selec_method1\", \"selec_method2\", \"selec_method3\", \"taille_method1\", \"taille_method2\", \"taille_method3\", \"prev_method1\", \"prev_method2\", \"prev_method3\", \"prev_method4\", \"temps1\", \"temps2\", \"temps3\", \"temps4\")\n  \n  return(res)\n}\n\n\n\n\nCode\n###### Exemple\na=fun(50,5,100)\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\n\n\nCode\na$selec_method1\n\n\n[1] 0.9\n\n\nCode\na$selec_method2\n\n\n[1] 0.16\n\n\nCode\na$selec_method3\n\n\n[1] 0.7\n\n\nCode\na$taille_method1\n\n\n  [1] 3 3 4 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3\n [38] 3 3 4 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 4 3 3 3 3 3\n [75] 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 4 3 3\n\n\nCode\na$taille_method2\n\n\n  [1] 5 5 5 4 4 5 3 5 3 5 5 5 5 4 4 4 3 4 4 4 5 4 3 4 5 5 4 4 3 5 5 4 4 4 5 4 4\n [38] 5 4 5 5 5 5 4 5 5 4 4 5 3 5 4 5 5 5 3 3 4 5 4 4 5 4 3 5 4 5 3 5 4 4 4 5 5\n [75] 5 3 4 5 3 4 5 5 5 5 5 5 5 5 3 3 5 5 3 4 5 5 4 4 3 5\n\n\nCode\na$taille_method3\n\n\n  [1] 3 3 5 3 3 5 3 3 3 3 3 3 5 3 3 3 3 3 4 3 3 3 3 3 5 3 3 3 3 4 5 4 3 3 4 3 3\n [38] 4 3 4 3 3 3 3 5 5 3 3 3 3 3 4 3 4 3 3 3 3 5 3 4 4 3 3 4 3 3 3 4 4 3 3 3 4\n [75] 4 3 3 4 3 3 3 5 3 4 3 3 4 3 3 3 5 4 3 3 3 3 3 4 3 3\n\n\nCode\nboxplot(sqrt(a$prev_method1),sqrt(a$prev_method2),sqrt(a$prev_method3),sqrt(a$prev_method4),names=c(\"Method1\",\"Method2\",\"Method3\",\"Method4\"),main=\"Title\")\n\n\n\n\n\nCode\nmean(a$prev_method1)\n\n\n[1] 4.317454\n\n\nCode\nmean(a$prev_method2)\n\n\n[1] 4.482734\n\n\nCode\nmean(a$prev_method3)\n\n\n[1] 4.405399\n\n\nCode\nmean(a$prev_method4)\n\n\n[1] 4.397463\n\n\nCode\na$temps1\n\n\n[1] 0.0363\n\n\nCode\na$temps2\n\n\n[1] 0.0887\n\n\nCode\na$temps3\n\n\n[1] 0.1785\n\n\nCode\na$temps4\n\n\n[1] 0.1824\n\n\n\nQuestion 1\nQuel modèle génère la fonction Simudata ? Combien de variables explicatives sont générées ? Parmi elles, lesquelles sont pertinentes pour la modélisation ? Ecrire l’équation du modèle.\n\n\nQuestion 2\nIdentifier les 4 méthodes d’estimation mises en oeuvre dans la fonction fun.\n\n\nQuestion 3\nDétailler les différentes sorties proposées par la fonction fun.\n\n\nQuestion 4\nRemplacer la valeur des options names et title du boxplot réalisé dans l’exemple par les bonnes informations.\n\n\nCode\nboxplot(sqrt(a$prev_method1),sqrt(a$prev_method2),sqrt(a$prev_method3),sqrt(a$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", 100,\"et p=\", 10),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"),\n        ylim = c(1,3))\n\n\n\n\n\n\n\nQuestion 5\nRéaliser une étude comparative des méthodes lorsque \\(n = 50\\) et \\(p = n/10\\), \\(p = n\\), \\(p = 2n\\), \\(p = 10n\\). Pour chaque situation, on considèrera \\(100\\) simulations afin de calculer les différents critères. On synthétisera les résultats en terme de qualité de sélection, nombre de variables sélectionnées, erreurs de prévision et temps de calcul.\n\n\nCode\n#parallelisation\nfuture::plan(multisession, workers = 2)\n\nn = 50\np_list = c(n/10, n, 2*n, 10*n)\n\nr_cas1 = fun(n, p_list[1])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\nr_cas2 = fun(n, p_list[2])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\nr_cas3 = fun(n, p_list[3])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\nr_cas4 = fun(n, p_list[4],1)\n\n\n1 :\n\n\nCode\nr_cas4bis = fun2(n, p_list[4])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\n# quit parallelisation\nfuture::plan(\"sequential\")\n\n\n\n\nCode\nres_cas1 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas1$selec_method1,r_cas1$selec_method2,r_cas1$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas1$taille_method1),mean(r_cas1$taille_method2),mean(r_cas1$taille_method3),NA),\n  Prevision_error = c(mean(r_cas1$prev_method1),mean(r_cas1$prev_method2),mean(r_cas1$prev_method3),mean(r_cas1$prev_method4)),\n  Running_time = c(r_cas1$temps1,r_cas1$temps2,r_cas1$temps3,r_cas1$temps4)\n)\nt(res_cas1)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.95\"     \"0.24\"     \"0.76\"             NA           \nMean_nb_selected_var \"3.05\"     \"4.19\"     \"3.29\"             NA           \nPrevision_error      \"4.267999\" \"4.372448\" \"4.311278\"         \"4.298561\"   \nRunning_time         \"0.0395\"   \"0.0926\"   \"0.1862\"           \"0.1901\"     \n\n\nCode\nboxplot(sqrt(r_cas1$prev_method1),sqrt(r_cas1$prev_method2),sqrt(r_cas1$prev_method3),sqrt(r_cas1$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[1]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nCode\nres_cas2 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas2$selec_method1,r_cas2$selec_method2,r_cas2$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas2$taille_method1),mean(r_cas2$taille_method2),mean(r_cas2$taille_method3),NA),\n  Prevision_error = c(mean(r_cas2$prev_method1),mean(r_cas2$prev_method2),mean(r_cas2$prev_method3),mean(r_cas2$prev_method4)),\n  Running_time = c(r_cas2$temps1,r_cas2$temps2,r_cas2$temps3,r_cas2$temps4)\n)\nt(res_cas2)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.06\"     \"0.01\"     \"0.09\"             NA           \nMean_nb_selected_var \" 7.92\"    \"12.88\"    \" 8.17\"            NA           \nPrevision_error      \"7.050225\" \"5.609938\" \"5.487207\"         \"6.401796\"   \nRunning_time         \"0.3002\"   \"0.2568\"   \"0.3666\"           \"0.3720\"     \n\n\nCode\nboxplot(sqrt(r_cas2$prev_method1),sqrt(r_cas2$prev_method2),sqrt(r_cas2$prev_method3),sqrt(r_cas2$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[2]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nCode\nres_cas3 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas3$selec_method1,r_cas3$selec_method2,r_cas3$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas3$taille_method1),mean(r_cas3$taille_method2),mean(r_cas3$taille_method3),NA),\n  Prevision_error = c(mean(r_cas3$prev_method1),mean(r_cas3$prev_method2),mean(r_cas3$prev_method3),mean(r_cas3$prev_method4)),\n  Running_time = c(r_cas3$temps1,r_cas3$temps2,r_cas3$temps3,r_cas3$temps4)\n)\nt(res_cas3)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.00\"      \"0.00\"      \"0.06\"             NA           \nMean_nb_selected_var \"40.57\"     \"15.80\"     \" 9.09\"            NA           \nPrevision_error      \"16.207790\" \" 6.138163\" \" 5.738140\"        \" 6.723044\"  \nRunning_time         \"3.0726\"    \"0.2392\"    \"0.3635\"           \"0.3691\"     \n\n\nCode\nboxplot(sqrt(r_cas3$prev_method1),sqrt(r_cas3$prev_method2),sqrt(r_cas3$prev_method3),sqrt(r_cas3$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nCode\nres_cas4 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4$selec_method1,r_cas4$selec_method2,r_cas4$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4$taille_method1),mean(r_cas4$taille_method2),mean(r_cas4$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4$prev_method1),mean(r_cas4$prev_method2),mean(r_cas4$prev_method3),mean(r_cas4$prev_method4)),\n  Running_time = c(r_cas4$temps1,r_cas4$temps2,r_cas4$temps3,r_cas4$temps4)\n)\nt(res_cas4)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \" 0\"        \" 0\"        \" 0\"               NA           \nMean_nb_selected_var \"49\"        \"41\"        \"19\"               NA           \nPrevision_error      \"11.762266\" \" 4.734249\" \" 4.562205\"        \" 5.403622\"  \nRunning_time         \"25.65\"     \" 0.19\"     \" 0.36\"            \" 0.38\"      \n\n\nCode\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4$prev_method2),sqrt(r_cas4$prev_method3),sqrt(r_cas4$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nCode\nres_cas4bis = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4bis$selec_method1,r_cas4bis$selec_method2,r_cas4bis$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4bis$taille_method1),mean(r_cas4bis$taille_method2),mean(r_cas4bis$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4bis$prev_method1),mean(r_cas4bis$prev_method2),mean(r_cas4bis$prev_method3),mean(r_cas4bis$prev_method4)),\n  Running_time = c(r_cas4bis$temps1,r_cas4bis$temps2,r_cas4bis$temps3,r_cas4bis$temps4)\n)\n\n\nWarning in mean.default(r_cas4bis$taille_method1): l'argument n'est ni\nnumérique, ni logique : renvoi de NA\n\n\nWarning in mean.default(r_cas4bis$prev_method1): l'argument n'est ni numérique,\nni logique : renvoi de NA\n\n\nCode\nt(res_cas4bis)\n\n\n                     [,1]      [,2]       [,3]               [,4]         \nMethod               \"Forward\" \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection NA        \"0.00\"     \"0.04\"             NA           \nMean_nb_selected_var NA        \"24.87\"    \"12.34\"            NA           \nPrevision_error      NA        \"7.230664\" \"6.781834\"         \"7.861071\"   \nRunning_time         NA        \"0.1812\"   \"0.3352\"           \"0.3494\"     \n\n\nCode\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4bis$prev_method2),sqrt(r_cas4bis$prev_method3),sqrt(r_cas4bis$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[4]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nQuestion 6\nRéaliser la même étude pour \\(n = 100\\) et \\(p = n/10\\), \\(p = n\\), \\(p = 2n\\), toujours basée sur \\(100\\) simulations dans chaque cas. Considérer de plus le cas \\(p = 10n\\) en ne faisant qu’une seule simulation afin d’en évaluer le temps de calcul. Une fois ce temps analysé, lancer \\(100\\) simulations pour \\(p = 10n\\) mais en omettant la méthode la plus couteuse en temps de calcul.\n\n\nCode\n#parallelisation\nfuture::plan(multisession, workers = 2)\n\nn = 100\np_list = c(n/10, n, 2*n, 10*n)\n\nr_cas1 = fun(n, p_list[1])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\nr_cas2 = fun(n, p_list[2])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\nr_cas3 = fun(n, p_list[3])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\nr_cas4 = fun(n, p_list[4],1)\n\n\n1 :\n\n\nCode\nr_cas4bis = fun2(n, p_list[4])\n\n\n1 :2 :3 :4 :5 :6 :7 :8 :9 :10 :11 :12 :13 :14 :15 :16 :17 :18 :19 :20 :21 :22 :23 :24 :25 :26 :27 :28 :29 :30 :31 :32 :33 :34 :35 :36 :37 :38 :39 :40 :41 :42 :43 :44 :45 :46 :47 :48 :49 :50 :51 :52 :53 :54 :55 :56 :57 :58 :59 :60 :61 :62 :63 :64 :65 :66 :67 :68 :69 :70 :71 :72 :73 :74 :75 :76 :77 :78 :79 :80 :81 :82 :83 :84 :85 :86 :87 :88 :89 :90 :91 :92 :93 :94 :95 :96 :97 :98 :99 :100 :\n\n\nCode\n# quit parallelisation\nfuture::plan(\"sequential\")\n\n\n\n\nCode\nres_cas1 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas1$selec_method1,r_cas1$selec_method2,r_cas1$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas1$taille_method1),mean(r_cas1$taille_method2),mean(r_cas1$taille_method3),NA),\n  Prevision_error = c(mean(r_cas1$prev_method1),mean(r_cas1$prev_method2),mean(r_cas1$prev_method3),mean(r_cas1$prev_method4)),\n  Running_time = c(r_cas1$temps1,r_cas1$temps2,r_cas1$temps3,r_cas1$temps4)\n)\nt(res_cas1)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.71\"     \"0.08\"     \"0.42\"             NA           \nMean_nb_selected_var \"3.30\"     \"6.35\"     \"4.15\"             NA           \nPrevision_error      \"4.270127\" \"4.367182\" \"4.300236\"         \"4.347811\"   \nRunning_time         \"0.0548\"   \"0.0985\"   \"0.2030\"           \"0.2076\"     \n\n\nCode\nboxplot(sqrt(r_cas1$prev_method1),sqrt(r_cas1$prev_method2),sqrt(r_cas1$prev_method3),sqrt(r_cas1$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[1]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nCode\nres_cas2 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas2$selec_method1,r_cas2$selec_method2,r_cas2$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas2$taille_method1),mean(r_cas2$taille_method2),mean(r_cas2$taille_method3),NA),\n  Prevision_error = c(mean(r_cas2$prev_method1),mean(r_cas2$prev_method2),mean(r_cas2$prev_method3),mean(r_cas2$prev_method4)),\n  Running_time = c(r_cas2$temps1,r_cas2$temps2,r_cas2$temps3,r_cas2$temps4)\n)\nt(res_cas2)\n\n\n                     [,1]       [,2]       [,3]               [,4]         \nMethod               \"Forward\"  \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.01\"     \"0.01\"     \"0.10\"             NA           \nMean_nb_selected_var \" 8.11\"    \"14.59\"    \" 7.61\"            NA           \nPrevision_error      \"5.682778\" \"4.824673\" \"4.588443\"         \"5.223387\"   \nRunning_time         \"0.5960\"   \"0.5668\"   \"0.6884\"           \"0.6941\"     \n\n\nCode\nboxplot(sqrt(r_cas2$prev_method1),sqrt(r_cas2$prev_method2),sqrt(r_cas2$prev_method3),sqrt(r_cas2$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[2]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nCode\nres_cas3 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas3$selec_method1,r_cas3$selec_method2,r_cas3$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas3$taille_method1),mean(r_cas3$taille_method2),mean(r_cas3$taille_method3),NA),\n  Prevision_error = c(mean(r_cas3$prev_method1),mean(r_cas3$prev_method2),mean(r_cas3$prev_method3),mean(r_cas3$prev_method4)),\n  Running_time = c(r_cas3$temps1,r_cas3$temps2,r_cas3$temps3,r_cas3$temps4)\n)\nt(res_cas3)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \"0.00\"      \"0.01\"      \"0.16\"             NA           \nMean_nb_selected_var \"48.66\"     \"17.34\"     \" 7.73\"            NA           \nPrevision_error      \"11.428807\" \" 5.016189\" \" 4.523595\"        \" 5.243494\"  \nRunning_time         \"11.0293\"   \" 0.4915\"   \" 0.6252\"          \" 0.6322\"    \n\n\nCode\nboxplot(sqrt(r_cas3$prev_method1),sqrt(r_cas3$prev_method2),sqrt(r_cas3$prev_method3),sqrt(r_cas3$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nCode\nres_cas4 = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4$selec_method1,r_cas4$selec_method2,r_cas4$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4$taille_method1),mean(r_cas4$taille_method2),mean(r_cas4$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4$prev_method1),mean(r_cas4$prev_method2),mean(r_cas4$prev_method3),mean(r_cas4$prev_method4)),\n  Running_time = c(r_cas4$temps1,r_cas4$temps2,r_cas4$temps3,r_cas4$temps4)\n)\nt(res_cas4)\n\n\n                     [,1]        [,2]        [,3]               [,4]         \nMethod               \"Forward\"   \"Lasso\"     \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection \" 0\"        \" 0\"        \" 0\"               NA           \nMean_nb_selected_var \"99\"        \"11\"        \" 6\"               NA           \nPrevision_error      \"11.946047\" \" 5.699005\" \" 4.413508\"        \" 5.439750\"  \nRunning_time         \"233.75\"    \"  0.40\"    \"  0.62\"           \"  0.65\"     \n\n\nCode\nres_cas4bis = data.frame(\n  Method = c(\"Forward\", \"Lasso\", \"Adaptative Lasso\", \"Gauss-Lasso\"), \n  Quality_of_selection = c(r_cas4bis$selec_method1,r_cas4bis$selec_method2,r_cas4bis$selec_method3,NA),\n  Mean_nb_selected_var = c(mean(r_cas4bis$taille_method1),mean(r_cas4bis$taille_method2),mean(r_cas4bis$taille_method3),NA),\n  Prevision_error = c(mean(r_cas4bis$prev_method1),mean(r_cas4bis$prev_method2),mean(r_cas4bis$prev_method3),mean(r_cas4bis$prev_method4)),\n  Running_time = c(r_cas4bis$temps1,r_cas4bis$temps2,r_cas4bis$temps3,r_cas4bis$temps4)\n)\n\n\nWarning in mean.default(r_cas4bis$taille_method1): l'argument n'est ni\nnumérique, ni logique : renvoi de NA\n\n\nWarning in mean.default(r_cas4bis$prev_method1): l'argument n'est ni numérique,\nni logique : renvoi de NA\n\n\nCode\nt(res_cas4bis)\n\n\n                     [,1]      [,2]       [,3]               [,4]         \nMethod               \"Forward\" \"Lasso\"    \"Adaptative Lasso\" \"Gauss-Lasso\"\nQuality_of_selection NA        \"0.00\"     \"0.03\"             NA           \nMean_nb_selected_var NA        \"30.92\"    \"11.07\"            NA           \nPrevision_error      NA        \"5.260876\" \"4.776523\"         \"5.836417\"   \nRunning_time         NA        \"0.3399\"   \"0.5520\"           \"0.5763\"     \n\n\nCode\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4$prev_method2),sqrt(r_cas4$prev_method3),sqrt(r_cas4$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[3]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\nCode\nboxplot(sqrt(r_cas4$prev_method1),sqrt(r_cas4bis$prev_method2),sqrt(r_cas4bis$prev_method3),sqrt(r_cas4bis$prev_method4),\n        names=c(\"Forward\",\"Lasso\",\"Adaptative Lasso\",\"Gauss-Lasso\"),\n        main=paste(\"Erreur de prévision pour n =\", n,\"et p=\", p_list[4]),\n        col = c(\"orchid3\", \"palegreen\", \"salmon2\", \"lightskyblue2\"))\n\n\n\n\n\n\n\nQuestion 7\nConclure sur les mérites respectifs de chaque méthode dans le contexte de l’étude.\n\n\nQuestion 8\nQuelles autres types de simulations pourrait-on envisager pour confirmer ou affiner ces conclusions ?"
  },
  {
    "objectID": "Exercice_1.html",
    "href": "Exercice_1.html",
    "title": "Exercice 1",
    "section": "",
    "text": "Setup\n\npackagesFonctions\n\n\n\nlibrary(ISLR) # Hitters data \nlibrary(leaps) # regsubsets \nlibrary(MASS)\nlibrary(GGally) # pour ggcorr\nlibrary(car) # pour VIF\nlibrary(dplyr)\nlibrary(DT)\n\n## Summary\nlibrary(rstatix)\nlibrary(tibble)\n\n## PCA\nlibrary(FactoMineR)\nlibrary(factoextra)\n\n# Plots\nlibrary(ggplot2)\nlibrary(reshape2)  # Pour transformer les données en format long\nlibrary(gridExtra)\n\n## for pairs panel\nlibrary(psych)\nlibrary(RColorBrewer)\n\n\n\n\nCritèresplot pour nos critères\n\n\n\nr2_fun &lt;- function(y, SCR){\n  # r2 = SSE/SST = (SST - SSR)/SST = 1 - ssr/sst\n  SCT &lt;- sum((y - mean(y) )^2)\n  r2 &lt;- 1 - SCR/SCT\n  return(r2)\n}\n\nr2a_fun &lt;- function(y, SCR){\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  SCT &lt;- sum((y - mean(y) )^2)\n  r2a &lt;- 1 - (SCR/(n-(p+1)))/(SCT/(n-1))\n  return(r2a)\n}\n\ncp_fun &lt;- function(mod, SCR){\n  sig &lt;- summary(mod)$sigma\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  cp &lt;- SCR/sig^2 + 2*(p+1) - n\n  return(cp)\n}\n\naic_fun &lt;- function(SCR){\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  aic &lt;- n * log(SCR/n) + 2*(p+1)\n  return(aic)\n}\n\nbic_fun &lt;- function(SCR){\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  bic &lt;- n * log(SCR/n) + log(n)*(p+1)\n  return(bic)\n}\n\n\n\n\nCriteria_plot &lt;- function(Criteria, crit_name = \"Critère\") {\n  # Création d'un data frame pour ggplot\n  df_criteria &lt;- data.frame(\n    nb_var = seq_along(Criteria),  # Nombre de variables utilisées\n    Criteria = Criteria            # Valeurs du critère (RSS, AIC, BIC, etc.)\n  )\n\n  # Création du plot avec ggplot2\n  g &lt;- ggplot(df_criteria, aes(x = nb_var, y = Criteria)) +\n    geom_line(color = \"#0072B2\", linewidth = 1) +  \n    geom_point(color = \"#D55E00\", size = 4) + \n    labs(\n      title = paste(\"Évolution de\", crit_name, \"en fonction du nombre de variables\"),\n      x = \"Nombre de variables sélectionnées\",\n      y = crit_name\n    ) +\n    theme_minimal() + \n    theme(\n      plot.title = element_text(hjust = 0.5, face = \"bold\", size = 26),  # Titre centré et agrandi\n      axis.title.x = element_text(face = \"bold\", size = 22),\n      axis.title.y = element_text(face = \"bold\", size = 22),\n      axis.text = element_text(size = 20)\n    )\n\n  return(g)\n}\n\n\n\n\n\n\n\n\n\nDonnées\nOn étudie le jeu de données Hitters disponible dans la libraire { ISLR } de R.\nIl s’agit d’un je de données de la Major League Baseball provenant des saisons de 1986 et 1987.\n\n# ?Hitters\nHitters %&gt;%\n  dim()\n\n[1] 322  20\n\nHitters %&gt;%\n  summary()\n\n     AtBat            Hits         HmRun            Runs       \n Min.   : 16.0   Min.   :  1   Min.   : 0.00   Min.   :  0.00  \n 1st Qu.:255.2   1st Qu.: 64   1st Qu.: 4.00   1st Qu.: 30.25  \n Median :379.5   Median : 96   Median : 8.00   Median : 48.00  \n Mean   :380.9   Mean   :101   Mean   :10.77   Mean   : 50.91  \n 3rd Qu.:512.0   3rd Qu.:137   3rd Qu.:16.00   3rd Qu.: 69.00  \n Max.   :687.0   Max.   :238   Max.   :40.00   Max.   :130.00  \n                                                               \n      RBI             Walks            Years            CAtBat       \n Min.   :  0.00   Min.   :  0.00   Min.   : 1.000   Min.   :   19.0  \n 1st Qu.: 28.00   1st Qu.: 22.00   1st Qu.: 4.000   1st Qu.:  816.8  \n Median : 44.00   Median : 35.00   Median : 6.000   Median : 1928.0  \n Mean   : 48.03   Mean   : 38.74   Mean   : 7.444   Mean   : 2648.7  \n 3rd Qu.: 64.75   3rd Qu.: 53.00   3rd Qu.:11.000   3rd Qu.: 3924.2  \n Max.   :121.00   Max.   :105.00   Max.   :24.000   Max.   :14053.0  \n                                                                     \n     CHits            CHmRun           CRuns             CRBI        \n Min.   :   4.0   Min.   :  0.00   Min.   :   1.0   Min.   :   0.00  \n 1st Qu.: 209.0   1st Qu.: 14.00   1st Qu.: 100.2   1st Qu.:  88.75  \n Median : 508.0   Median : 37.50   Median : 247.0   Median : 220.50  \n Mean   : 717.6   Mean   : 69.49   Mean   : 358.8   Mean   : 330.12  \n 3rd Qu.:1059.2   3rd Qu.: 90.00   3rd Qu.: 526.2   3rd Qu.: 426.25  \n Max.   :4256.0   Max.   :548.00   Max.   :2165.0   Max.   :1659.00  \n                                                                     \n     CWalks        League  Division    PutOuts          Assists     \n Min.   :   0.00   A:175   E:157    Min.   :   0.0   Min.   :  0.0  \n 1st Qu.:  67.25   N:147   W:165    1st Qu.: 109.2   1st Qu.:  7.0  \n Median : 170.50                    Median : 212.0   Median : 39.5  \n Mean   : 260.24                    Mean   : 288.9   Mean   :106.9  \n 3rd Qu.: 339.25                    3rd Qu.: 325.0   3rd Qu.:166.0  \n Max.   :1566.00                    Max.   :1378.0   Max.   :492.0  \n                                                                    \n     Errors          Salary       NewLeague\n Min.   : 0.00   Min.   :  67.5   A:176    \n 1st Qu.: 3.00   1st Qu.: 190.0   N:146    \n Median : 6.00   Median : 425.0            \n Mean   : 8.04   Mean   : 535.9            \n 3rd Qu.:11.00   3rd Qu.: 750.0            \n Max.   :32.00   Max.   :2460.0            \n                 NA's   :59                \n\n\n\n\n\n\n\n\nWarning\n\n\n\nOn peut déjà remarquer la présence de 59 valeurs manquantes pour la variable Salary.\n\n\nOn va donc commencer par s’en débarasser (il ne s’agit que de 59 lignes sur 322). Puis on va également se concentrer sur les variables quantitatives .\n\nHitters_Without_NA &lt;- Hitters %&gt;% na.omit()\nHitters_Without_NA_quant &lt;- Hitters_Without_NA %&gt;% subset(, select = -c(League, Division, NewLeague))\n\nHitters_Without_NA_quant %&gt;% dim()\n\n[1] 263  17\n\n\n\n\nAnalyse descriptive\n\nBoxplotCorrelation panelPCA\n\n\nOn peut regarder un peu la distribution de nos différents variables quantitatives via des boxplots.\n\n# Transformer les données en format long pour ggplot\nHitters_long &lt;- melt(Hitters_Without_NA_quant)\n\nggplot(Hitters_long, aes(x = variable, y = value, fill = variable)) +\n  geom_boxplot() +\n  scale_fill_viridis_d() +  # Palette de couleurs harmonieuse\n  labs(title = \"Distribution des Variables (Boxplot)\",\n       x = \"Variables\",\n       y = \"Valeurs\") +\n  theme_minimal() +  # Thème épuré\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotation des étiquettes\n\n\n\n\nOn peut remarquer que nos variables ont en général peut de valeurs outliers.\n\n\nOn regarde ici la corrélation calculée entre chacune de nos variables.\n\npairs.panels(\n  Hitters_Without_NA_quant,\n  method = \"pearson\",      # Méthode de corrélation \n  hist.col = brewer.pal(9, \"Set3\"), # Couleurs des histogrammes\n  density = TRUE,          # Ajout des courbes de densité\n  ellipses = TRUE,         # Ajout d'ellipses \n  smooth = TRUE,           # Ajout de régressions lissées\n  lm = TRUE,               # Ajout des droites de régression\n  col = \"#69b3a2\",         # Couleur des points\n  alpha = 0.5              # Transparence \n)\n\n\n\n\nOn voit la présence de plusieurs fortes corrélations qui peut déjà nous alerter si l’on veut faire des modèles de regressions linéaires car on risque d’avoir un problème de colinéarité entre les varibales explicatives.\n\n\nAvec une Analyse en Composantes Principales (PCA) on peut regarder un peu le comportement de nos données.\nEn effet, Cette méthode respose sur la transformation des variables d’origine en nouvelles variables non corrélées, appelées composantes principales, qui capturent successivement la plus grande variance possible des données.\n\nres_pca &lt;- PCA(Hitters_Without_NA, \n               quali.sup = c(which(colnames(Hitters_Without_NA) %in% c(\"League\", \"Division\", \"NewLeague\"))),\n               quanti.sup = which(colnames(Hitters_Without_NA) == \"Salary\"),\n               graph = FALSE)\n\nIci, on spécifi nos varibales qualitatives et on décide de mettre la variable Salary en variable supplémentaire, ce qui veut d’ire qu’elle ne sera pas considéré pour la formation de nos composantes principales (variable que l’on cherchera à estimer plus tard).\n\nIndividusVariables\n\n\nLe plan des individus est une projection des observations (dans notre cas, les joueurs de baseball) sur les axes principaux de la PCA. Cette visualisation permet d’identifier des regroupements, tendances et anomalies au sein des données.\nAinsi, des individus proches sur le graphique ont des caractéristiques similaires par rapport aux variables utilisées.\nPuis, le placement d’un individu en fonction des axes peut permettre de savoir comment le jouer se caractérise par rapport aux variables qui contribuent le plus à ces axes.\n\nfviz_pca_ind(res_pca, \n             label = \"none\",  # Supprime les noms des individus\n             pointsize = 2,    # Taille des points\n             col.ind = \"cyan3\")\n\n\n\n\nIci, on voit que les joueurs se répartissent bien sur le plan ce qui témoignent de la présence d’une grande variété de type de joueurs.\n\n\nLe cercle des variables est une représentation graphique qui permet d’analyser les relations entre les variables initiales et les composantes principales qui forment nos axes. Il est basé sur les corrélations entre les variables et les axes principaux.\nAinsi, plus une variable est proche du bord du cercle, plus elle est bien représentée sur le plan factoriel et contribue fortement à la formation des axes.\nDe plus, selon l’angle entre deux varibles, on peut faire des suppositions sur leur corrélation :\n\nSi deux variables ont des vecteurs proches (petit angle), elles sont fortement corrélées positivement\nSi deux variables ont des vecteurs opposés (angle proche de 180°), elles sont corrélées négativement\nSi l’angle est proche de 90°, alors les variables ne sont pas corrélées\n\n\nfviz_pca_var(res_pca, \n             col.var = \"purple\",\n             repel = TRUE)\n\n\n\n\nDans notre cas, ce que l’on peut voir c’est que la majorité de nos variables sont bien représentées par nos deux axes (cumulant plus de 70% d’explication). Mais beaucoup semblent aussi fortement corrélées avecla formation de deux groupes et la variable Salary se trouvant au milieu. Cette corrélation ayant déjà pu être observé précédemment.\n\n\n\n\n\n\n\n\nAnalyse inférentielle\nOn désire modéliser le salaire Salary en fonction des variables disponibles.\nOn va donc ajuster un modèle de régression linéaire en utilisant toutes les variables à disposition et analyser la qualité de cet ajustement.\n\nmod1 &lt;- lm(formula = Salary ~ .,\n           Hitters_Without_NA) \nmod1 %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ ., data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-907.62 -178.35  -31.11  139.09 1877.04 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  163.10359   90.77854   1.797 0.073622 .  \nAtBat         -1.97987    0.63398  -3.123 0.002008 ** \nHits           7.50077    2.37753   3.155 0.001808 ** \nHmRun          4.33088    6.20145   0.698 0.485616    \nRuns          -2.37621    2.98076  -0.797 0.426122    \nRBI           -1.04496    2.60088  -0.402 0.688204    \nWalks          6.23129    1.82850   3.408 0.000766 ***\nYears         -3.48905   12.41219  -0.281 0.778874    \nCAtBat        -0.17134    0.13524  -1.267 0.206380    \nCHits          0.13399    0.67455   0.199 0.842713    \nCHmRun        -0.17286    1.61724  -0.107 0.914967    \nCRuns          1.45430    0.75046   1.938 0.053795 .  \nCRBI           0.80771    0.69262   1.166 0.244691    \nCWalks        -0.81157    0.32808  -2.474 0.014057 *  \nLeagueN       62.59942   79.26140   0.790 0.430424    \nDivisionW   -116.84925   40.36695  -2.895 0.004141 ** \nPutOuts        0.28189    0.07744   3.640 0.000333 ***\nAssists        0.37107    0.22120   1.678 0.094723 .  \nErrors        -3.36076    4.39163  -0.765 0.444857    \nNewLeagueN   -24.76233   79.00263  -0.313 0.754218    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 315.6 on 243 degrees of freedom\nMultiple R-squared:  0.5461,    Adjusted R-squared:  0.5106 \nF-statistic: 15.39 on 19 and 243 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNote\n\n\n\nNous sommes sur un modèle comprenant des variables quantitatives et qualitative ce qui le rapproche d’une modélisation ANOVA.\n\n\nQuelques commentaires sur le modèle :\n\nbeaucoup de variables ont un effet non significatif\nle \\(R^2\\) et le \\(R^2_{adjusted}\\) sont autour de 0.5 ce qui témoigne d’une mauvaise qualité d’ajustament du modèle\nl’écart type résiduel est de 315.6 ce qui est assez important et témoigne d’un modèle peu précis\n\nPour tenter de trouver un meilleur ajustment, il est important d’analyser d’avantage le lien entre toutes les variables explicatives. On utilise alors comunément le VIF\n\nvif(mod1) \n\n     AtBat       Hits      HmRun       Runs        RBI      Walks      Years \n 22.944366  30.281255   7.758668  15.246418  11.921715   4.148712   9.313280 \n    CAtBat      CHits     CHmRun      CRuns       CRBI     CWalks     League \n251.561160 502.954289  46.488462 162.520810 131.965858  19.744105   4.134115 \n  Division    PutOuts    Assists     Errors  NewLeague \n  1.075398   1.236317   2.709341   2.214543   4.099063 \n\n\nOn remarque ainsi que beaucoup de valeurs sont supérieur à 10 ce qui s’interprète communément comme la précence d’une forte colinéarité sur nos variables explicatives.\nCette colinéarité se constatait déjà durant les analyses descriptive via les graphes de corrélations (d’où l’importance de ne pas se lancer trop rapidement dans les analyses inférentielles).\nMaintenant, on va donc tenter de trouver le meilleur sous-modèle possible. Pour cela on va suivre la procédure suivante :\n\nmettre en oeuvre une méthode de sélection automatique exhaustive et observer l’évolution des SCR (Sommes de Carrés Résiduels) pour les modèles retenus en fonction de leur taille.\ndéduire de ces SCR le \\(R^2\\), \\(R^2_{adjusted}\\), AIC, BIC et \\(C_p\\) correspondants. Les comparer avec les valeurs fournies dans le summary de regsubsets et tracer leur évolution en fonction de la taille du modèle.\n\nPuis reproduire la même procédure avec des séléctions backward, forward et stepwise\n\n\n\n\n\n\nNote\n\n\n\nUn rappel sur nos critère se trouve dans la partie Setup, onglet fonction, de ce document avec la création de fonction pour les calculés.\n\n\n\nSélection automatiquebackwardforwardboth\n\n\n\nselec_auto &lt;- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"exhaustive\",\n                         nvmax = 19 # maximum size of subsets to examine\n                         )\n# selec_auto %&gt;% summary()\n\nOn va déjà commencer par regarder la valeur du critère en fonction des variables des différents modèles testés.\n\npar(mfrow=c(2,2))\nplot(selec_auto, scale = 'bic') \nplot(selec_auto, scale = 'Cp') \nplot(selec_auto, scale = 'r2') \nplot(selec_auto, scale = 'adjr2') \n\n\n\npar(mfrow=c(1,1))\n\nIci on remarque clairement que toutes nos variables ne sont pas gardés lorsque l’on cherche à optimiser nos critères.\nAussi, on peut voir encore de faibles valeurs pour les \\(R^2\\) et \\(R^2_{adjusted}\\) pouvant témoignés d’un mauvais ajustement de modèle.\n\n\n\n\n\n\nNote\n\n\n\nplot.regsubsets() de leaps ne prend pas directement “aic” comme option de scale. Pour une sélection basée sur AIC, une approche alternative consiste à utiliser la fonction stepAIC() du package MASS, qui permet une sélection pas à pas basée sur AIC.\n\n\nRegardons un peut l’évolution de la Somme des Carrés Résiduels (SCR).\n\nSCR &lt;- summary(selec_auto)$rss\nCriteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\")\n\n\n\n\nMaintenant regardons les autres critères mentionné précédemment\n\nr2 &lt;- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a &lt;- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp &lt;- cp_fun(mod1, SCR)\naic &lt;- aic_fun(SCR)\nbic &lt;- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n\n\n\n\nOn peut ainsi voir que ce sont plutot des modèles entre 5 et 10 variables qui optimisent nos critères (donc pas un modèle avec toutes nos variables).\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\nbest_model_r2 &lt;- which.max(r2)\nselected_vars &lt;- summary(selec_auto)$which[best_model_r2,]\ncat(\"Meilleur modèle selon R2 : Modèle avec\", best_model_r2, \"variables\\n\")\n\nMeilleur modèle selon R2 : Modèle avec 19 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"HmRun\"       \"Runs\"       \n [6] \"RBI\"         \"Walks\"       \"Years\"       \"CAtBat\"      \"CHits\"      \n[11] \"CHmRun\"      \"CRuns\"       \"CRBI\"        \"CWalks\"      \"LeagueN\"    \n[16] \"DivisionW\"   \"PutOuts\"     \"Assists\"     \"Errors\"      \"NewLeagueN\" \n\n\n\nbest_model_r2a &lt;- which.max(r2a)\nselected_vars &lt;- summary(selec_auto)$which[best_model_r2a,]\ncat(\"Meilleur modèle selon AIC : Modèle avec\", best_model_r2a, \"variables\\n\")\n\nMeilleur modèle selon AIC : Modèle avec 11 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CAtBat\"     \n [6] \"CRuns\"       \"CRBI\"        \"CWalks\"      \"LeagueN\"     \"DivisionW\"  \n[11] \"PutOuts\"     \"Assists\"    \n\n\n\nbest_model_cp &lt;- which.min(cp)\nselected_vars &lt;- summary(selec_auto)$which[best_model_cp,]\ncat(\"Meilleur modèle selon AIC : Modèle avec\", best_model_cp, \"variables\\n\")\n\nMeilleur modèle selon AIC : Modèle avec 10 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CAtBat\"     \n [6] \"CRuns\"       \"CRBI\"        \"CWalks\"      \"DivisionW\"   \"PutOuts\"    \n[11] \"Assists\"    \n\n\n\nbest_model_aic &lt;- which.min(aic)\nselected_vars &lt;- summary(selec_auto)$which[best_model_aic,]\ncat(\"Meilleur modèle selon AIC : Modèle avec\", best_model_aic, \"variables\\n\")\n\nMeilleur modèle selon AIC : Modèle avec 10 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n [1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CAtBat\"     \n [6] \"CRuns\"       \"CRBI\"        \"CWalks\"      \"DivisionW\"   \"PutOuts\"    \n[11] \"Assists\"    \n\n\n\nbest_model_bic &lt;- which.min(bic)\nselected_vars &lt;- summary(selec_auto)$which[best_model_bic,]\ncat(\"Meilleur modèle selon BIC : Modèle avec\", best_model_bic, \"variables\\n\")\n\nMeilleur modèle selon BIC : Modèle avec 6 variables\n\nrownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE])\n\n[1] \"(Intercept)\" \"AtBat\"       \"Hits\"        \"Walks\"       \"CRBI\"       \n[6] \"DivisionW\"   \"PutOuts\"    \n\n\nPour finir, comparons un peut les critères que nous avons calculés avec ceux que l’on peut récupérer via le summary de regsubset (pour tous sauf l’AIC qui n’est pas présent).\nPour cela regardons si nous avons régulièrement la valeur 0 (ou valeur proche) :\n\nround(r2-summary(selec_auto)$rsq) %&gt;% mean()\n\n[1] 0\n\nround(r2a-summary(selec_auto)$adjr2) %&gt;% mean()\n\n[1] 0\n\nround(cp-summary(selec_auto)$cp) %&gt;% mean()\n\n[1] 0\n\nround(bic-summary(selec_auto)$bic) %&gt;% mean()\n\n[1] 3214\n\n\non voit une grosse différence seulement pour le BIC donc regardons plus en détail.\n\ngrid.arrange(Criteria_plot(bic, crit_name = \"BIC\"),\n             Criteria_plot(summary(selec_auto)$bic, crit_name = \"BIC regsubstet ajusté\"),\n             ncol = 2)\n\n\n\n\nOn voit que les valeurs sont différentes mais en fait le comportement est identique. Ce qui veut dire que la différence est seulement due à une constant multiplicative près.\n\n\nCette fois ci on va regarder en sélection backward. D’abord, on fait à nouveau avec la fonction regsubset.\n\nselec_back &lt;- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"backward\",\n                         nvmax = 19)\n\n\nSCR &lt;- summary(selec_back)$rss\nr2 &lt;- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a &lt;- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp &lt;- cp_fun(mod1, SCR)\naic &lt;- aic_fun(SCR)\nbic &lt;- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n\n\n\n\nOn peut également utiliser la fonction step de la library { stats }. Pour cela, on part du plus gros modèle défini précédemment par mod1.\n\nn &lt;- dim(Hitters_Without_NA)[1]\nmodselect_back_bic &lt;- step(mod1,\n                       scope = formula(mod1),\n                       trace = FALSE, # trace = TRUE permet de voir le détail des étapes\n                       direction = c(\"backward\"),\n                       k = log(n) # BIC selection\n                       )\n\nPuis on peut regarder le modèle qui optimise le critère utilisé pour la selection.\n\nmodselect_back_bic %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CRuns + CRBI + CWalks + \n    Division + PutOuts, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-794.06 -171.94  -28.48  133.36 2017.83 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  117.15204   65.07016   1.800 0.072985 .  \nAtBat         -2.03392    0.52282  -3.890 0.000128 ***\nHits           6.85491    1.65215   4.149 4.56e-05 ***\nWalks          6.44066    1.52212   4.231 3.25e-05 ***\nCRuns          0.70454    0.24869   2.833 0.004981 ** \nCRBI           0.52732    0.18861   2.796 0.005572 ** \nCWalks        -0.80661    0.26395  -3.056 0.002483 ** \nDivisionW   -123.77984   39.28749  -3.151 0.001824 ** \nPutOuts        0.27539    0.07431   3.706 0.000259 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 314.7 on 254 degrees of freedom\nMultiple R-squared:  0.5281,    Adjusted R-squared:  0.5133 \nF-statistic: 35.54 on 8 and 254 DF,  p-value: &lt; 2.2e-16\n\n\nLa fonction step propose aussi une selection avec AIC et Cp.\n\nAIC\n\n\nmodselect_back_aic &lt;- step(mod1,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"backward\"),\n                       k = 2 # AIC selection\n                       )\n\nmodselect_back_aic %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + \n    CRBI + CWalks + Division + PutOuts + Assists, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-939.11 -176.87  -34.08  130.90 1910.55 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  162.53544   66.90784   2.429 0.015830 *  \nAtBat         -2.16865    0.53630  -4.044 7.00e-05 ***\nHits           6.91802    1.64665   4.201 3.69e-05 ***\nWalks          5.77322    1.58483   3.643 0.000327 ***\nCAtBat        -0.13008    0.05550  -2.344 0.019858 *  \nCRuns          1.40825    0.39040   3.607 0.000373 ***\nCRBI           0.77431    0.20961   3.694 0.000271 ***\nCWalks        -0.83083    0.26359  -3.152 0.001818 ** \nDivisionW   -112.38006   39.21438  -2.866 0.004511 ** \nPutOuts        0.29737    0.07444   3.995 8.50e-05 ***\nAssists        0.28317    0.15766   1.796 0.073673 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.8 on 252 degrees of freedom\nMultiple R-squared:  0.5405,    Adjusted R-squared:  0.5223 \nF-statistic: 29.64 on 10 and 252 DF,  p-value: &lt; 2.2e-16\n\n\n\n\\(C_p\\)\n\n\nmodselect_back_cp &lt;- step(mod1,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"backward\"),\n                       k = 1 # Cp selection\n                       )\n\nmodselect_back_cp %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + \n    CRBI + CWalks + League + Division + PutOuts + Assists, data = Hitters_Without_NA)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-932.2 -175.4  -29.2  130.4 1897.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  135.75122   71.34623   1.903 0.058223 .  \nAtBat         -2.12775    0.53746  -3.959 9.81e-05 ***\nHits           6.92370    1.64612   4.206 3.62e-05 ***\nWalks          5.62028    1.59064   3.533 0.000488 ***\nCAtBat        -0.13899    0.05609  -2.478 0.013870 *  \nCRuns          1.45533    0.39270   3.706 0.000259 ***\nCRBI           0.78525    0.20978   3.743 0.000225 ***\nCWalks        -0.82286    0.26361  -3.121 0.002010 ** \nLeagueN       43.11162   39.96612   1.079 0.281755    \nDivisionW   -111.14603   39.21835  -2.834 0.004970 ** \nPutOuts        0.28941    0.07478   3.870 0.000139 ***\nAssists        0.26883    0.15816   1.700 0.090430 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 251 degrees of freedom\nMultiple R-squared:  0.5426,    Adjusted R-squared:  0.5226 \nF-statistic: 27.07 on 11 and 251 DF,  p-value: &lt; 2.2e-16\n\n\nOn voit que parmi nos modèles, le BIC semble le plus parcimonieux mais de manière général on constate encore des valeurs de \\(R^2\\) et \\(R^2_{adjusted}\\) assez faibles.\n\n\nCette fois ci on va regarder en sélection forward. D’abord, on fait à nouveau avec la fonction regsubset.\n\nselec_forw &lt;- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"forward\",\n                         nvmax = 19)\n\n\nSCR &lt;- summary(selec_forw)$rss\nr2 &lt;- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a &lt;- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp &lt;- cp_fun(mod1, SCR)\naic &lt;- aic_fun(SCR)\nbic &lt;- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n\n\n\n\nOn peut également utiliser la fonction step de la library { stats }. Cette fois ci il faut définir en modèle de départ le plus petit modèle (celui composé seulement de l’intercept).\n\nmod0 &lt;- lm(Salary~1,\n           Hitters_Without_NA)\n\nmodselect_forw_bic &lt;- step(mod0,\n                       scope = formula(mod1),\n                       trace = FALSE, # trace = TRUE permet de voir le détail des étapes\n                       direction = c(\"forward\"),\n                       k = log(n) # BIC selection\n                       )\n\nPuis on peut regarder le modèle qui optimise le critère utilisé pour la selection.\n\nmodselect_forw_bic %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-873.11 -181.72  -25.91  141.77 2040.47 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   91.51180   65.00006   1.408 0.160382    \nCRBI           0.64302    0.06443   9.979  &lt; 2e-16 ***\nHits           7.60440    1.66254   4.574 7.46e-06 ***\nPutOuts        0.26431    0.07477   3.535 0.000484 ***\nDivisionW   -122.95153   39.82029  -3.088 0.002239 ** \nAtBat         -1.86859    0.52742  -3.543 0.000470 ***\nWalks          3.69765    1.21036   3.055 0.002488 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 319.9 on 256 degrees of freedom\nMultiple R-squared:  0.5087,    Adjusted R-squared:  0.4972 \nF-statistic: 44.18 on 6 and 256 DF,  p-value: &lt; 2.2e-16\n\n\nLa fonction step propose aussi une selection avec AIC et Cp.\n\nAIC\n\n\nmodselect_forw_aic &lt;- step(mod0,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"forward\"),\n                       k = 2 # AIC selection\n                       )\n\nmodselect_forw_aic %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-939.11 -176.87  -34.08  130.90 1910.55 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  162.53544   66.90784   2.429 0.015830 *  \nCRBI           0.77431    0.20961   3.694 0.000271 ***\nHits           6.91802    1.64665   4.201 3.69e-05 ***\nPutOuts        0.29737    0.07444   3.995 8.50e-05 ***\nDivisionW   -112.38006   39.21438  -2.866 0.004511 ** \nAtBat         -2.16865    0.53630  -4.044 7.00e-05 ***\nWalks          5.77322    1.58483   3.643 0.000327 ***\nCWalks        -0.83083    0.26359  -3.152 0.001818 ** \nCRuns          1.40825    0.39040   3.607 0.000373 ***\nCAtBat        -0.13008    0.05550  -2.344 0.019858 *  \nAssists        0.28317    0.15766   1.796 0.073673 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.8 on 252 degrees of freedom\nMultiple R-squared:  0.5405,    Adjusted R-squared:  0.5223 \nF-statistic: 29.64 on 10 and 252 DF,  p-value: &lt; 2.2e-16\n\n\n\n\\(C_p\\)\n\n\nmodselect_forw_cp &lt;- step(mod0,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"forward\"),\n                       k = 1 # Cp selection\n                       )\n\nmodselect_forw_cp %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists + League, data = Hitters_Without_NA)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-932.2 -175.4  -29.2  130.4 1897.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  135.75122   71.34623   1.903 0.058223 .  \nCRBI           0.78525    0.20978   3.743 0.000225 ***\nHits           6.92370    1.64612   4.206 3.62e-05 ***\nPutOuts        0.28941    0.07478   3.870 0.000139 ***\nDivisionW   -111.14603   39.21835  -2.834 0.004970 ** \nAtBat         -2.12775    0.53746  -3.959 9.81e-05 ***\nWalks          5.62028    1.59064   3.533 0.000488 ***\nCWalks        -0.82286    0.26361  -3.121 0.002010 ** \nCRuns          1.45533    0.39270   3.706 0.000259 ***\nCAtBat        -0.13899    0.05609  -2.478 0.013870 *  \nAssists        0.26883    0.15816   1.700 0.090430 .  \nLeagueN       43.11162   39.96612   1.079 0.281755    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 251 degrees of freedom\nMultiple R-squared:  0.5426,    Adjusted R-squared:  0.5226 \nF-statistic: 27.07 on 11 and 251 DF,  p-value: &lt; 2.2e-16\n\n\nOn voit que parmi nos modèles, le BIC semble le plus parcimonieux mais de manière général on constate encore des valeurs de \\(R^2\\) et \\(R^2_{adjusted}\\) assez faibles.\n\n\nMaintenant on va regarder en sélection both. On va alors utiliser la fonction step directement.\n\nmodselect_bic &lt;- step(mod0,\n                  scope = formula(mod1),\n                  trace = FALSE,\n                  direction = c(\"both\"),\n                  k = log(n))\nmodselect_bic %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-873.11 -181.72  -25.91  141.77 2040.47 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   91.51180   65.00006   1.408 0.160382    \nCRBI           0.64302    0.06443   9.979  &lt; 2e-16 ***\nHits           7.60440    1.66254   4.574 7.46e-06 ***\nPutOuts        0.26431    0.07477   3.535 0.000484 ***\nDivisionW   -122.95153   39.82029  -3.088 0.002239 ** \nAtBat         -1.86859    0.52742  -3.543 0.000470 ***\nWalks          3.69765    1.21036   3.055 0.002488 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 319.9 on 256 degrees of freedom\nMultiple R-squared:  0.5087,    Adjusted R-squared:  0.4972 \nF-statistic: 44.18 on 6 and 256 DF,  p-value: &lt; 2.2e-16\n\n\n\nmodselect_aic &lt;- step(mod0,\n                  scope = formula(mod1),\n                  trace = FALSE,\n                  direction = c(\"both\"),\n                  k = 2)\nmodselect_aic %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-939.11 -176.87  -34.08  130.90 1910.55 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  162.53544   66.90784   2.429 0.015830 *  \nCRBI           0.77431    0.20961   3.694 0.000271 ***\nHits           6.91802    1.64665   4.201 3.69e-05 ***\nPutOuts        0.29737    0.07444   3.995 8.50e-05 ***\nDivisionW   -112.38006   39.21438  -2.866 0.004511 ** \nAtBat         -2.16865    0.53630  -4.044 7.00e-05 ***\nWalks          5.77322    1.58483   3.643 0.000327 ***\nCWalks        -0.83083    0.26359  -3.152 0.001818 ** \nCRuns          1.40825    0.39040   3.607 0.000373 ***\nCAtBat        -0.13008    0.05550  -2.344 0.019858 *  \nAssists        0.28317    0.15766   1.796 0.073673 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.8 on 252 degrees of freedom\nMultiple R-squared:  0.5405,    Adjusted R-squared:  0.5223 \nF-statistic: 29.64 on 10 and 252 DF,  p-value: &lt; 2.2e-16\n\n\n\nmodselect_cp &lt;- step(mod0,\n                  scope = formula(mod1),\n                  trace = FALSE,\n                  direction = c(\"both\"),\n                  k = 1)\nmodselect_cp %&gt;% summary()\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists + League, data = Hitters_Without_NA)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-932.2 -175.4  -29.2  130.4 1897.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  135.75122   71.34623   1.903 0.058223 .  \nCRBI           0.78525    0.20978   3.743 0.000225 ***\nHits           6.92370    1.64612   4.206 3.62e-05 ***\nPutOuts        0.28941    0.07478   3.870 0.000139 ***\nDivisionW   -111.14603   39.21835  -2.834 0.004970 ** \nAtBat         -2.12775    0.53746  -3.959 9.81e-05 ***\nWalks          5.62028    1.59064   3.533 0.000488 ***\nCWalks        -0.82286    0.26361  -3.121 0.002010 ** \nCRuns          1.45533    0.39270   3.706 0.000259 ***\nCAtBat        -0.13899    0.05609  -2.478 0.013870 *  \nAssists        0.26883    0.15816   1.700 0.090430 .  \nLeagueN       43.11162   39.96612   1.079 0.281755    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 251 degrees of freedom\nMultiple R-squared:  0.5426,    Adjusted R-squared:  0.5226 \nF-statistic: 27.07 on 11 and 251 DF,  p-value: &lt; 2.2e-16\n\n\nMalheuresement, même en sélection both nous avons encore des \\(R^2\\) et \\(R^2_{adjusted}\\) faibles.\n\n\n\n\n\nConclusion\nÀ la lumière des résultats de notre analyse, on peut envisager le modèle both car bien qu’il n’ait pas montré de grandes améliorations en termes de \\(R^2\\) et \\(R^2_{adjusted}\\), il permet de réduire le nombre de variables tout en maintenant celles qui sont significatives. Ce modèle est donc plus parcimonieux tout en conservant des variables importantes. Cependant, une réflexion supplémentaire pourrait être menée sur l’éventuelle suppression de l’intercept, ce qui nécessiterait une validation supplémentaire.\nEn ce qui concerne le choix final du modèle, on peut opté pour celui qui maximise le critère BIC, ce qui nous mène à un modèle avec 6 variables. Le BIC est particulièrement utile pour privilégier un modèle plus simple et plus parcimonieux, ce qui est un atout lorsqu’on cherche à éviter un surajustement. Toutefois, il est important de noter que la qualité de l’ajustement n’est pas optimale, ce qui suggère qu’il pourrait manquer certaines informations pour expliquer pleinement la variable cible (le salaire).\nEnfin, la validité interne est un aspect crucial qui n’a pas été suffisamment exploré dans cette analyse. Il aurait été pertinent de vérifier que toutes les hypothèses sous-jacentes des modèles étaient satisfaites. Cela aurait permis de renforcer la robustesse de nos résultats et de garantir que les conclusions qu’on sont fiables.\nDonc, il serait pertinent d’examiner plus en profondeur la validité interne, notamment en testant les hypothèses de normalité, d’homoscédasticité, et d’indépendance des résidus.\n\n\nSession info\n\nsessioninfo::session_info(pkgs = \"attached\")\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23 ucrt)\n os       Windows 10 x64 (build 22631)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  French_France.utf8\n ctype    French_France.utf8\n tz       Europe/Paris\n date     2025-02-17\n pandoc   3.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package      * version date (UTC) lib source\n car          * 3.1-2   2023-03-30 [1] CRAN (R 4.2.3)\n carData      * 3.0-5   2022-01-06 [1] CRAN (R 4.2.1)\n dplyr        * 1.1.4   2023-11-17 [1] CRAN (R 4.2.3)\n DT           * 0.33    2024-04-04 [1] CRAN (R 4.2.3)\n factoextra   * 1.0.7   2020-04-01 [1] CRAN (R 4.2.1)\n FactoMineR   * 2.9     2023-10-12 [1] CRAN (R 4.2.3)\n GGally       * 2.2.1   2024-02-14 [1] CRAN (R 4.2.3)\n ggplot2      * 3.5.1   2024-04-23 [1] CRAN (R 4.2.3)\n gridExtra    * 2.3     2017-09-09 [1] CRAN (R 4.2.1)\n ISLR         * 1.4     2021-09-15 [1] CRAN (R 4.2.3)\n leaps        * 3.1     2020-01-16 [1] CRAN (R 4.2.1)\n MASS         * 7.3-60  2023-05-04 [1] CRAN (R 4.2.3)\n psych        * 2.4.1   2024-01-18 [1] CRAN (R 4.2.3)\n RColorBrewer * 1.1-3   2022-04-03 [1] CRAN (R 4.2.0)\n reshape2     * 1.4.4   2020-04-09 [1] CRAN (R 4.2.1)\n rstatix      * 0.7.2   2023-02-01 [1] CRAN (R 4.2.1)\n tibble       * 3.2.1   2023-03-20 [1] CRAN (R 4.2.3)\n\n [1] C:/Users/cleme/AppData/Local/R/win-library/4.2\n [2] C:/Program Files/R/R-4.2.1/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "Exercice_1.html#analyse-descriptive",
    "href": "Exercice_1.html#analyse-descriptive",
    "title": "Exercice 1",
    "section": "Analyse descriptive",
    "text": "Analyse descriptive\n\n\nBoxplot\n\n\nCode\n# Transformer les données en format long pour ggplot\nHitters_long &lt;- melt(Hitters_Without_NA)\n\nggplot(Hitters_long, aes(x = variable, y = value, fill = variable)) +\n  geom_boxplot() +\n  scale_fill_viridis_d() +  # Palette de couleurs harmonieuse\n  labs(title = \"Distribution des Variables (Boxplot)\",\n       x = \"Variables\",\n       y = \"Valeurs\") +\n  theme_minimal() +  # Thème épuré\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotation des étiquettes\n\n\n\n\n\n\n\nCorrelation panel\n\n\nCode\nlibrary(psych)\nlibrary(RColorBrewer)\n\n# Palette de couleurs pour la corrélation\ncolorRamp &lt;- colorRampPalette(c(\"blue\", \"white\", \"red\"))\n\n# Création du pairs.panels amélioré\npairs.panels(\n  Hitters_Without_NA,\n  method = \"pearson\",      # Méthode de corrélation (Pearson par défaut)\n  hist.col = brewer.pal(9, \"Set3\"), # Couleurs des histogrammes\n  density = TRUE,          # Ajout des courbes de densité\n  ellipses = TRUE,         # Ajout d'ellipses pour mieux voir les relations\n  smooth = TRUE,           # Ajout de régressions lissées\n  lm = TRUE,               # Ajout des droites de régression\n  col = \"#69b3a2\",         # Couleur des points\n  alpha = 0.5              # Transparence pour éviter le chevauchement\n)\n\n\n\n\n\n\n\n\n\nCode\ny = Hitters_Without_NA$Salary\nx = Hitters_Without_NA[,-19]\nx_quant = x[,-c(14, 15, 19)] # on enlève les variables qualitatives\nggcorr(x_quant)\n\n\n\n\n\nCode\nPCA(Hitters_Without_NA, quanti.sup = 19, quali.sup = c(14, 15, 20))\n\n\n\n\n\n**Results for the Principal Component Analysis (PCA)**\nThe analysis was performed on 263 individuals, described by 20 variables\n*The results are available in the following objects:\n\n   name               \n1  \"$eig\"             \n2  \"$var\"             \n3  \"$var$coord\"       \n4  \"$var$cor\"         \n5  \"$var$cos2\"        \n6  \"$var$contrib\"     \n7  \"$ind\"             \n8  \"$ind$coord\"       \n9  \"$ind$cos2\"        \n10 \"$ind$contrib\"     \n11 \"$quanti.sup\"      \n12 \"$quanti.sup$coord\"\n13 \"$quanti.sup$cor\"  \n14 \"$quali.sup\"       \n15 \"$quali.sup$coord\" \n16 \"$quali.sup$v.test\"\n17 \"$call\"            \n18 \"$call$centre\"     \n19 \"$call$ecart.type\" \n20 \"$call$row.w\"      \n21 \"$call$col.w\"      \n   description                                              \n1  \"eigenvalues\"                                            \n2  \"results for the variables\"                              \n3  \"coord. for the variables\"                               \n4  \"correlations variables - dimensions\"                    \n5  \"cos2 for the variables\"                                 \n6  \"contributions of the variables\"                         \n7  \"results for the individuals\"                            \n8  \"coord. for the individuals\"                             \n9  \"cos2 for the individuals\"                               \n10 \"contributions of the individuals\"                       \n11 \"results for the supplementary quantitative variables\"   \n12 \"coord. for the supplementary quantitative variables\"    \n13 \"correlations suppl. quantitative variables - dimensions\"\n14 \"results for the supplementary categorical variables\"    \n15 \"coord. for the supplementary categories\"                \n16 \"v-test of the supplementary categories\"                 \n17 \"summary statistics\"                                     \n18 \"mean of the variables\"                                  \n19 \"standard error of the variables\"                        \n20 \"weights for the individuals\"                            \n21 \"weights for the variables\"                              \n\n\non voit salaire entre les 2 groupes lorsque celle ci est projetée sur l’espaces [X] etc…\nQuestion 2\n\n\nCode\nmod1 = lm(formula = Salary ~ ., Hitters_Without_NA ) # c'est une ancova car var quanti et quali\nsummary(mod1)\n\n\n\nCall:\nlm(formula = Salary ~ ., data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-907.62 -178.35  -31.11  139.09 1877.04 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  163.10359   90.77854   1.797 0.073622 .  \nAtBat         -1.97987    0.63398  -3.123 0.002008 ** \nHits           7.50077    2.37753   3.155 0.001808 ** \nHmRun          4.33088    6.20145   0.698 0.485616    \nRuns          -2.37621    2.98076  -0.797 0.426122    \nRBI           -1.04496    2.60088  -0.402 0.688204    \nWalks          6.23129    1.82850   3.408 0.000766 ***\nYears         -3.48905   12.41219  -0.281 0.778874    \nCAtBat        -0.17134    0.13524  -1.267 0.206380    \nCHits          0.13399    0.67455   0.199 0.842713    \nCHmRun        -0.17286    1.61724  -0.107 0.914967    \nCRuns          1.45430    0.75046   1.938 0.053795 .  \nCRBI           0.80771    0.69262   1.166 0.244691    \nCWalks        -0.81157    0.32808  -2.474 0.014057 *  \nLeagueN       62.59942   79.26140   0.790 0.430424    \nDivisionW   -116.84925   40.36695  -2.895 0.004141 ** \nPutOuts        0.28189    0.07744   3.640 0.000333 ***\nAssists        0.37107    0.22120   1.678 0.094723 .  \nErrors        -3.36076    4.39163  -0.765 0.444857    \nNewLeagueN   -24.76233   79.00263  -0.313 0.754218    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 315.6 on 243 degrees of freedom\nMultiple R-squared:  0.5461,    Adjusted R-squared:  0.5106 \nF-statistic: 15.39 on 19 and 243 DF,  p-value: &lt; 2.2e-16\n\n\nCode\n# beaucoup de var non significatives\n# r2 et r2aj autour de 0.5 donc pas un bon modèle (mauvaise qualité d'ajustement)\n# ecart type residuel gros (315.6) donc pas precis \n\nvif(mod1)\n\n\n     AtBat       Hits      HmRun       Runs        RBI      Walks      Years \n 22.944366  30.281255   7.758668  15.246418  11.921715   4.148712   9.313280 \n    CAtBat      CHits     CHmRun      CRuns       CRBI     CWalks     League \n251.561160 502.954289  46.488462 162.520810 131.965858  19.744105   4.134115 \n  Division    PutOuts    Assists     Errors  NewLeague \n  1.075398   1.236317   2.709341   2.214543   4.099063 \n\n\nCode\n# beaucoup de valeurs supérieur à 10 qui s'interprète \n# comme la précence d'une forte colinéarité sur nos var explicatives \n# déjà présent au pairs.panels\n\n\nQuestion 3\n\n\nCode\nselec_auto = regsubsets(Salary~., Hitters_Without_NA, method = \"exhaustive\", nvmax = 19)\nsummary(selec_auto)\n\n\nSubset selection object\nCall: regsubsets.formula(Salary ~ ., Hitters_Without_NA, method = \"exhaustive\", \n    nvmax = 19)\n19 Variables  (and intercept)\n           Forced in Forced out\nAtBat          FALSE      FALSE\nHits           FALSE      FALSE\nHmRun          FALSE      FALSE\nRuns           FALSE      FALSE\nRBI            FALSE      FALSE\nWalks          FALSE      FALSE\nYears          FALSE      FALSE\nCAtBat         FALSE      FALSE\nCHits          FALSE      FALSE\nCHmRun         FALSE      FALSE\nCRuns          FALSE      FALSE\nCRBI           FALSE      FALSE\nCWalks         FALSE      FALSE\nLeagueN        FALSE      FALSE\nDivisionW      FALSE      FALSE\nPutOuts        FALSE      FALSE\nAssists        FALSE      FALSE\nErrors         FALSE      FALSE\nNewLeagueN     FALSE      FALSE\n1 subsets of each size up to 19\nSelection Algorithm: exhaustive\n          AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI\n1  ( 1 )  \" \"   \" \"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n2  ( 1 )  \" \"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n3  ( 1 )  \" \"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n4  ( 1 )  \" \"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n5  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n6  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n7  ( 1 )  \" \"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \"*\"   \"*\"    \" \"   \" \" \n8  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \"*\"    \"*\"   \" \" \n9  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n10  ( 1 ) \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n11  ( 1 ) \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n12  ( 1 ) \"*\"   \"*\"  \" \"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n13  ( 1 ) \"*\"   \"*\"  \" \"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n14  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n15  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n16  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \" \"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n17  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \" \"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n18  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \"*\"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n19  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \"*\"   \"*\"    \"*\"   \"*\"    \"*\"   \"*\" \n          CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN\n1  ( 1 )  \" \"    \" \"     \" \"       \" \"     \" \"     \" \"    \" \"       \n2  ( 1 )  \" \"    \" \"     \" \"       \" \"     \" \"     \" \"    \" \"       \n3  ( 1 )  \" \"    \" \"     \" \"       \"*\"     \" \"     \" \"    \" \"       \n4  ( 1 )  \" \"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n5  ( 1 )  \" \"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n6  ( 1 )  \" \"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n7  ( 1 )  \" \"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n8  ( 1 )  \"*\"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n9  ( 1 )  \"*\"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n10  ( 1 ) \"*\"    \" \"     \"*\"       \"*\"     \"*\"     \" \"    \" \"       \n11  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \" \"    \" \"       \n12  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \" \"    \" \"       \n13  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n14  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n15  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n16  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n17  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \"*\"       \n18  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \"*\"       \n19  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \"*\"       \n\n\nCode\nplot(selec_auto) # evolution de la SCres\n\n\n\n\n\nCode\nssr = summary(selec_auto)$rss\nplot(ssr, type = 'l', main = \"Evolution du RSS (ou SCR)\", xlab=\"nb de var\", ylab = \"RSS\")\n\n\n\n\n\nCode\nplot(selec_auto, scale = 'bic') # on peut modif le critère \n\n\n\n\n\n\n\nCode\n# r2 = SSE/SST = (SST - SSR)/SST = 1 - ssr/sst\nsst = sum((y - mean(y) )^2)\nr2 = 1 - ssr/sst\nr2\n\n\n [1] 0.3214501 0.4252237 0.4514294 0.4754067 0.4908036 0.5087146 0.5141227\n [8] 0.5285569 0.5346124 0.5404950 0.5426153 0.5436302 0.5444570 0.5452164\n[15] 0.5454692 0.5457656 0.5459518 0.5460945 0.5461159\n\n\nCode\nsummary(selec_auto)$rsq\n\n\n [1] 0.3214501 0.4252237 0.4514294 0.4754067 0.4908036 0.5087146 0.5141227\n [8] 0.5285569 0.5346124 0.5404950 0.5426153 0.5436302 0.5444570 0.5452164\n[15] 0.5454692 0.5457656 0.5459518 0.5460945 0.5461159\n\n\nCode\n# on compare et si on fait différence (avec un round pour prendre en compte l'erreur machine à 10^-16) on a 0 donc ok\n\n\n\n\nCode\n# r2 ajusté\nn = dim(Hitters_Without_NA)[1]\np = 1:(dim(Hitters_Without_NA)[2]-1)\n\nr2a = 1 - (ssr/(n-(p+1)))/(sst/(n-1))\nr2a\n\n\n [1] 0.3188503 0.4208024 0.4450753 0.4672734 0.4808971 0.4972001 0.5007849\n [8] 0.5137083 0.5180572 0.5222606 0.5225706 0.5217245 0.5206736 0.5195431\n[15] 0.5178661 0.5162219 0.5144464 0.5126097 0.5106270\n\n\nCode\nsummary(selec_auto)$adjr2\n\n\n [1] 0.3188503 0.4208024 0.4450753 0.4672734 0.4808971 0.4972001 0.5007849\n [8] 0.5137083 0.5180572 0.5222606 0.5225706 0.5217245 0.5206736 0.5195431\n[15] 0.5178661 0.5162219 0.5144464 0.5126097 0.5106270\n\n\nCode\nround(r2a-summary(selec_auto)$adjr2)\n\n\n [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n\n\n\n\nCode\n# Cp\nsig = summary(mod1)$sigma\ncp = ssr/sig^2 + 2*(p+1) - n\ncp\n\n\n [1] 104.281319  50.723090  38.693127  27.856220  21.613011  14.023870\n [7]  13.128474   7.400719   6.158685   5.009317   5.874113   7.330766\n[13]   8.888112  10.481576  12.346193  14.187546  16.087831  18.011425\n[19]  20.000000\n\n\nCode\nsummary(selec_auto)$cp\n\n\n [1] 104.281319  50.723090  38.693127  27.856220  21.613011  14.023870\n [7]  13.128474   7.400719   6.158685   5.009317   5.874113   7.330766\n[13]   8.888112  10.481576  12.346193  14.187546  16.087831  18.011425\n[19]  20.000000\n\n\n\n\nCode\n# AIC\naic = n * log(ssr/n) + 2*(p+1)\naic\n\n\n [1] 3115.778 3074.126 3063.853 3054.099 3048.264 3040.846 3039.935 3034.004\n [9] 3032.604 3031.258 3032.042 3033.457 3034.981 3036.542 3038.396 3040.224\n[17] 3042.116 3044.033 3046.021\n\n\nCode\n# BIC\nbic = n * log(ssr/n) + log(n)*(p+1)\nbic\n\n\n [1] 3122.922 3084.842 3078.141 3071.959 3069.697 3065.851 3068.512 3066.153\n [9] 3068.325 3070.552 3074.908 3079.895 3084.991 3090.124 3095.550 3100.951\n[17] 3106.415 3111.904 3117.464\n\n\nCode\nsummary(selec_auto)$bic\n\n\n [1]  -90.84637 -128.92622 -135.62693 -141.80892 -144.07143 -147.91690\n [7] -145.25594 -147.61525 -145.44316 -143.21651 -138.86077 -133.87283\n[13] -128.77759 -123.64420 -118.21832 -112.81768 -107.35339 -101.86391\n[19]  -96.30412\n\n\nCode\n# grosse différence \n# surement différence de formule. \n# Mais, le critère étant à minimisé, \n# on remarque que dans les deux cas, on peut interprété les valeurs de la même manière. \n# Donc surement identique à une cste évolutive près\n\n\n\n\nCode\n## backward\n\nselec_back = regsubsets(Salary~., Hitters_Without_NA, method = \"backward\", nvmax = 19)\nsummary(selec_back)\n\n\nSubset selection object\nCall: regsubsets.formula(Salary ~ ., Hitters_Without_NA, method = \"backward\", \n    nvmax = 19)\n19 Variables  (and intercept)\n           Forced in Forced out\nAtBat          FALSE      FALSE\nHits           FALSE      FALSE\nHmRun          FALSE      FALSE\nRuns           FALSE      FALSE\nRBI            FALSE      FALSE\nWalks          FALSE      FALSE\nYears          FALSE      FALSE\nCAtBat         FALSE      FALSE\nCHits          FALSE      FALSE\nCHmRun         FALSE      FALSE\nCRuns          FALSE      FALSE\nCRBI           FALSE      FALSE\nCWalks         FALSE      FALSE\nLeagueN        FALSE      FALSE\nDivisionW      FALSE      FALSE\nPutOuts        FALSE      FALSE\nAssists        FALSE      FALSE\nErrors         FALSE      FALSE\nNewLeagueN     FALSE      FALSE\n1 subsets of each size up to 19\nSelection Algorithm: backward\n          AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI\n1  ( 1 )  \" \"   \" \"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \"*\"   \" \" \n2  ( 1 )  \" \"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \"*\"   \" \" \n3  ( 1 )  \" \"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \"*\"   \" \" \n4  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \"*\"   \" \" \n5  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \" \"    \"*\"   \" \" \n6  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \" \"    \"*\"   \" \" \n7  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \" \"    \"*\"   \" \" \n8  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \" \"    \"*\"   \"*\" \n9  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n10  ( 1 ) \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n11  ( 1 ) \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n12  ( 1 ) \"*\"   \"*\"  \" \"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n13  ( 1 ) \"*\"   \"*\"  \" \"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n14  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n15  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n16  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \" \"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n17  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \" \"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n18  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \"*\"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n19  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \"*\"   \"*\"    \"*\"   \"*\"    \"*\"   \"*\" \n          CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN\n1  ( 1 )  \" \"    \" \"     \" \"       \" \"     \" \"     \" \"    \" \"       \n2  ( 1 )  \" \"    \" \"     \" \"       \" \"     \" \"     \" \"    \" \"       \n3  ( 1 )  \" \"    \" \"     \" \"       \"*\"     \" \"     \" \"    \" \"       \n4  ( 1 )  \" \"    \" \"     \" \"       \"*\"     \" \"     \" \"    \" \"       \n5  ( 1 )  \" \"    \" \"     \" \"       \"*\"     \" \"     \" \"    \" \"       \n6  ( 1 )  \" \"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n7  ( 1 )  \"*\"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n8  ( 1 )  \"*\"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n9  ( 1 )  \"*\"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n10  ( 1 ) \"*\"    \" \"     \"*\"       \"*\"     \"*\"     \" \"    \" \"       \n11  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \" \"    \" \"       \n12  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \" \"    \" \"       \n13  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n14  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n15  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n16  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n17  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \"*\"       \n18  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \"*\"       \n19  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \"*\"       \n\n\nCode\nmodselect_back = step(mod1, scope = formula(mod1), trace = FALSE, direction = c(\"backward\"), \n                      k = log(n))\n# trace = TRUE permet de voir le détail des étapes\nsummary(modselect_back)\n\n\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CRuns + CRBI + CWalks + \n    Division + PutOuts, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-794.06 -171.94  -28.48  133.36 2017.83 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  117.15204   65.07016   1.800 0.072985 .  \nAtBat         -2.03392    0.52282  -3.890 0.000128 ***\nHits           6.85491    1.65215   4.149 4.56e-05 ***\nWalks          6.44066    1.52212   4.231 3.25e-05 ***\nCRuns          0.70454    0.24869   2.833 0.004981 ** \nCRBI           0.52732    0.18861   2.796 0.005572 ** \nCWalks        -0.80661    0.26395  -3.056 0.002483 ** \nDivisionW   -123.77984   39.28749  -3.151 0.001824 ** \nPutOuts        0.27539    0.07431   3.706 0.000259 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 314.7 on 254 degrees of freedom\nMultiple R-squared:  0.5281,    Adjusted R-squared:  0.5133 \nF-statistic: 35.54 on 8 and 254 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nCode\n## forward\n\n\nselec_for = regsubsets(Salary~., Hitters_Without_NA, method = \"forward\", nvmax = 19)\nsummary(selec_for)\n\n\nSubset selection object\nCall: regsubsets.formula(Salary ~ ., Hitters_Without_NA, method = \"forward\", \n    nvmax = 19)\n19 Variables  (and intercept)\n           Forced in Forced out\nAtBat          FALSE      FALSE\nHits           FALSE      FALSE\nHmRun          FALSE      FALSE\nRuns           FALSE      FALSE\nRBI            FALSE      FALSE\nWalks          FALSE      FALSE\nYears          FALSE      FALSE\nCAtBat         FALSE      FALSE\nCHits          FALSE      FALSE\nCHmRun         FALSE      FALSE\nCRuns          FALSE      FALSE\nCRBI           FALSE      FALSE\nCWalks         FALSE      FALSE\nLeagueN        FALSE      FALSE\nDivisionW      FALSE      FALSE\nPutOuts        FALSE      FALSE\nAssists        FALSE      FALSE\nErrors         FALSE      FALSE\nNewLeagueN     FALSE      FALSE\n1 subsets of each size up to 19\nSelection Algorithm: forward\n          AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI\n1  ( 1 )  \" \"   \" \"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n2  ( 1 )  \" \"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n3  ( 1 )  \" \"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n4  ( 1 )  \" \"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n5  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n6  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n7  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n8  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \" \"    \"*\"   \"*\" \n9  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n10  ( 1 ) \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n11  ( 1 ) \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n12  ( 1 ) \"*\"   \"*\"  \" \"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n13  ( 1 ) \"*\"   \"*\"  \" \"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n14  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n15  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n16  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \" \"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n17  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \" \"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n18  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \"*\"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n19  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \"*\"   \"*\"    \"*\"   \"*\"    \"*\"   \"*\" \n          CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN\n1  ( 1 )  \" \"    \" \"     \" \"       \" \"     \" \"     \" \"    \" \"       \n2  ( 1 )  \" \"    \" \"     \" \"       \" \"     \" \"     \" \"    \" \"       \n3  ( 1 )  \" \"    \" \"     \" \"       \"*\"     \" \"     \" \"    \" \"       \n4  ( 1 )  \" \"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n5  ( 1 )  \" \"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n6  ( 1 )  \" \"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n7  ( 1 )  \"*\"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n8  ( 1 )  \"*\"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n9  ( 1 )  \"*\"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n10  ( 1 ) \"*\"    \" \"     \"*\"       \"*\"     \"*\"     \" \"    \" \"       \n11  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \" \"    \" \"       \n12  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \" \"    \" \"       \n13  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n14  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n15  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n16  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n17  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \"*\"       \n18  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \"*\"       \n19  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \"*\"       \n\n\nCode\nmod0 = lm(Salary~1, Hitters_Without_NA) #on donne le mod de départ \nmodselect_for = step(mod0, scope = formula(mod1), trace = FALSE, direction = c(\"forward\"), \n                     k = log(n))\nsummary(modselect_for)\n\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-873.11 -181.72  -25.91  141.77 2040.47 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   91.51180   65.00006   1.408 0.160382    \nCRBI           0.64302    0.06443   9.979  &lt; 2e-16 ***\nHits           7.60440    1.66254   4.574 7.46e-06 ***\nPutOuts        0.26431    0.07477   3.535 0.000484 ***\nDivisionW   -122.95153   39.82029  -3.088 0.002239 ** \nAtBat         -1.86859    0.52742  -3.543 0.000470 ***\nWalks          3.69765    1.21036   3.055 0.002488 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 319.9 on 256 degrees of freedom\nMultiple R-squared:  0.5087,    Adjusted R-squared:  0.4972 \nF-statistic: 44.18 on 6 and 256 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nCode\n## both \n\nmodselect = step(mod0, scope = formula(mod1), trace = FALSE, direction = c(\"both\"), \n                        k = log(n))\nsummary(modselect)\n\n\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-873.11 -181.72  -25.91  141.77 2040.47 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   91.51180   65.00006   1.408 0.160382    \nCRBI           0.64302    0.06443   9.979  &lt; 2e-16 ***\nHits           7.60440    1.66254   4.574 7.46e-06 ***\nPutOuts        0.26431    0.07477   3.535 0.000484 ***\nDivisionW   -122.95153   39.82029  -3.088 0.002239 ** \nAtBat         -1.86859    0.52742  -3.543 0.000470 ***\nWalks          3.69765    1.21036   3.055 0.002488 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 319.9 on 256 degrees of freedom\nMultiple R-squared:  0.5087,    Adjusted R-squared:  0.4972 \nF-statistic: 44.18 on 6 and 256 DF,  p-value: &lt; 2.2e-16\n\n\npréférable forward car forte multicolinearité (on avance petit à petit) R2 pas dingue autour de 0.5\nQuestion 4\non peut suggérer le both car même si pas trop d’améliortion en r2 et s, on a quand même moins de var et elles sont significatifs (peut etre on peut enlever l’intercept?)\nQuel est le modèle que l’on souhaite garder à la fin? Avec le critère BIC, on garde un modèle à 6 variables. BIC est le critère qui permet d’avoir un modele plus partcimonieux ATTENTION: qualité de l’ajustement n’est pas ouf, donc il nous manque des informations pour expliquer le salaire\nCe qu’on aurait du faire: Faire de la validité interne: s’assurer que les hypothèses sur lesquelles on a basé nos modèles sont satisfaites"
  },
  {
    "objectID": "Exercice_1.html#boxplot",
    "href": "Exercice_1.html#boxplot",
    "title": "Exercice 1",
    "section": "Boxplot",
    "text": "Boxplot\n\n\nCode\n# Transformer les données en format long pour ggplot\nHitters_long &lt;- melt(Hitters_Without_NA_quant)\n\nggplot(Hitters_long, aes(x = variable, y = value, fill = variable)) +\n  geom_boxplot() +\n  scale_fill_viridis_d() +  # Palette de couleurs harmonieuse\n  labs(title = \"Distribution des Variables (Boxplot)\",\n       x = \"Variables\",\n       y = \"Valeurs\") +\n  theme_minimal() +  # Thème épuré\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotation des étiquettes"
  },
  {
    "objectID": "Exercice_1.html#correlation-panel",
    "href": "Exercice_1.html#correlation-panel",
    "title": "Exercice 1",
    "section": "Correlation panel",
    "text": "Correlation panel\n\n\nCode\n# Palette de couleurs pour la corrélation\ncolorRamp &lt;- colorRampPalette(c(\"blue\", \"white\", \"red\"))\n\n# Création du pairs.panels amélioré\npairs.panels(\n  Hitters_Without_NA_quant,\n  method = \"pearson\",      # Méthode de corrélation (Pearson par défaut)\n  hist.col = brewer.pal(9, \"Set3\"), # Couleurs des histogrammes\n  density = TRUE,          # Ajout des courbes de densité\n  ellipses = TRUE,         # Ajout d'ellipses pour mieux voir les relations\n  smooth = TRUE,           # Ajout de régressions lissées\n  lm = TRUE,               # Ajout des droites de régression\n  col = \"#69b3a2\",         # Couleur des points\n  alpha = 0.5              # Transparence pour éviter le chevauchement\n)\n\n\n\n\n\nOn voit la présence de plusieurs fortes corrélations"
  },
  {
    "objectID": "Exercice_1.html#pca",
    "href": "Exercice_1.html#pca",
    "title": "Exercice 1",
    "section": "PCA",
    "text": "PCA\n\n\nCode\nres_pca &lt;- PCA(Hitters_Without_NA, \n               quali.sup = c(which(colnames(Hitters_Without_NA) %in% c(\"League\", \"Division\", \"NewLeague\"))),\n               quanti.sup = which(colnames(Hitters_Without_NA) == \"Salary\"),\n               graph = FALSE)\n\n\n\n\nCode\n# Affichage du plan factoriel des individus (sans labels)\nfviz_pca_ind(res_pca, \n             label = \"none\",  # Supprime les noms des individus\n             pointsize = 2,    # Taille des points\n             col.ind = \"blue\", # Couleur des points\n             title = \"Plan factoriel des individus\")\n\n\n\n\n\nOn ne distingue rien de particulier (cluster de point ou autre).\n\n\nCode\n# Affichage du cercle des variables\nfviz_pca_var(res_pca, \n             col.var = \"purple\",  # Couleur des variables\n             repel = TRUE,           # Évite le chevauchement des labels\n             title = \"Cercle des variables\")\n\n\n\n\n\nOn voit que pour les variables, deux groupes semblent se former avec au milieu la variable salaire."
  },
  {
    "objectID": "Exercice_1.html#packages",
    "href": "Exercice_1.html#packages",
    "title": "Exercice 1",
    "section": "",
    "text": "library(ISLR) # Hitters data \nlibrary(leaps) # regsubsets \nlibrary(MASS)\nlibrary(GGally) # pour ggcorr\nlibrary(car) # pour VIF\nlibrary(dplyr)\nlibrary(DT)\n\n## Summary\nlibrary(rstatix)\nlibrary(tibble)\n\n## PCA\nlibrary(FactoMineR)\nlibrary(factoextra)\n\n# Plots\nlibrary(ggplot2)\nlibrary(reshape2)  # Pour transformer les données en format long\nlibrary(gridExtra)\n\n## for pairs panel\nlibrary(psych)\nlibrary(RColorBrewer)"
  },
  {
    "objectID": "Exercice_1.html#critères",
    "href": "Exercice_1.html#critères",
    "title": "Exercice 1",
    "section": "",
    "text": "r2_fun &lt;- function(y, SCR){\n  # r2 = SSE/SST = (SST - SSR)/SST = 1 - ssr/sst\n  SCT &lt;- sum((y - mean(y) )^2)\n  r2 &lt;- 1 - SCR/SCT\n  return(r2)\n}\n\nr2a_fun &lt;- function(y, SCR){\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  SCT &lt;- sum((y - mean(y) )^2)\n  r2a &lt;- 1 - (SCR/(n-(p+1)))/(SCT/(n-1))\n  return(r2a)\n}\n\ncp_fun &lt;- function(mod, SCR){\n  sig &lt;- summary(mod)$sigma\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  cp &lt;- SCR/sig^2 + 2*(p+1) - n\n  return(cp)\n}\n\naic_fun &lt;- function(SCR){\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  aic &lt;- n * log(SCR/n) + 2*(p+1)\n  return(aic)\n}\n\nbic_fun &lt;- function(SCR){\n  n &lt;- dim(Hitters_Without_NA)[1]\n  p &lt;- 1:(dim(Hitters_Without_NA)[2]-1)\n  bic &lt;- n * log(SCR/n) + log(n)*(p+1)\n  return(bic)\n}"
  },
  {
    "objectID": "Exercice_1.html#fonctions",
    "href": "Exercice_1.html#fonctions",
    "title": "Exercice 1",
    "section": "",
    "text": "Criteria_plot &lt;- function(Criteria, crit_name = \"Critère\") {\n  # Création d'un data frame pour ggplot\n  df_criteria &lt;- data.frame(\n    nb_var = seq_along(Criteria),  # Nombre de variables utilisées\n    Criteria = Criteria            # Valeurs du critère (RSS, AIC, BIC, etc.)\n  )\n\n  # Création du plot avec ggplot2\n  g &lt;- ggplot(df_criteria, aes(x = nb_var, y = Criteria)) +\n    geom_line(color = \"#0072B2\", linewidth = 1) +  \n    geom_point(color = \"#D55E00\", size = 4) + \n    labs(\n      title = paste(\"Évolution de\", crit_name, \"en fonction du nombre de variables\"),\n      x = \"Nombre de variables sélectionnées\",\n      y = crit_name\n    ) +\n    theme_minimal() + \n    theme(\n      plot.title = element_text(hjust = 0.5, face = \"bold\", size = 26),  # Titre centré et agrandi\n      axis.title.x = element_text(face = \"bold\", size = 22),\n      axis.title.y = element_text(face = \"bold\", size = 22),\n      axis.text = element_text(size = 20)\n    )\n\n  return(g)\n}"
  }
]