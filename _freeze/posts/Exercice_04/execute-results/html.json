{
  "hash": "a90b79cedcae8caa1663ce38ba6ed772",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exercice 4\"\nauthor: \"Clément Poupelin\"\ndate: \"2025-02-20\"\nformat: \n  html:\n    embed-resources: false\n    toc: true\n    code-fold: true\n    code-summary: \"Show the code\"\n    code-tools: true\n    toc-location: right\n    page-layout: article\n    code-overflow: wrap\ntoc: true\nnumber-sections: false\neditor: visual\ncategories: [\"TP\"]\nimage: \"/img/caravane.png\"\ndescription: \"Utilisation des précédentes techniques de selections de variable et de validation croisée dans le cadre de données de grandes dimension avec le jeu de données Caravan\"\n---\n\n\n\n# Setup\n\n:::: panel-tabset\n## Packages\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Données\nlibrary(ISLR)         # Caravan data \nlibrary(dplyr)        # manipulation des données\n\n\nlibrary(car)          # pour VIF\n\n\n\n\n\n# Plots\n## ggplot\nlibrary(ggplot2)\nlibrary(gridExtra)\n```\n:::\n\n\n\n## Fonctions\n\n::: panel-tabset\n### boxplot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_boxplot <- function(data) {\n  # Transformer les données en format long pour ggplot\n  data_long <- reshape2::melt(data)\n  \n  ggplot(data_long, aes(x = variable, y = value, fill = variable)) +\n    geom_boxplot() +\n    scale_fill_viridis_d() +  # Palette de couleurs harmonieuse\n    labs(title = \"Distribution des Variables (Boxplot)\", x = \"Variables\", y = \"Valeurs\") +\n    theme_minimal() +  # Thème épuré\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotation des étiquettes\n}\n```\n:::\n\n\n\n### Heatmap\n\n\n\n::: {.cell}\n\n:::\n\n\n\n### VIF plot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_VIFplot <- function(vif) {\n  vif_df <- data.frame(Variable = names(vif), VIF = vif)\n  \n  p <- ggplot(vif_df, aes(\n    x = reorder(Variable, VIF),\n    y = pmin(VIF, 15),\n    fill = VIF > 10\n  )) +\n    geom_bar(stat = \"identity\") +\n    geom_text(aes(label = ifelse(VIF > 10, round(VIF, 1), \"\")), hjust = -0.2, size = 6) +\n    coord_flip() +\n    scale_fill_manual(values = c(\"FALSE\" = \"#0072B2\", \"TRUE\" = \"#D55E00\")) +\n    labs(title = \"Variance Inflation Factor (VIF)\", x = \"Variables\", y = \"VIF (limité à 15)\") +\n    theme_minimal() +\n    theme(\n      axis.title = element_text(size = 34, face = \"bold\"),\n      plot.title = element_text(\n        size = 54,\n        face = \"bold\",\n        hjust = 0.5\n      ),\n      axis.text.x = element_text(size = 26),\n      axis.text.y = element_text(size = 18),\n      legend.text = element_text(size = 30),\n      legend.title = element_text(size = 38, face = \"bold\")\n    )\n  \n  return(p)\n}\n```\n:::\n\n\n\n\n:::\n::::\n\n# Données\n\nOn considère le jeu de données Caravan de la librairie ISLR de R. Ce jeu de données contient, pour 5822 clients d’une assurance, 86 variables décrivant leur profil.\\\nDans ces 86 variables, les variables 1 à 43 contiennent des données sociodémographiques et les variables 44 à 86 la propriété du produit. \\\nA savoir que les données sociodémographiques sont dérivées des codes postaux. Tous les clients vivant dans des zones ayant le même code postal ont les mêmes attributs sociodémographiques.\\\n\nPuis, la dernière variable *Purchase* indique si le client a souscrit une assurance pour caravane ou non. Cela veut donc dire que nos variables sont pour beaucoup qualitative (nominales ou ordinales).\n\nLes détails sur l'information représentée par nos différentes variables se trouvent sur [cette page](http://www.liacs.nl/~putten/library/cc2000/data.html). Le détail ne sera donc pas afficher ici car un peu trop long mais je vous invite à jeter un oeil pour mieux comprendre les données.\n\nAussi, à la vu des dimensions, on se passera d'afficher le *summary()*. Mais n'oublions pas de vérifier s'il y a des valeurs manquantes.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"Y-at-il des valeurs manquantes : \", anyNA(Caravan))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nY-at-il des valeurs manquantes :  FALSE\n```\n\n\n:::\n:::\n\n\n\nPour nos analyses, on s'intéressera à la variable *Purchase*. Celle ci pouvans déjà nous indiquer que le pourcentage de clients ayant souscrit à une assurance caravane est de 5.98%\n\n# Analyse descriptive (pertinent ?? car var quali)\n\n::::::::::::::::::: panel-tabset\n## Boxplot\n\nOn peut regarder un peu la distribution de nos différents variables quantitatives via des boxplots.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_boxplot(Caravan)\n```\n\n::: {.cell-output-display}\n![](Exercice_04_files/figure-html/unnamed-chunk-6-1.png){width=1536}\n:::\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\n\nOn voit que pour nos variables, nous sommes sur des valeurs généralement comprises entre 0 et 10 sauf pour la vairiable *MOSTYPE* représentant ??? qui a des valuers beaucoup plus importante.\n:::\n\nAinsi, ssi l'on veut mieux voir la distribution de nos variables, on peut enlever *MOSTYPE*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_boxplot(Caravan[,-1])\n```\n\n::: {.cell-output-display}\n![](Exercice_04_files/figure-html/unnamed-chunk-7-1.png){width=1536}\n:::\n:::\n\n\n\n## Heatmap\n\nLorsque nos données sont de grandes dimension, des correlation panel deviennent difficile à produire et à lire. On peut donc tenter de passer sur une représentation commune qui est la heatmap. Ici, on fera la heatmap pour nos variable sociodémographiques, pour nos variables de propriété du produit et sur toutes les vaiables.\n\n::: panel-tabset\n\n### Sociodémographiques\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_subset <- Caravan[,1:43]\ndata_long <- reshape2::melt(as.matrix(data_subset))\n\nggplot(data_long, aes(x = Var2, y = Var1, fill = value)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"blue\") +  \n  labs(title = \"Heatmap des 43 premières variables de Caravan\",\n       x = \"Variables\",\n       y = \"Observations\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Exercice_04_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\n\n:::\n\n### Produit\n\n\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\n\n:::\n\n### Tout\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\n\n:::\n\n:::\n\n## PCA\n\nAvec une Analyse en Composantes Principales (PCA) on peut regarder un peu le comportement de nos données.\n\nEn effet, Cette méthode respose sur la transformation des variables d'origine en nouvelles variables non corrélées, appelées composantes principales, qui capturent successivement la plus grande variance possible des données.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_pca <- FactoMineR::PCA(Caravan, \n                           quali.sup = c(which(colnames(Caravan) %in% c(\"Purchase\"))),\n                           graph = FALSE)\n```\n:::\n\n\n\nIci, on spécifi notre variable qualitative en variable supplémentaire, ce qui veut dire qu'elles ne seront pas considérés pour la formation de nos composantes principales (variable que l'on cherchera à estimer plus tard).\n\n:::::::::::: panel-tabset\n#### Barplot des variances\n\nTout d'abord, on peut commencer par regarder le pourcentage de variance expliqué par nos différentes composantes principales.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactoextra::fviz_eig(\n  res_pca,\n  ncp = 15,\n  addlabels = TRUE,\n  barfill = \"coral\",\n  barcolor = \"coral\",\n  ylim = c(0, 15),\n  main = \"Percentage of variance of the 15 first components\"\n)\n```\n\n::: {.cell-output-display}\n![](Exercice_04_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nOn voit ainsi que la variance expliqué par nos deux premiers axes est d'environ 16%. Ce qui est une situation que l'on peut facilement retrouver dans des cas de grandes dimensions avec beaucoup de variables.\n:::\n\n#### Individus\n\nLe plan des individus est une projection des observations sur les axes principaux de la PCA. Cette visualisation permet d’identifier des regroupements, tendances et anomalies au sein des données.\n\nAinsi, des individus proches sur le graphique ont des caractéristiques similaires par rapport aux variables utilisées.\n\nPuis, le placement d'un individu en fonction des axes peut permettre de savoir comment le jouer se caractérise par rapport aux variables qui contribuent le plus à ces axes.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactoextra::fviz_pca_ind(\n  res_pca,\n  label = \"none\",\n  pointsize = 2,\n  habillage = as.factor(Caravan$Purchase),\n  addEllipses = TRUE,\n  ellipse.level = 0.95\n)\n```\n\n::: {.cell-output-display}\n![](Exercice_04_files/figure-html/unnamed-chunk-11-1.png){width=768}\n:::\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nIci on voit une repartition plutot uniforme sur le plan qui ne semble pas permettre de distinguer une séparation forte correspodant à notre variable qualitative.\n:::\n\n#### Variables\n\nLe cercle des variables est une représentation graphique qui permet d’analyser les relations entre les variables initiales et les composantes principales qui forment nos axes. Il est basé sur les corrélations entre les variables et les axes principaux.\n\nAinsi, plus une variable est proche du bord du cercle, plus elle est bien représentée sur le plan factoriel et contribue fortement à la formation des axes. Ici, on utilise le cos2 pour le gradient de couleur qui va aider à l'indentifictation de ces différentes qualitées de représentation.\n\nDe plus, selon l'angle entre deux varibles, on peut faire des suppositions sur leur corrélation :\n\n-   Si deux variables ont des vecteurs proches (petit angle), elles sont fortement corrélées positivement\n\n-   Si deux variables ont des vecteurs opposés (angle proche de 180°), elles sont corrélées négativement\n\n-   Si l’angle est proche de 90°, alors les variables ne sont pas corrélées\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactoextra::fviz_pca_var(\n  res_pca,\n  col.var = \"cos2\",\n  gradient.cols = rainbow(n = 8, start = .6, end = .9),\n  repel = TRUE\n)\n```\n\n::: {.cell-output-display}\n![](Exercice_04_files/figure-html/unnamed-chunk-12-1.png){width=1152}\n:::\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nIci aussi, du fait du grand nombre de variable il est difficile de dicerner quelque chose de pertinent.\n\nMaintenant, certaines variables sont tout de même bien représenter sur nos premiers axes et sont assez proche, ce qui témoigne d'une corrélation entre elles.\n:::\n::::::::::::\n:::::::::::::::::::\n\n# Analyse inférentielle\n\n## Modèle brut\n\nAjustons un modèle de régression logistique modélisant la probabilité de souscrire une assurance caravane en fonction de toutes les autres variables à disposition\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod1 <- glm(Caravan$Purchase~.,\n                family = binomial,\n                Caravan)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: glm.fit: des probabilités ont été ajustées numériquement à 0 ou 1\n```\n\n\n:::\n\n```{.r .cell-code}\nmod1 %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = Caravan$Purchase ~ ., family = binomial, data = Caravan)\n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  2.542e+02  1.116e+04   0.023  0.98183    \nMOSTYPE      6.580e-02  4.624e-02   1.423  0.15468    \nMAANTHUI    -1.832e-01  1.927e-01  -0.951  0.34157    \nMGEMOMV     -2.696e-02  1.399e-01  -0.193  0.84723    \nMGEMLEEF     2.096e-01  1.016e-01   2.063  0.03911 *  \nMOSHOOFD    -2.767e-01  2.076e-01  -1.333  0.18247    \nMGODRK      -1.142e-01  1.069e-01  -1.068  0.28535    \nMGODPR      -1.910e-02  1.177e-01  -0.162  0.87112    \nMGODOV      -1.618e-02  1.055e-01  -0.153  0.87818    \nMGODGE      -6.817e-02  1.113e-01  -0.612  0.54024    \nMRELGE       2.310e-01  1.566e-01   1.475  0.14031    \nMRELSA       8.509e-02  1.466e-01   0.580  0.56169    \nMRELOV       1.467e-01  1.562e-01   0.939  0.34759    \nMFALLEEN    -8.291e-02  1.311e-01  -0.633  0.52702    \nMFGEKIND    -1.154e-01  1.337e-01  -0.863  0.38813    \nMFWEKIND    -8.140e-02  1.417e-01  -0.575  0.56561    \nMOPLHOOG     9.717e-04  1.311e-01   0.007  0.99408    \nMOPLMIDD    -9.077e-02  1.365e-01  -0.665  0.50605    \nMOPLLAAG    -1.994e-01  1.376e-01  -1.449  0.14740    \nMBERHOOG     8.883e-02  9.349e-02   0.950  0.34204    \nMBERZELF     3.918e-02  9.897e-02   0.396  0.69219    \nMBERBOER    -1.169e-01  1.104e-01  -1.059  0.28951    \nMBERMIDD     1.353e-01  9.191e-02   1.472  0.14106    \nMBERARBG     3.976e-02  9.067e-02   0.438  0.66104    \nMBERARBO     9.954e-02  9.143e-02   1.089  0.27628    \nMSKA         2.690e-02  1.035e-01   0.260  0.79502    \nMSKB1       -8.801e-03  1.011e-01  -0.087  0.93064    \nMSKB2        1.200e-02  9.081e-02   0.132  0.89485    \nMSKC         9.016e-02  9.958e-02   0.905  0.36527    \nMSKD        -2.468e-02  9.724e-02  -0.254  0.79967    \nMHHUUR      -1.472e+01  8.140e+02  -0.018  0.98557    \nMHKOOP      -1.469e+01  8.140e+02  -0.018  0.98561    \nMAUT1        1.819e-01  1.514e-01   1.202  0.22953    \nMAUT2        1.507e-01  1.371e-01   1.099  0.27162    \nMAUT0        9.325e-02  1.436e-01   0.649  0.51603    \nMZFONDS     -1.445e+01  9.359e+02  -0.015  0.98768    \nMZPART      -1.451e+01  9.359e+02  -0.016  0.98763    \nMINKM30      1.181e-01  1.006e-01   1.174  0.24039    \nMINK3045     1.366e-01  9.650e-02   1.415  0.15694    \nMINK4575     1.009e-01  9.667e-02   1.043  0.29678    \nMINK7512     1.144e-01  1.027e-01   1.114  0.26513    \nMINK123M    -1.607e-01  1.449e-01  -1.109  0.26738    \nMINKGEM      9.214e-02  9.945e-02   0.927  0.35417    \nMKOOPKLA     6.856e-02  4.642e-02   1.477  0.13966    \nPWAPART      5.954e-01  3.901e-01   1.526  0.12693    \nPWABEDR     -2.757e-01  4.635e-01  -0.595  0.55196    \nPWALAND     -4.405e-01  1.035e+00  -0.425  0.67052    \nPPERSAUT     2.306e-01  4.199e-02   5.491 4.01e-08 ***\nPBESAUT      1.215e+01  4.029e+02   0.030  0.97595    \nPMOTSCO     -8.101e-02  1.147e-01  -0.706  0.48006    \nPVRAAUT     -2.106e+00  2.557e+03  -0.001  0.99934    \nPAANHANG     1.014e+00  9.371e-01   1.082  0.27917    \nPTRACTOR     7.229e-01  4.278e-01   1.690  0.09107 .  \nPWERKT      -5.525e+00  4.805e+03  -0.001  0.99908    \nPBROM        2.170e-01  4.865e-01   0.446  0.65559    \nPLEVEN      -2.382e-01  1.170e-01  -2.036  0.04173 *  \nPPERSONG    -4.523e-01  2.094e+00  -0.216  0.82901    \nPGEZONG      1.444e+00  1.029e+00   1.404  0.16033    \nPWAOREG      8.239e-01  5.943e-01   1.386  0.16565    \nPBRAND       2.401e-01  7.714e-02   3.113  0.00185 ** \nPZEILPL     -8.658e+00  3.261e+03  -0.003  0.99788    \nPPLEZIER    -1.886e-01  3.259e-01  -0.579  0.56289    \nPFIETS       3.664e-01  8.325e-01   0.440  0.65985    \nPINBOED     -1.068e+00  8.764e-01  -1.219  0.22301    \nPBYSTAND    -1.676e-01  3.321e-01  -0.505  0.61373    \nAWAPART     -9.293e-01  7.802e-01  -1.191  0.23364    \nAWABEDR      4.197e-01  1.082e+00   0.388  0.69824    \nAWALAND      2.762e-01  3.528e+00   0.078  0.93758    \nAPERSAUT    -3.902e-02  1.772e-01  -0.220  0.82566    \nABESAUT     -7.298e+01  2.417e+03  -0.030  0.97591    \nAMOTSCO      2.418e-01  3.772e-01   0.641  0.52142    \nAVRAAUT     -4.490e+00  1.078e+04   0.000  0.99967    \nAAANHANG    -1.351e+00  1.687e+00  -0.801  0.42322    \nATRACTOR    -2.376e+00  1.524e+00  -1.559  0.11899    \nAWERKT      -8.749e-01  9.682e+03   0.000  0.99993    \nABROM       -1.060e+00  1.549e+00  -0.684  0.49367    \nALEVEN       4.789e-01  2.245e-01   2.133  0.03291 *  \nAPERSONG     3.997e-01  4.329e+00   0.092  0.92644    \nAGEZONG     -3.163e+00  2.706e+00  -1.169  0.24247    \nAWAOREG     -3.212e+00  3.433e+00  -0.936  0.34939    \nABRAND      -4.118e-01  2.787e-01  -1.477  0.13956    \nAZEILPL      1.047e+01  3.261e+03   0.003  0.99744    \nAPLEZIER     2.516e+00  1.010e+00   2.490  0.01276 *  \nAFIETS       2.318e-01  5.699e-01   0.407  0.68420    \nAINBOED      1.947e+00  1.412e+00   1.378  0.16812    \nABYSTAND     1.078e+00  1.103e+00   0.977  0.32870    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2635.5  on 5821  degrees of freedom\nResidual deviance: 2243.5  on 5736  degrees of freedom\nAIC: 2415.5\n\nNumber of Fisher Scoring iterations: 17\n```\n\n\n:::\n:::\n\n\n\non a ici un modèle avec beaucoup de variable. Mais si on analyse le summary, on constate que seulement 6 varaibales sont significative.\n\nRegardons un peu le VIF pour toutes les variables.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_VIFplot(vif(mod1))\n```\n\n::: {.cell-output-display}\n![](Exercice_04_files/figure-html/unnamed-chunk-14-1.png){width=2688}\n:::\n:::\n\n\n\nOn constate la présence de beaucoup de variables avec un VIF très élevé et donc une forte colinéarité indiquant bien qu'il va falloir sélectionner les variables à garder dans notre modèle.\n\n## Sélecion automatique\n\n::::: panel-tabset\n### AIC\n\n::: panel-tabset\n#### Forward\n\n#### Backward\n\n#### Both\n:::\n\n### BIC\n\n::: panel-tabset\n#### Forward\n\n#### Backward\n\n#### Both\n:::\n:::::\n\nAprès toute ces modélisations, rappelons nous tout de même l'objectif de l’assureur est de démarcher des clients de manière ciblée pour leurs faire souscrire une assurance caravane. On pourrait alors de demander : s’il démarchait les clients de façon aléatoire, sans tenir compte de leurs caractéristiques, quel serait environ son taux de réussite ?\n\nPour cela il suffit juste de ce rappeler du pourcentage donné précédemment qui nous disait la proportion de oui actuellement.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(table(Caravan$Purchase)*100/nrow(Caravan), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n    No    Yes \n94.023  5.977 \n```\n\n\n:::\n:::\n\n\n\nLe pourcentage étant très bas, on va souhaiter utiliser l’un des 3 modèles estimés ci-dessus (le global, un de ceux sélectionnés par AIC et un de ceux sélectionnés par BIC) pour cibler les clients à démarcher.\n\nAinsi on regardera\n\nSi l’on choisissait de démarcher tous les clients ayant une probabilité de souscrire l’assurance supérieure à 0.5, quel pourcentage de clients cela représenterait il pour chacun des 3 modèles estimés ? Quel seuil faudrait-il choisir à la place de 0.5 pour que ce pourcentage corresponde à environ 6% des clients ? On décide dans la suite de fixer ce seuil à 0.2 et on cherche à sélectionner le meilleur modèle parmi les 3 précédents.\n\n# Conclusion\n\n# Session info\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info(pkgs = \"attached\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       Ubuntu 24.04.1 LTS\n system   x86_64, linux-gnu\n ui       X11\n language (EN)\n collate  fr_FR.UTF-8\n ctype    fr_FR.UTF-8\n tz       Europe/Paris\n date     2025-02-20\n pandoc   3.2 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/x86_64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package   * version date (UTC) lib source\n car       * 3.1-3   2024-09-27 [1] CRAN (R 4.4.2)\n carData   * 3.0-5   2022-01-06 [1] CRAN (R 4.4.2)\n dplyr     * 1.1.4   2023-11-17 [1] CRAN (R 4.4.2)\n ggplot2   * 3.5.1   2024-04-23 [1] CRAN (R 4.4.2)\n gridExtra * 2.3     2017-09-09 [1] CRAN (R 4.4.2)\n ISLR      * 1.4     2021-09-15 [1] CRAN (R 4.4.2)\n\n [1] /home/clement/R/x86_64-pc-linux-gnu-library/4.4\n [2] /usr/local/lib/R/site-library\n [3] /usr/lib/R/site-library\n [4] /usr/lib/R/library\n\n──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncar <- Caravan\n# Question 3 --------------------------------------------------------------\n\nmod_full = glm(car$Purchase~., family = binomial, car)\nsummary(mod_full)\n\nlibrary(car)\nvif(mod_full) # quelques de vif elevé \n\n## courbe ROC\nlibrary(pROC)\nlibrary(PresenceAbsence) \ndf_rocr_mod = matrix(0, nrow=nrow(as.matrix(car$Purchase)), ncol = 3)\ndf_rocr_mod[,1] = 1:nrow(as.matrix(car$Purchase))\ndf_rocr_mod[,2] = as.numeric(mod_full$y)\ndf_rocr_mod[,3] = mod_full$fitted\ndf_rocr_mod = as.data.frame(df_rocr_mod)\ndimnames(df_rocr_mod)[[2]] = c('ID', \"Observed\", \"Predicted\")\ndimnames(df_rocr_mod)[[2]]\n# matrice de confusion \ncmx(df_rocr_mod, threshold = 0.5)\n\n# Calcul de la specificite et de la sensibilite\nsensitivity(cmx(df_rocr_mod,threshold=0.5))\nspecificity(cmx(df_rocr_mod,threshold=0.5))\n# Courbe ROC pour le modele logistique CHD\nroc.plot.calculate(df_rocr_mod)\nauc.roc.plot(df_rocr_mod) # graphe courbe ROC\n\nauc(df_rocr_mod) # calcul AUC \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Question 4 --------------------------------------------------------------\n\nmod_start = glm(car$Purchase~1, family = binomial, car)\n\n# AIC k = 2 \nmod_both_AIC = step(mod_start, scope = formula(mod_full), trace = FALSE, direction = \"both\", k=2)\n\n# BIC k = log(n)\nn = dim(car)[1]\nmod_both_BIC = step(mod_start, scope = formula(mod_full), trace = FALSE, direction = \"both\", k = log(n))\n\nsummary(mod_both_AIC)\nsummary(mod_both_BIC)\n\n\nvif(mod_both_AIC)\nvif(mod_both_BIC)\n\n# on a encore un peu de colinearité pour des var du modèle selec avec AIC\n# plus de colinearité pour le model selec avec BIC\n\n# Il serait preferable de garder le mod_both_BIC\n#mais on peut aussi enlever les variables au vif elevé \n\nmod_both_AIC_2.0 = glm(formula = car$Purchase ~ PPERSAUT + MKOOPKLA + PBRAND + APLEZIER + \n                         MOPLLAAG + MBERBOER + MRELGE + PWALAND + AFIETS + MINK123M + \n                         MINKGEM + MGEMLEEF + PWAPART + ABYSTAND + ABRAND + \n                         AWERKT + MGODPR + MSKC + MOPLHOOG + MBERMIDD, family = binomial, \n                       data = car)\nsummary(mod_both_AIC_2.0)\nvif(mod_both_AIC_2.0)\n\n# on analyse tout de même tout les modèle \n\n#####\n# df_rocr_mod_both_AIC\ndf_rocr_mod_both_AIC = matrix(0, nrow=nrow(as.matrix(car$Purchase)), ncol = 3)\ndf_rocr_mod_both_AIC[,1] = 1:nrow(as.matrix(car$Purchase))\ndf_rocr_mod_both_AIC[,2] = as.numeric(mod_both_AIC$y)\ndf_rocr_mod_both_AIC[,3] = mod_both_AIC$fitted\ndf_rocr_mod_both_AIC = as.data.frame(df_rocr_mod_both_AIC)\ndimnames(df_rocr_mod_both_AIC)[[2]] = c('ID', \"Observed\", \"Predicted\")\ndimnames(df_rocr_mod_both_AIC)[[2]]\n# matrice de confusion \ncmx(df_rocr_mod_both_AIC, threshold = 0.5)\n\n# Calcul de la specificite et de la sensibilite\nsensitivity(cmx(df_rocr_mod_both_AIC,threshold=0.5))\nspecificity(cmx(df_rocr_mod_both_AIC,threshold=0.5))\n# Courbe ROC pour le modele logistique CHD\nroc.plot.calculate(df_rocr_mod_both_AIC)\n\n# df_rocr_mod_both_AIC_2.0\ndf_rocr_mod_both_AIC_2.0 = matrix(0, nrow=nrow(as.matrix(car$Purchase)), ncol = 3)\ndf_rocr_mod_both_AIC_2.0[,1] = 1:nrow(as.matrix(car$Purchase))\ndf_rocr_mod_both_AIC_2.0[,2] = as.numeric(mod_both_AIC_2.0$y)\ndf_rocr_mod_both_AIC_2.0[,3] = mod_both_AIC_2.0$fitted\ndf_rocr_mod_both_AIC_2.0 = as.data.frame(df_rocr_mod_both_AIC_2.0)\ndimnames(df_rocr_mod_both_AIC_2.0)[[2]] = c('ID', \"Observed\", \"Predicted\")\ndimnames(df_rocr_mod_both_AIC_2.0)[[2]]\n# matrice de confusion \ncmx(df_rocr_mod_both_AIC_2.0, threshold = 0.5)\n\n# Calcul de la specificite et de la sensibilite\nsensitivity(cmx(df_rocr_mod_both_AIC_2.0,threshold=0.5))\nspecificity(cmx(df_rocr_mod_both_AIC_2.0,threshold=0.5))\n# Courbe ROC pour le modele logistique CHD\nroc.plot.calculate(df_rocr_mod_both_AIC_2.0)\n\n# df_rocr_mod_both_BIC\ndf_rocr_mod_both_BIC = matrix(0, nrow=nrow(as.matrix(car$Purchase)), ncol = 3)\ndf_rocr_mod_both_BIC[,1] = 1:nrow(as.matrix(car$Purchase))\ndf_rocr_mod_both_BIC[,2] = as.numeric(mod_both_BIC$y)\ndf_rocr_mod_both_BIC[,3] = mod_both_BIC$fitted\ndf_rocr_mod_both_BIC = as.data.frame(df_rocr_mod_both_BIC)\ndimnames(df_rocr_mod_both_BIC)[[2]] = c('ID', \"Observed\", \"Predicted\")\ndimnames(df_rocr_mod_both_BIC)[[2]]\n# matrice de confusion \ncmx(df_rocr_mod_both_BIC, threshold = 0.5)\n\n# Calcul de la specificite et de la sensibilite\nsensitivity(cmx(df_rocr_mod_both_BIC,threshold=0.5))\nspecificity(cmx(df_rocr_mod_both_BIC,threshold=0.5))\n# Courbe ROC pour le modele logistique CHD\nroc.plot.calculate(df_rocr_mod_both_BIC)\n#####\n\npar(mfrow=c(2,2))\nauc.roc.plot(df_rocr_mod, main = \"ROC plot mod_full\")\nauc.roc.plot(df_rocr_mod_both_AIC, main = \"ROC plot mod_both_AIC\")\nauc.roc.plot(df_rocr_mod_both_AIC_2.0, main = \"ROC plot mod_both_AIC_2.0\")\nauc.roc.plot(df_rocr_mod_both_BIC, main = \"ROC plot mod_both_BIC\") # graphe courbe ROC\npar(mfrow=c(1,1))\n\n\n# On veut maximiser l'AUC, ici les valeurs sont très proche \n# donc on peut quand même préféré le petit modele (BIC) meme si AUC plus faible\n\n## On compare avec anova \n\nanova(mod_full, mod_both_AIC_2.0)\n\nanova(mod_full, mod_both_BIC)\n\nanova(mod_both_AIC_2.0, mod_both_BIC)\n### INTERPRETATION ???????\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Question 5 --------------------------------------------------------------\n\n#demarche aléatoire conduit à 6%\nround(table(car$Purchase)*100/n, 3)\n\n\n# Question 6 --------------------------------------------------------------\n\n\nmod_full.probs=predict(mod_full, car, type=\"response\")# --> donne les proba\nmod_full.pred=rep(\"No\", n)\nmod_full.pred[mod_full.probs>.5]=\"Yes\"\ntable(mod_full.pred, car$Purchase)\n# taux de reussitz de démarchage \n# (i.e, le nb de vrais positifs par rapport au nb de positifs prédit)\n# 7/(8+7) = 0.4666667\n# on arrive à prévoir les souscriptions d'assurances dans 47% des cas\n# (8+341)/n = 6% erreur de classification\n# (7+5466)/n = 94% precision ou accuracy\n# sensibility = 7/(7+341) =0.02\nmean(mod_full.pred == car$Purchase) # ne marche pas ??\n# = 0\n\nmod_both_AIC_2.0.probs=predict(mod_both_AIC_2.0, car, type=\"response\")# --> donne les proba\nmod_both_AIC_2.0.pred=rep(\"No\", n)\nmod_both_AIC_2.0.pred[mod_both_AIC_2.0.probs>.5]=\"Yes\"\ntable(mod_both_AIC_2.0.pred, car$Purchase)\n# refaire l'analyse du dessus \n\nmod_both_BIC.probs=predict(mod_both_BIC, car, type=\"response\")# --> donne les proba\nmod_both_BIC.pred=rep(\"No\", n)\nmod_both_BIC.pred[mod_both_BIC.probs>.5]=\"Yes\"\ntable(mod_both_BIC.pred, car$Purchase)\n# refaire l'analyse du dessus \n\n\n\n#  % de clients ayant une proba >0.5\nround(sum(fitted.values(mod_full)>0.5)*100/n, 3)\n# 0.26%\nboxplot(fitted.values(mod_full))\nquantile(fitted.values(mod_full), 0.94) # seuil pour que ce % corresponde à environ 6% des clients\n# 0.1807236 \n\nround(sum(fitted.values(mod_both_AIC_2.0)>0.5)*100/n, 3)\n# 0.223\nboxplot(fitted.values(mod_both_AIC_2.0))\nquantile(fitted.values(mod_both_AIC_2.0), 0.94)\n# 0.1759159\n\nround(sum(fitted.values(mod_both_BIC)>0.5)*100/n, 3)\n# 0.137\nboxplot(fitted.values(mod_both_BIC))\nquantile(fitted.values(mod_both_BIC), 0.94)\n# 0.1659636 \n\n\n\n########\n# On décide dans la suite de fixer ce seuil à 0.2 et on cherche à sélectionner \n# le meilleur modèle parmi les 3 précédents.\n\n# on change le seuil\nmod_full.pred[mod_full.probs>0.2]=1 # = \"Yes\"\ntable(mod_full.pred, car$Purchase)\n# taux de reussite demarchage (vrais positifs par rapport au positifs predits)\n# 87/(197+87) = 0.306338 = 30.6%\n\n### refaire pour les autres modèles \n\nmod_both_AIC_2.0.pred[mod_both_AIC_2.0.probs>0.2]=1\ntable(mod_both_AIC_2.0.pred, car$Purchase)\n# 0.2929688\n\nmod_both_BIC.pred[mod_both_BIC.probs>0.2]=1\ntable(mod_both_BIC.pred, car$Purchase)\n# 0.2673797\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Question 7 --------------------------------------------------------------\n\n# Estimer le taux de réussite du démarchage (c’est à dire le nombre de vrais\n# positifs par rapport au nombre de positifs prédits) sur \n# l’échantillon d’apprentissage pour chaque modèle\n\n# fct de cout : freq vrai posi parmi les posi preddit\ncost = function(r, p){\n  # r = reponse\n  # p = prevision\n  s = sum(p>0.2 & r==1)/sum(p>0.2)\n  return(s)\n}\n\ncost(mod_full$y, fitted.values(mod_full))\n# 0.306338 = 30.6 % \n# on obtient effectivement le même resultat que calculé précédement \n\ncost(mod_both_AIC_2.0$y, fitted.values(mod_both_AIC_2.0))\n#  0.2929688\n# ca correspond \n\ncost(mod_both_BIC$y, fitted.values(mod_both_BIC))\n# 0.2673797\n# ca correspond \n\n## Selection  du modele complet\n# MAIS les resultats sont trop optimistes car ils sontobtenus via l'echant d'apprent\n# Dans ce cas, il n'est pas etonnant que le plus gros mod (mod_full) soit selectionné \n# il faut évaluer l'erreur sur echant test\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Question 8 --------------------------------------------------------------\nlibrary(boot)\n\nres = cv.glm(data = car, glmfit = mod_full, cost = cost, K=10)\nres2 = cv.glm(car, mod_both_AIC_2.0, cost, K=10)\nres3 = cv.glm(car, mod_both_BIC, cost, K=10)\n## marche pas. pourquoi??? (voir photo code pour réponse)\n\nres$delta\nres2$delta\nres3$delta\n\n\ndim(car)\n###### test #####\nmod_test = glm(Caravan$Purchase~., family = \"binomial\", data = Caravan)\ncv.glm(Caravan, mod_test, cost = cost, K=10)\n\nsummary(Caravan)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Question 9 --------------------------------------------------------------\n\n# Estimer de même le taux de réussite pour chaque modèle lorsque le seuil\n# varie de 0.10 à 0.30 par pas de 0.01\n\n\nmat=matrix(nrow=3,ncol=21)\nk=0\nfor(s in seq(0.1,0.3,0.01)){\n  k=k+1\n  cat(k) # Concatenate and Print\n  res=cv.glm(Caravan,mod_full,cost,K=10)\n  res2=cv.glm(Caravan,mod_both_AIC_2.0,cost,K=10)\n  res3=cv.glm(Caravan,mod_both_BIC,cost,K=10)\n  mat[1,k]=res$delta[1]\n  mat[2,k]=res2$delta[1]\n  mat[3,k]=res3$delta[1]\n}\nmatplot(seq(0.1,0.3,0.01),t(mat),type='l')\nlegend('topleft',c('Tout','AIC','BIC'),col=1:3,lty=1:3)\n\n\n\n\n\n#repetition 5 fois (tres long)\nres_seuil=NULL\nfor(i in 1:5){\n  mat=matrix(nrow=3,ncol=21)\n  k=0\n  for(s in seq(0.1,0.3,0.01)){\n    k=k+1\n    cat(k)\n    res=cv.glm(Caravan,mod,cost,K=10)\n    res2=cv.glm(Caravan,mod2,cost,K=10)\n    res3=cv.glm(Caravan,mod3,cost,K=10)\n    mat[1,k]=res$delta[1]\n    mat[2,k]=res2$delta[1]\n    mat[3,k]=res3$delta[1]\n  }\n  res_seuil[[i]]=mat\n}\n\nmatplot(seq(0.1,0.3,0.01),t(res_seuil[[1]]),type='l',ylim=c(0.15,0.35),lty=2)\nfor(i in 2:5) matplot(seq(0.1,0.3,0.01),t(res_seuil[[i]]),type='l',lty=2,add=T)\nres_moy=res_seuil[[1]]\nfor(i in 2:5) res_moy=res_moy+res_seuil[[i]]\nmatplot(seq(0.1,0.3,0.01),t(res_moy)/5,type='l',lty=1,lwd=2,add=T)\nlegend('topleft',c('Tout','AIC','BIC'),col=1:3,lty=1:3)\n\n#On observe que les courbes deviennent tres variables lorsque le seuil grandit. Il y a meme des valeurs manquantes\n#C'est parcequ'il y a tres peu de positifs predits dans ce cas (voire aucun dans certains folds) et donc l'estimation de l'erreur est tres peu precise\n#Le meilleur modele semble celui par BIC. \n#Si on veut avoir a la fois un taux de demarchage optimum et un nombre de positifs pas trop faible, un seuil de 0.2 semble pas mal\n```\n:::\n",
    "supporting": [
      "Exercice_04_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}