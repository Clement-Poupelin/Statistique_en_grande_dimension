{
  "hash": "e345325c8215c191db9fc5ff2cbf0cbd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exercice 01\"\nauthor: \"Clément Poupelin\"\ndate: \"2025-02-17\"\ndate-modified: \"2025-02-25\"\nformat: \n  html:\n    embed-resources: false\n    toc: true\n    code-fold: true\n    code-summary: \"Show the code\"\n    code-tools: true\n    toc-location: right\n    page-layout: article\n    code-overflow: wrap\ntoc: true\nnumber-sections: false\neditor: visual\ncategories: [\"Régression linéaire\", \"Sélection automatique\"]\nimage: \"/img/baseball.png\"\ndescription: \"Il s'agit d'une première utilisation des méthodes de régression avec selection de variable via des approches stepwise sur des données de baseball\"\n---\n\n\n\n# Intervenant.e.s\n\n### Rédaction\n\n-   **Clément Poupelin**, [clementjc.poupelin\\@gmail.com](mailto:clementjc.poupelin@gmail.com){.email}\\\n\n### Relecture\n\n-   \n\n# Setup\n\n:::: panel-tabset\n## Packages\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Données\nlibrary(ISLR)         # Hitters data \nlibrary(dplyr)        # manipulation des données\n\n# Inférence\nlibrary(leaps)        # regsubsets \nlibrary(car)          # pour VIF\n\n# Plots\n## ggplot\nlibrary(ggplot2)\nlibrary(gridExtra)\n```\n:::\n\n\n\n## Fonctions\n\n::: panel-tabset\n### Boxplot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_boxplot <- function(data) {\n  # Transformer les données en format long pour ggplot\n  data_long <- reshape2::melt(data)\n  \n  ggplot(data_long, aes(x = variable, y = value, fill = variable)) +\n    geom_boxplot() +\n    scale_fill_viridis_d() +  # Palette de couleurs harmonieuse\n    labs(title = \"Distribution des Variables (Boxplot)\", x = \"Variables\", y = \"Valeurs\") +\n    theme_minimal() +  # Thème épuré\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotation des étiquettes\n}\n```\n:::\n\n\n\n\n### barplot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_barplot <- function(data, variable1, variable2) {\n  ggplot(data, aes(x = {{ variable1 }}, fill = {{ variable2 }})) +\n    geom_bar(position = \"dodge\") +\n    scale_fill_manual(values = c(\"#C41E3A\", \"#0033A0\")) +  \n    labs(\n      title = \"Répartition des joueurs par League et Division\",\n      x = deparse(substitute(variable1)), \n      y = \"Nombre de joueurs\"\n    ) +\n    theme_minimal()\n}\n```\n:::\n\n\n\n### Heatmap\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_League_heatmap <- function(data) {\n  table_league <- as.data.frame(table(\n    data$League,\n    data$NewLeague\n  ))\n  colnames(table_league) <- c(\"League\", \"NewLeague\", \"Count\")\n  \n  ggplot(table_league, aes(x = League, y = NewLeague, fill = Count)) +\n    geom_tile(color = \"white\") +\n    scale_fill_gradient(low = \"deeppink\", high = \"deeppink4\") +\n    geom_text(aes(label = Count), color = \"white\", size = 5) +\n    labs(\n      title = \"Transition des Joueurs entre les Ligues\",\n      x = \"League d'origine\",\n      y = \"Nouvelle League\",\n      fill = \"Nombre de joueurs\"\n    ) +\n    theme_minimal()\n}\n```\n:::\n\n\n\n### pairs.panels\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_pairs.panels <- function(data) {\n  psych::pairs.panels(\n    data,\n    method = \"pearson\",  # Méthode de corrélation\n    hist.col = RColorBrewer::brewer.pal(9, \"Set3\"),  # Couleurs des histogrammes\n    density = TRUE,  # Ajout des courbes de densité\n    ellipses = TRUE,  # Ajout d'ellipses\n    smooth = TRUE,  # Ajout de régressions lissées\n    lm = TRUE,  # Ajout des droites de régression\n    col = \"#69b3a2\",\n    alpha = 0.5,  # Transparence\n    cex.labels = 3.5,  # Taille du texte des variables\n    font.labels = 2  # Mettre en gras\n  )\n}\n```\n:::\n\n\n\n### VIF plot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_VIFplot <- function(vif) {\n  vif_df <- data.frame(Variable = names(vif), VIF = vif)\n  \n  p <- ggplot(vif_df, aes(\n    x = reorder(Variable, VIF),\n    y = pmin(VIF, 15),\n    fill = VIF > 10\n  )) +\n    geom_bar(stat = \"identity\") +\n    geom_text(aes(label = ifelse(VIF > 10, round(VIF, 1), \"\")), hjust = -0.2, size = 6) +\n    coord_flip() +\n    scale_fill_manual(values = c(\"FALSE\" = \"#0072B2\", \"TRUE\" = \"#D55E00\")) +\n    labs(title = \"Variance Inflation Factor (VIF)\", x = \"Variables\", y = \"VIF (limité à 15)\") +\n    theme_minimal() +\n    theme(\n      axis.title = element_text(size = 34, face = \"bold\"),\n      plot.title = element_text(\n        size = 54,\n        face = \"bold\",\n        hjust = 0.5\n      ),\n      axis.text.x = element_text(size = 26),\n      axis.text.y = element_text(size = 18),\n      legend.text = element_text(size = 30),\n      legend.title = element_text(size = 38, face = \"bold\")\n    )\n  \n  return(p)\n}\n```\n:::\n\n\n\n### Critères\n\nOn rappel que $SCR = \\sum_i (y_i - f(x_i))^2$ et $SCT = \\sum_i (y_i - \\bar{y})^2$.\\\n\nAinsi, on peut aretrouver les différents critères :\n\n$$ R^2 = 1 - \\frac{SCR}{SCT}$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr2_fun <- function(y, SCR){\n  # r2 = SSE/SST = (SST - SSR)/SST = 1 - ssr/sst\n  SCT <- sum((y - mean(y) )^2)\n  r2 <- 1 - SCR/SCT\n  return(r2)\n}\n```\n:::\n\n\n\n$$ R^2_{adjusted} = 1 - \\frac{SCR (n-1)}{SCT(n-(p+1))}$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr2a_fun <- function(y, SCR){\n  n <- dim(Hitters_Without_NA)[1]\n  p <- 1:(dim(Hitters_Without_NA)[2]-1)\n  SCT <- sum((y - mean(y) )^2)\n  r2a <- 1 - (SCR/(n-(p+1)))/(SCT/(n-1))\n  return(r2a)\n}\n```\n:::\n\n\n\n$$ C_p = \\frac{SCR}{\\sigma^2} + 2(p+1) - n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncp_fun <- function(mod, SCR){\n  sig <- summary(mod)$sigma\n  n <- dim(Hitters_Without_NA)[1]\n  p <- 1:(dim(Hitters_Without_NA)[2]-1)\n  cp <- SCR/sig^2 + 2*(p+1) - n\n  return(cp)\n}\n```\n:::\n\n\n\n$$ AIC = n\\text{log}\\left(\\frac{SCR}{n}\\right) + 2(p+1)$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naic_fun <- function(SCR){\n  n <- dim(Hitters_Without_NA)[1]\n  p <- 1:(dim(Hitters_Without_NA)[2]-1)\n  aic <- n * log(SCR/n) + 2*(p+1)\n  return(aic)\n}\n```\n:::\n\n\n\n$$ BIC = n\\text{log}\\left(\\frac{SCR}{n}\\right) + \\text{log}(n)(p+1)$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbic_fun <- function(SCR){\n  n <- dim(Hitters_Without_NA)[1]\n  p <- 1:(dim(Hitters_Without_NA)[2]-1)\n  bic <- n * log(SCR/n) + log(n)*(p+1)\n  return(bic)\n}\n```\n:::\n\n\n\n### plot pour nos critères\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCriteria_plot <- function(Criteria, crit_name = \"Critère\") {\n  # Création d'un data frame pour ggplot\n  df_criteria <- data.frame(\n    nb_var = seq_along(Criteria),  # Nombre de variables du modèle\n    Criteria = Criteria            # Critère\n  )\n\n  # Création du plot avec ggplot2\n  g <- ggplot(df_criteria, aes(x = nb_var, y = Criteria)) +\n    geom_line(color = \"#0072B2\", linewidth = 1) +  \n    geom_point(color = \"#D55E00\", size = 4) + \n    labs(\n      title = paste(\"Évolution de\", crit_name, \"en fonction du nombre de variables\"),\n      x = \"Nombre de variables sélectionnées\",\n      y = crit_name\n    ) +\n    theme_minimal() + \n    theme(\n      plot.title = element_text(hjust = 0.5, face = \"bold\", size = 26),  # Titre centré et agrandi\n      axis.title.x = element_text(face = \"bold\", size = 22),\n      axis.title.y = element_text(face = \"bold\", size = 22),\n      axis.text = element_text(size = 20)\n    )\n\n  return(g)\n}\n```\n:::\n\n\n\n### Meilleur modèle après regsubset\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBest_model <- function(model, criteria_df){\n  ## On a d'abord les critères à maximiser\n  for(i in 1:2){\n    criteria_name <- colnames(criteria_df)[i]\n    criteria <- criteria_df[,i]\n    \n    best_model_criteria <- which.max(criteria)\n    selected_vars <- summary(model)$which[best_model_criteria,]\n    \n    cat(\"Meilleur modèle selon\", criteria_name, \" = \", round(max(criteria), 3), \" : Modèle avec\", best_model_criteria, \"variables\\n\", \n        rownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE]), \"\\n\", \"\\n\")\n  }\n  ## On a ensuite les critères à minimiser\n  for(i in 3:5){\n    criteria_name <- colnames(criteria_df)[i]\n    criteria <- criteria_df[,i]\n    \n    best_model_criteria <- which.min(criteria)\n    selected_vars <- summary(model)$which[best_model_criteria,]\n    \n    cat(\"Meilleur modèle selon\", criteria_name, \" = \", round(min(criteria), 3),\" : Modèle avec\", best_model_criteria, \"variables\\n\", \n        rownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE]), \"\\n\", \"\\n\")\n  }\n}\n```\n:::\n\n\n:::\n::::\n\n# Données\n\nOn étudie le jeu de données [**Hitters**](https://rdrr.io/cran/ISLR/man/Hitters.html) disponible dans la libraire *`{ISLR}`* de *`R`*. Il s'agit d'un jeu de données de la *Major League Baseball* provenant des saisons de 1986 et 1987.\n\nLe jeu de données possède 322 lignes/individus pour les différents joueurs et 20 variables.\\\nParmi les variables, on trouve les informations suivantes :\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-hover table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">AtBat</span> </td>\n   <td style=\"text-align:left;\"> Number of times at bat in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Hits</span> </td>\n   <td style=\"text-align:left;\"> Number of hits in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">HmRun</span> </td>\n   <td style=\"text-align:left;\"> Number of home runs in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Runs</span> </td>\n   <td style=\"text-align:left;\"> Number of runs in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">RBI</span> </td>\n   <td style=\"text-align:left;\"> Number of runs batted in in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Walks</span> </td>\n   <td style=\"text-align:left;\"> Number of walks in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Years</span> </td>\n   <td style=\"text-align:left;\"> Number of years in the major leagues </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">CAtBat</span> </td>\n   <td style=\"text-align:left;\"> Number of times at bat during his career </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">CHits</span> </td>\n   <td style=\"text-align:left;\"> Number of hits during his career </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">CHmRun</span> </td>\n   <td style=\"text-align:left;\"> Number of home runs during his career </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">CRuns</span> </td>\n   <td style=\"text-align:left;\"> Number of runs during his career </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">CRBI</span> </td>\n   <td style=\"text-align:left;\"> Number of runs batted in during his career </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">CWalks</span> </td>\n   <td style=\"text-align:left;\"> Number of walks during his career </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">League</span> </td>\n   <td style=\"text-align:left;\"> A factor with levels A and N indicating player's league at the end of 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Division</span> </td>\n   <td style=\"text-align:left;\"> A factor with levels E and W indicating player's division at the end of 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">PutOuts</span> </td>\n   <td style=\"text-align:left;\"> Number of put outs in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Assists</span> </td>\n   <td style=\"text-align:left;\"> Number of assists in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Errors</span> </td>\n   <td style=\"text-align:left;\"> Number of errors in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Salary</span> </td>\n   <td style=\"text-align:left;\"> 1987 annual salary on opening day in thousands of dollars </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">NewLeague</span> </td>\n   <td style=\"text-align:left;\"> A factor with levels A and N indicating player's league at the beginning of 1987 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nRegardons maintenant le *`summary`* pour examiner les différentes variables.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ?Hitters\nHitters %>%\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     AtBat            Hits         HmRun            Runs       \n Min.   : 16.0   Min.   :  1   Min.   : 0.00   Min.   :  0.00  \n 1st Qu.:255.2   1st Qu.: 64   1st Qu.: 4.00   1st Qu.: 30.25  \n Median :379.5   Median : 96   Median : 8.00   Median : 48.00  \n Mean   :380.9   Mean   :101   Mean   :10.77   Mean   : 50.91  \n 3rd Qu.:512.0   3rd Qu.:137   3rd Qu.:16.00   3rd Qu.: 69.00  \n Max.   :687.0   Max.   :238   Max.   :40.00   Max.   :130.00  \n                                                               \n      RBI             Walks            Years            CAtBat       \n Min.   :  0.00   Min.   :  0.00   Min.   : 1.000   Min.   :   19.0  \n 1st Qu.: 28.00   1st Qu.: 22.00   1st Qu.: 4.000   1st Qu.:  816.8  \n Median : 44.00   Median : 35.00   Median : 6.000   Median : 1928.0  \n Mean   : 48.03   Mean   : 38.74   Mean   : 7.444   Mean   : 2648.7  \n 3rd Qu.: 64.75   3rd Qu.: 53.00   3rd Qu.:11.000   3rd Qu.: 3924.2  \n Max.   :121.00   Max.   :105.00   Max.   :24.000   Max.   :14053.0  \n                                                                     \n     CHits            CHmRun           CRuns             CRBI        \n Min.   :   4.0   Min.   :  0.00   Min.   :   1.0   Min.   :   0.00  \n 1st Qu.: 209.0   1st Qu.: 14.00   1st Qu.: 100.2   1st Qu.:  88.75  \n Median : 508.0   Median : 37.50   Median : 247.0   Median : 220.50  \n Mean   : 717.6   Mean   : 69.49   Mean   : 358.8   Mean   : 330.12  \n 3rd Qu.:1059.2   3rd Qu.: 90.00   3rd Qu.: 526.2   3rd Qu.: 426.25  \n Max.   :4256.0   Max.   :548.00   Max.   :2165.0   Max.   :1659.00  \n                                                                     \n     CWalks        League  Division    PutOuts          Assists     \n Min.   :   0.00   A:175   E:157    Min.   :   0.0   Min.   :  0.0  \n 1st Qu.:  67.25   N:147   W:165    1st Qu.: 109.2   1st Qu.:  7.0  \n Median : 170.50                    Median : 212.0   Median : 39.5  \n Mean   : 260.24                    Mean   : 288.9   Mean   :106.9  \n 3rd Qu.: 339.25                    3rd Qu.: 325.0   3rd Qu.:166.0  \n Max.   :1566.00                    Max.   :1378.0   Max.   :492.0  \n                                                                    \n     Errors          Salary       NewLeague\n Min.   : 0.00   Min.   :  67.5   A:176    \n 1st Qu.: 3.00   1st Qu.: 190.0   N:146    \n Median : 6.00   Median : 425.0            \n Mean   : 8.04   Mean   : 535.9            \n 3rd Qu.:11.00   3rd Qu.: 750.0            \n Max.   :32.00   Max.   :2460.0            \n                 NA's   :59                \n```\n\n\n:::\n:::\n\n\n\n::: callout-warning\nOn peut déjà remarquer la présence de 59 valeurs manquantes pour la variable *Salary*.\n:::\n\nOn va donc commencer par s'en débarasser (il ne s'agit que de 59 joueurs sur les 322). Puis on va également créer un sous jeu de données ne conservant que les variables quantitatives .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHitters_Without_NA <- Hitters %>% na.omit()\nHitters_Without_NA_quant <- Hitters_Without_NA %>% subset(, select = -c(League, Division, NewLeague))\nHitters_Without_NA_quali <- Hitters_Without_NA %>% subset(, select = c(League, Division, NewLeague))\n```\n:::\n\n\n\n# Analyse descriptive\n\nAvant de se lancer dans des analyses inférentielles avec de l'estimation, prédiction, etc... Il convient toujours de commencer par quelques analyses descritpives afin de mieuxcomprendre les données sur lesquelles on travail.\n\n:::::::::::::::::::::::::::: panel-tabset\n## Variables quantitatives\n\n::::::::: panel-tabset\n### Boxplot\n\nOn peut regarder un peu la distribution de nos différents variables quantitatives via des boxplots.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_boxplot(Hitters_Without_NA_quant)\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-16-1.png){width=768}\n:::\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nComme on pouvait s'y attendre, on retrouve des distributions assez variées selon les différentes statistques des joueurs.\n\nOn peut tout de même remarquer que nos variables ont en général peu de valeurs outliers.\n:::\n\n### Correlations\n\nOn regarde ici la corrélation calculée entre chacune de nos variables quantitative.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_pairs.panels(Hitters_Without_NA_quant)\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-17-1.png){width=3072}\n:::\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nOn voit la présence de plusieurs fortes corrélations qui peut déjà nous alerter si l'on veut faire des modèles de regressions linéaires car on risque d'avoir un problème de colinéarité entre les varibales explicatives. Parmi ces fortes corrélations, on arrive même à distiguer deux zones où les variables sont très corrélées entre elles (de *AtBat* à *RBI* et de *Years* à *Cwalks*)\n\nPar contre, il n'y a aucune forte corrélation entre la variable *Salary* et les autres variables du jeu de données. Ce qui peut nous indiquer qu'il n'y aura pas une variable avec très forte influence sur *Salary*.\n:::\n:::::::::\n\n## Variables qualitatives\n\n::::::::: panel-tabset\n### Barplot\n\nIci, regardons un peu le nombre des joeurs par ligue, selon la division.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid.arrange(my_barplot(Hitters_Without_NA_quali, League, Division),\n             my_barplot(Hitters_Without_NA_quali, NewLeague, Division)\n             , ncol=2)\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-18-1.png){width=1152}\n:::\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nDe manière globale, on peut remarque que de fin 1986 à début 1987, il ne semble pas y avoir beaucoup de changement dans la répartition des joueurs par ligue selon la division.\n\nDe manière plus locale, on remarque qu'il y a un peu plus de joueur en division Ouest (*West*) que division Est (*East*). Et ça, qu'on sit en ligue Américaine (*American League*) ou ligue Nationale (*National League*)\n:::\n\n### Heatmap\n\nOn peut regarder la Heatmap nous donnans la transition des joueurs entre les ligues, i.e on regarde la similarité des variables *League* et *NewLeague*.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_League_heatmap(Hitters_Without_NA_quali)\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nOn voit bien ici qu'effectivement les joueurs n'ont globalement pas changer de ligue entre fin 1986 et début 1987. Seulement 8 joueurs sont passés de ligue américaine à ligue nationale et 10 de ligue nationale à ligue américaine.\n:::\n:::::::::\n\n## PCA\n\nAvec une Analyse en Composantes Principales (PCA) on peut regarder un peu le comportement de nos données.\n\nEn effet, Cette méthode respose sur la transformation des variables d'origine en nouvelles variables non corrélées, appelées composantes principales, qui capturent successivement la plus grande variance possible des données.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_pca <- FactoMineR::PCA(\n  Hitters_Without_NA,\n  quali.sup = c(which(\n    colnames(Hitters_Without_NA) %in% c(\"League\", \"Division\", \"NewLeague\")\n  )),\n  quanti.sup = which(colnames(Hitters_Without_NA) == \"Salary\"),\n  graph = FALSE\n)\n```\n:::\n\n\n\nIci, on spécifi nos variables qualitatives et on décide de mettre la variable *Salary* en variable supplémentaire, ce qui veut dire qu'elle ne sera pas considéré pour la formation de nos composantes principales (variable que l'on cherchera à estimer plus tard).\n\n::::::::::::: panel-tabset\n#### Barplot des variances\n\nTout d'abord, on peut commencer par regarder le pourcentage de variance expliqué par nos différentes composantes principales.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactoextra::fviz_eig(\n  res_pca,\n  ncp = 10,\n  addlabels = TRUE,\n  barfill = \"coral\",\n  barcolor = \"coral\",\n  ylim = c(0, 50),\n  main = \"Percentage of variance of the 10 first components\"\n)\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nOn voit ainsi que la majorité de la variance est expliquée par nos deux premières composantes principales avec la présence d'un fort effet de coude après celle-ci.\n:::\n\n#### Individus\n\nLe plan des individus est une projection des observations (dans notre cas, les joueurs de baseball) sur les axes principaux de la PCA. Cette visualisation permet d’identifier des regroupements, tendances et anomalies au sein des données.\n\nAinsi, des individus proches sur le graphique ont des caractéristiques similaires par rapport aux variables utilisées.\n\nPuis, le placement d'un individu en fonction des axes peut permettre de savoir comment le jouer se caractérise par rapport aux variables qui contribuent le plus à ces axes.\\\nOn peut ensuite regarder ce placement en fonction de nos différentes variables qualitatives.\n\n::: panel-tabset\n##### Simple\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactoextra::fviz_pca_ind(\n  res_pca,\n  label = \"none\",\n  pointsize = 2,\n  col.ind = \"cyan3\"\n)\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-22-1.png){width=768}\n:::\n:::\n\n\n\n##### *League*\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactoextra::fviz_pca_ind(\n  res_pca,\n  habillage = Hitters_Without_NA$League,\n  addEllipses=TRUE,\n  ellipse.level=0.95,\n  label = \"none\",\n  pointsize = 2,\n  col.ind = \"cyan3\"\n)\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-23-1.png){width=768}\n:::\n:::\n\n\n\n##### *NewLeague*\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactoextra::fviz_pca_ind(\n  res_pca,\n  habillage = Hitters_Without_NA$NewLeague,\n  addEllipses=TRUE,\n  ellipse.level=0.95,\n  label = \"none\",\n  pointsize = 2,\n  col.ind = \"cyan3\"\n)\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-24-1.png){width=768}\n:::\n:::\n\n\n\n##### *Division*\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactoextra::fviz_pca_ind(\n  res_pca,\n  habillage = Hitters_Without_NA$Division,\n  addEllipses=TRUE,\n  ellipse.level=0.95,\n  label = \"none\",\n  pointsize = 2,\n  col.ind = \"cyan3\"\n)\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-25-1.png){width=768}\n:::\n:::\n\n\n:::\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nIci, on voit que les joueurs se répartissent de manière plûtot uniforme sur le plan ce qui témoignent de la présence d'une grande variété de type de joueurs.\n\nEt on ne voit pas de regroupement se faire en fonction de nos différentes variables qualitatives.\n:::\n\n#### Variables\n\nLe cercle des variables est une représentation graphique qui permet d’analyser les relations entre les variables initiales et les composantes principales qui forment nos axes. Il est basé sur les corrélations entre les variables et les axes principaux.\n\nAinsi, plus une variable est proche du bord du cercle, plus elle est bien représentée sur le plan factoriel et contribue fortement à la formation des axes. Ici, on utilise le cos2 pour le gradient de couleur qui va aider à l'indentifictation de ces différentes qualitées de représentation.\n\nDe plus, selon l'angle entre deux varibles, on peut faire des suppositions sur leur corrélation :\n\n-   Si deux variables ont des vecteurs proches (petit angle), elles sont fortement corrélées positivement\n\n-   Si deux variables ont des vecteurs opposés (angle proche de 180°), elles sont corrélées négativement\n\n-   Si l’angle est proche de 90°, alors les variables ne sont pas corrélées\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactoextra::fviz_pca_var(\n  res_pca,\n  col.var = \"cos2\",\n  gradient.cols = rainbow(n = 8, start = .6, end = .9),\n  repel = TRUE\n)\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-26-1.png){width=768}\n:::\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nDans notre cas, ce que l'on peut voir c'est que la majorité de nos variables sont bien représentées par nos deux axes (cumulant plus de 70% d'explication). Mais beaucoup semblent aussi fortement corrélées avec la formation de deux groupes et la variable *Salary* se trouvant au milieu. Cette corrélation entre nos variables quantitatives ayant déjà pu être observé précédemment.\\\nPour aller un peu plus loin dans la compréhension de ce phénomène, on peut remarquer que les deux groupes correspondent en fait aux variables qui sont des statistiques de joueurs pour la saison de 1986 (*Hits*, *AtBat*, *Runs*, *RBI*, ...) et des statistiques de joueurs sur toute leur carrière (*Cwalks*, *CAtBat*, *CHmRun*, *CRBI*, ...). Ainsi cela explique la présence de fortes corrélations corrélation.\n:::\n:::::::::::::\n::::::::::::::::::::::::::::\n\n# Analyse inférentielle\n\n## Modèle brut\n\nOn désire modéliser le salaire *Salary* en fonction des variables disponibles.\n\nOn va donc ajuster un modèle de régression linéaire en utilisant toutes les variables à disposition et analyser la qualité de cet ajustement.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod1 <- lm(formula = Salary ~ .,\n           Hitters_Without_NA) \nmod1 %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Salary ~ ., data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-907.62 -178.35  -31.11  139.09 1877.04 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  163.10359   90.77854   1.797 0.073622 .  \nAtBat         -1.97987    0.63398  -3.123 0.002008 ** \nHits           7.50077    2.37753   3.155 0.001808 ** \nHmRun          4.33088    6.20145   0.698 0.485616    \nRuns          -2.37621    2.98076  -0.797 0.426122    \nRBI           -1.04496    2.60088  -0.402 0.688204    \nWalks          6.23129    1.82850   3.408 0.000766 ***\nYears         -3.48905   12.41219  -0.281 0.778874    \nCAtBat        -0.17134    0.13524  -1.267 0.206380    \nCHits          0.13399    0.67455   0.199 0.842713    \nCHmRun        -0.17286    1.61724  -0.107 0.914967    \nCRuns          1.45430    0.75046   1.938 0.053795 .  \nCRBI           0.80771    0.69262   1.166 0.244691    \nCWalks        -0.81157    0.32808  -2.474 0.014057 *  \nLeagueN       62.59942   79.26140   0.790 0.430424    \nDivisionW   -116.84925   40.36695  -2.895 0.004141 ** \nPutOuts        0.28189    0.07744   3.640 0.000333 ***\nAssists        0.37107    0.22120   1.678 0.094723 .  \nErrors        -3.36076    4.39163  -0.765 0.444857    \nNewLeagueN   -24.76233   79.00263  -0.313 0.754218    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 315.6 on 243 degrees of freedom\nMultiple R-squared:  0.5461,\tAdjusted R-squared:  0.5106 \nF-statistic: 15.39 on 19 and 243 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n::: callout-note\nNous sommes sur un modèle comprenant des variables quantitatives et qualitative ce qui le rapproche d'une modélisation ANOVA.\n:::\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nCe qu'on peut remarquer en premier sur ce modèle c'est que beaucoup de variables ont un effet non significatif.\n\nAussi, ce modèle offre des valeurs de $R^2$ et $R^2_{adjusted}$ autour de 0.5 ce qui témoigne d'une mauvaise qualité d'ajustament du modèle\n\nEt enfin, l'écart type résiduel est de 315.6 ce qui est assez important et témoigne d'un modèle peu précis\n:::\n\nPour tenter de trouver un meilleur ajustment, il est important d'analyser d'avantage le lien entre toutes les variables explicatives. On utilise alors comunément le *VIF* (*variance inflation factor*).\n\nOn obtient alors pour chacune de nos variable une valeur qui, plus elle est élevé, témoigne de la multicolinéarité entre nos variables explicatives.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvif(mod1) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     AtBat       Hits      HmRun       Runs        RBI      Walks      Years \n 22.944366  30.281255   7.758668  15.246418  11.921715   4.148712   9.313280 \n    CAtBat      CHits     CHmRun      CRuns       CRBI     CWalks     League \n251.561160 502.954289  46.488462 162.520810 131.965858  19.744105   4.134115 \n  Division    PutOuts    Assists     Errors  NewLeague \n  1.075398   1.236317   2.709341   2.214543   4.099063 \n```\n\n\n:::\n\n```{.r .cell-code}\nmy_VIFplot(vif(mod1))\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-28-1.png){width=1920}\n:::\n:::\n\n\n\nOn remarque ainsi que beaucoup de valeurs sont supérieur à 10 ce qui s'interprète communément comme la précence d'une forte colinéarité sur nos variables explicatives.\n\n::: callout-note\nCette colinéarité se constatait déjà durant les analyses descriptive via les graphes de corrélations (d'où l'importance de ne pas se lancer trop rapidement dans les analyses inférentielles).\n:::\n\n## Modèles parcimonieux\n\nMaintenant, on va donc tenter de trouver le meilleur sous-modèle possible. Pour cela on va suivre la procédure suivante :\n\n-   mettre en oeuvre une méthode de sélection automatique exhaustive et observer l’évolution des SCR (Sommes de Carrés Résiduels) pour les modèles retenus en fonction de leur taille.\n\n-   déduire de ces SCR le $R^2$, $R^2_{adjusted}$, AIC, BIC et $C_p$ correspondants. Les comparer avec les valeurs fournies dans le summary de regsubsets et tracer leur évolution en fonction de la taille du modèle.\n\nPuis reproduire la même procédure avec des séléctions *backward*, *forward* et *stepwise*\n\nTout d'abord, on va définir un nouveau modèle simple ne comprenant que l'*intercept*.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod0 <- lm(Salary~1,\n           Hitters_Without_NA)\nsummary(mod0)$call\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlm(formula = Salary ~ 1, data = Hitters_Without_NA)\n```\n\n\n:::\n:::\n\n\n\nLe principe de ces méthodes de régression avec sélection de variables est de tester et comparer les différents modèles possibles avec nos variables en allant du modèle le plus simple $y \\sim 1$ jusqu'au modèle le plus complet $y \\sim .$ ou l'inverse. Puis à chaque étape de rajout ou de suppression d'une variable dans le modèles, on sélectionne le meilleur modèle via le critère de notre choix.\n\n::: callout-note\nUn rappel sur nos critère se trouve dans la partie **Setup**, onglet **Fonction**, de ce document avec la création de fonction pour les calculer.\n:::\n\n::::::::::::::::::::::::::::::::::::::::::::::: panel-tabset\n### Exhaustive\n\n:::::::::: panel-tabset\n#### Modèle\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselec_auto <- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"exhaustive\",\n                         nvmax = 19 # maximum size of subsets to examine\n                         )\n# selec_auto %>% summary()\n```\n:::\n\n\n\nOn va déjà commencer par regarder la valeur du critère en fonction des variables des différents modèles testés.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(2,2))\nplot(selec_auto, scale = 'bic') \nplot(selec_auto, scale = 'Cp') \nplot(selec_auto, scale = 'r2') \nplot(selec_auto, scale = 'adjr2') \n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-31-1.png){width=1152}\n:::\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nIci on remarque clairement que toutes nos variables ne sont pas gardés lorsque l'on cherche à optimiser nos critères.\n\nAussi, on peut voir encore de faibles valeurs pour les $R^2$ et $R^2_{adjusted}$ pouvant témoignés d'un mauvais ajustement de modèle.\n:::\n\n::: callout-note\n*`plot.regsubsets`* de *`{leaps}`* ne prend pas directement \"aic\" comme option de scale. Pour une sélection basée sur AIC, une approche alternative consiste à utiliser la fonction *`stepAIC`* du package *`{MASS}`*, qui permet une sélection pas à pas basée sur AIC.\n:::\n\n#### Evolution des critères\n\nRegardons un peut l'évolution de la Somme des Carrés Résiduels (SCR).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSCR <- summary(selec_auto)$rss\nCriteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\")\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-32-1.png){width=1536}\n:::\n:::\n\n\n\nMaintenant regardons les autres critères mentionné précédemment\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr2 <- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a <- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp <- cp_fun(mod1, SCR)\naic <- aic_fun(SCR)\nbic <- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-33-1.png){width=2880}\n:::\n:::\n\n\n\nOn peut ainsi voir que ce sont plutot des modèles entre 5 et 10 variables qui optimisent nos critères (donc pas un modèle avec toutes nos variables).\n\n#### Meilleur modèle\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncriteria_df <- data.frame(r2, r2a, cp, aic, bic)\nBest_model(selec_auto, criteria_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMeilleur modèle selon r2  =  0.546  : Modèle avec 19 variables\n (Intercept) AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN \n \nMeilleur modèle selon r2a  =  0.523  : Modèle avec 11 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists \n \nMeilleur modèle selon cp  =  5.009  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon aic  =  3031.258  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon bic  =  3065.851  : Modèle avec 6 variables\n (Intercept) AtBat Hits Walks CRBI DivisionW PutOuts \n \n```\n\n\n:::\n:::\n\n\n:::\n::::::::::\n\n### Backward\n\nCette fois ci on va regarder en sélection backward. D'abord, on fait à nouveau avec la fonction *`regsubset`*.\n\n::::::::: panel-tabset\n#### Modèle\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselec_back <- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"backward\",\n                         nvmax = 19)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(2,2))\nplot(selec_back, scale = 'bic') \nplot(selec_back, scale = 'Cp') \nplot(selec_back, scale = 'r2') \nplot(selec_back, scale = 'adjr2') \n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-36-1.png){width=1152}\n:::\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nOn remarque à nouveau une importante sélection de variables.\n\nMais ici aussi on a encore de faibles valeurs pour les $R^2$ et $R^2_{adjusted}$ pouvant témoignés d'un mauvais ajustement de modèle.\n:::\n\n#### Evolution des critères\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSCR <- summary(selec_back)$rss\nr2 <- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a <- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp <- cp_fun(mod1, SCR)\naic <- aic_fun(SCR)\nbic <- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-37-1.png){width=2880}\n:::\n:::\n\n\n\n#### Meilleur modèle\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncriteria_df <- data.frame(r2, r2a, cp, aic, bic)\nBest_model(selec_back, criteria_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMeilleur modèle selon r2  =  0.546  : Modèle avec 19 variables\n (Intercept) AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN \n \nMeilleur modèle selon r2a  =  0.523  : Modèle avec 11 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists \n \nMeilleur modèle selon cp  =  5.009  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon aic  =  3031.258  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon bic  =  3066.386  : Modèle avec 8 variables\n (Intercept) AtBat Hits Walks CRuns CRBI CWalks DivisionW PutOuts \n \n```\n\n\n:::\n:::\n\n\n:::\n:::::::::\n\n#### **Utilisation de la fonction step**\n\n------------------------------------------------------------------------\n\nOn peut également utiliser la fonction *`step`* de la library *`{stats}`*. Pour cela, on part du plus gros modèle défini précédemment par *mod1.*\n\nLa fonction *`step`* nous propose quel critère nous voulons utiliser pour la sélection entre le *BIC*, *AIC* et $C_p$.\n\n::: panel-tabset\n#### BIC\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- nrow(Hitters_Without_NA)\nmodselect_back_bic <- step(mod1,\n                       scope = formula(mod1),\n                       trace = FALSE, # trace = TRUE permet de voir le détail des étapes\n                       direction = c(\"backward\"),\n                       k = log(n) # BIC selection\n                       )\n```\n:::\n\n\n\nPuis on peut regarder le modèle qui optimise le critère utilisé pour la selection.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodselect_back_bic %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CRuns + CRBI + CWalks + \n    Division + PutOuts, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-794.06 -171.94  -28.48  133.36 2017.83 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  117.15204   65.07016   1.800 0.072985 .  \nAtBat         -2.03392    0.52282  -3.890 0.000128 ***\nHits           6.85491    1.65215   4.149 4.56e-05 ***\nWalks          6.44066    1.52212   4.231 3.25e-05 ***\nCRuns          0.70454    0.24869   2.833 0.004981 ** \nCRBI           0.52732    0.18861   2.796 0.005572 ** \nCWalks        -0.80661    0.26395  -3.056 0.002483 ** \nDivisionW   -123.77984   39.28749  -3.151 0.001824 ** \nPutOuts        0.27539    0.07431   3.706 0.000259 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 314.7 on 254 degrees of freedom\nMultiple R-squared:  0.5281,\tAdjusted R-squared:  0.5133 \nF-statistic: 35.54 on 8 and 254 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\nLa fonction step propose aussi une selection avec AIC et Cp.\n\n#### AIC\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodselect_back_aic <- step(mod1,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"backward\"),\n                       k = 2 # AIC selection\n                       )\n\nmodselect_back_aic %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + \n    CRBI + CWalks + Division + PutOuts + Assists, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-939.11 -176.87  -34.08  130.90 1910.55 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  162.53544   66.90784   2.429 0.015830 *  \nAtBat         -2.16865    0.53630  -4.044 7.00e-05 ***\nHits           6.91802    1.64665   4.201 3.69e-05 ***\nWalks          5.77322    1.58483   3.643 0.000327 ***\nCAtBat        -0.13008    0.05550  -2.344 0.019858 *  \nCRuns          1.40825    0.39040   3.607 0.000373 ***\nCRBI           0.77431    0.20961   3.694 0.000271 ***\nCWalks        -0.83083    0.26359  -3.152 0.001818 ** \nDivisionW   -112.38006   39.21438  -2.866 0.004511 ** \nPutOuts        0.29737    0.07444   3.995 8.50e-05 ***\nAssists        0.28317    0.15766   1.796 0.073673 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.8 on 252 degrees of freedom\nMultiple R-squared:  0.5405,\tAdjusted R-squared:  0.5223 \nF-statistic: 29.64 on 10 and 252 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n#### $C_p$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodselect_back_cp <- step(mod1,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"backward\"),\n                       k = 1 # Cp selection\n                       )\n\nmodselect_back_cp %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + \n    CRBI + CWalks + League + Division + PutOuts + Assists, data = Hitters_Without_NA)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-932.2 -175.4  -29.2  130.4 1897.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  135.75122   71.34623   1.903 0.058223 .  \nAtBat         -2.12775    0.53746  -3.959 9.81e-05 ***\nHits           6.92370    1.64612   4.206 3.62e-05 ***\nWalks          5.62028    1.59064   3.533 0.000488 ***\nCAtBat        -0.13899    0.05609  -2.478 0.013870 *  \nCRuns          1.45533    0.39270   3.706 0.000259 ***\nCRBI           0.78525    0.20978   3.743 0.000225 ***\nCWalks        -0.82286    0.26361  -3.121 0.002010 ** \nLeagueN       43.11162   39.96612   1.079 0.281755    \nDivisionW   -111.14603   39.21835  -2.834 0.004970 ** \nPutOuts        0.28941    0.07478   3.870 0.000139 ***\nAssists        0.26883    0.15816   1.700 0.090430 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 251 degrees of freedom\nMultiple R-squared:  0.5426,\tAdjusted R-squared:  0.5226 \nF-statistic: 27.07 on 11 and 251 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n:::\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nAvec la fonction *`step`* nous avons le modèle utilisant le critère *BIC* qui nous permet d'avoir toutes nos variables significatives (sauf l'*intercept* ce qui pourrait nous donner envie de faire des modèles sans).\n\nPar contre, nos valeurs de $R^2$ et $R^2_{adjusted}$ sont encore assez faible pour considérer ces modèles comme étant de très bonne qualité.\n:::\n\n::: callout-note\nAussi, si on veut comparer le modèle initial et le modèle final, on peut utiliser la fonction *`anova`*. Cela permet de voir si la sélection de variables a significativement amélioré l'ajustement.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(mod0, modselect_back_bic, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: Salary ~ 1\nModel 2: Salary ~ AtBat + Hits + Walks + CRuns + CRBI + CWalks + Division + \n    PutOuts\n  Res.Df      RSS Df Sum of Sq  Pr(>Chi)    \n1    262 53319113                           \n2    254 25159234  8  28159879 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\nDe manière logique on voit donc tout de même que le modèle avec nos variable explicatives sélectionnées (ici celui avec selection via le critère *BIC*) propose un meilleur ajustement que celui sans variable.\n:::\n\n### Forward\n\nCette fois ci on va regarder en sélection *forward*. D'abord, on fait à nouveau avec la fonction *`regsubset`*.\n\n::::::::: panel-tabset\n#### Modèle\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselec_forw <- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"forward\",\n                         nvmax = 19)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(2,2))\nplot(selec_forw, scale = 'bic') \nplot(selec_forw, scale = 'Cp') \nplot(selec_forw, scale = 'r2') \nplot(selec_forw, scale = 'adjr2') \n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-45-1.png){width=1152}\n:::\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nOn remarque à nouveau une importante sélection de variables.\n\nMais ici aussi on a encore de faibles valeurs pour les $R^2$ et $R^2_{adjusted}$ pouvant témoignés d'un mauvais ajustement de modèle.\n:::\n\n#### Evolution des critères\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSCR <- summary(selec_forw)$rss\nr2 <- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a <- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp <- cp_fun(mod1, SCR)\naic <- aic_fun(SCR)\nbic <- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-46-1.png){width=2880}\n:::\n:::\n\n\n\n#### Meilleur modèle\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncriteria_df <- data.frame(r2, r2a, cp, aic, bic)\nBest_model(selec_forw, criteria_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMeilleur modèle selon r2  =  0.546  : Modèle avec 19 variables\n (Intercept) AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN \n \nMeilleur modèle selon r2a  =  0.523  : Modèle avec 11 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists \n \nMeilleur modèle selon cp  =  5.009  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon aic  =  3031.258  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon bic  =  3065.851  : Modèle avec 6 variables\n (Intercept) AtBat Hits Walks CRBI DivisionW PutOuts \n \n```\n\n\n:::\n:::\n\n\n:::\n:::::::::\n\n#### **Utilisation de la fonction step**\n\n------------------------------------------------------------------------\n\nOn peut également utiliser la fonction *`step`* de la library *`{stats}`*. Cette fois ci il faut définir en modèle de départ le plus petit modèle (celui composé seulement de l'intercept).\n\nLa fonction *`step`* nous propose quel critère nous voulons utiliser pour la sélection entre le *BIC*, *AIC* et $C_p$.\n\n::: panel-tabset\n#### BIC\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodselect_forw_bic <- step(mod0,\n                       scope = formula(mod1),\n                       trace = FALSE, # trace = TRUE permet de voir le détail des étapes\n                       direction = c(\"forward\"),\n                       k = log(n) # BIC selection\n                       )\n```\n:::\n\n\n\nPuis on peut regarder le modèle qui optimise le critère utilisé pour la selection.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodselect_forw_bic %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-873.11 -181.72  -25.91  141.77 2040.47 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   91.51180   65.00006   1.408 0.160382    \nCRBI           0.64302    0.06443   9.979  < 2e-16 ***\nHits           7.60440    1.66254   4.574 7.46e-06 ***\nPutOuts        0.26431    0.07477   3.535 0.000484 ***\nDivisionW   -122.95153   39.82029  -3.088 0.002239 ** \nAtBat         -1.86859    0.52742  -3.543 0.000470 ***\nWalks          3.69765    1.21036   3.055 0.002488 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 319.9 on 256 degrees of freedom\nMultiple R-squared:  0.5087,\tAdjusted R-squared:  0.4972 \nF-statistic: 44.18 on 6 and 256 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\nLa fonction step propose aussi une selection avec AIC et Cp.\n\n#### AIC\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodselect_forw_aic <- step(mod0,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"forward\"),\n                       k = 2 # AIC selection\n                       )\n\nmodselect_forw_aic %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-939.11 -176.87  -34.08  130.90 1910.55 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  162.53544   66.90784   2.429 0.015830 *  \nCRBI           0.77431    0.20961   3.694 0.000271 ***\nHits           6.91802    1.64665   4.201 3.69e-05 ***\nPutOuts        0.29737    0.07444   3.995 8.50e-05 ***\nDivisionW   -112.38006   39.21438  -2.866 0.004511 ** \nAtBat         -2.16865    0.53630  -4.044 7.00e-05 ***\nWalks          5.77322    1.58483   3.643 0.000327 ***\nCWalks        -0.83083    0.26359  -3.152 0.001818 ** \nCRuns          1.40825    0.39040   3.607 0.000373 ***\nCAtBat        -0.13008    0.05550  -2.344 0.019858 *  \nAssists        0.28317    0.15766   1.796 0.073673 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.8 on 252 degrees of freedom\nMultiple R-squared:  0.5405,\tAdjusted R-squared:  0.5223 \nF-statistic: 29.64 on 10 and 252 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n#### $C_p$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodselect_forw_cp <- step(mod0,\n                       scope = formula(mod1),\n                       trace = FALSE, \n                       direction = c(\"forward\"),\n                       k = 1 # Cp selection\n                       )\n\nmodselect_forw_cp %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists + League, data = Hitters_Without_NA)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-932.2 -175.4  -29.2  130.4 1897.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  135.75122   71.34623   1.903 0.058223 .  \nCRBI           0.78525    0.20978   3.743 0.000225 ***\nHits           6.92370    1.64612   4.206 3.62e-05 ***\nPutOuts        0.28941    0.07478   3.870 0.000139 ***\nDivisionW   -111.14603   39.21835  -2.834 0.004970 ** \nAtBat         -2.12775    0.53746  -3.959 9.81e-05 ***\nWalks          5.62028    1.59064   3.533 0.000488 ***\nCWalks        -0.82286    0.26361  -3.121 0.002010 ** \nCRuns          1.45533    0.39270   3.706 0.000259 ***\nCAtBat        -0.13899    0.05609  -2.478 0.013870 *  \nAssists        0.26883    0.15816   1.700 0.090430 .  \nLeagueN       43.11162   39.96612   1.079 0.281755    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 251 degrees of freedom\nMultiple R-squared:  0.5426,\tAdjusted R-squared:  0.5226 \nF-statistic: 27.07 on 11 and 251 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n:::\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nAvec la fonction *`step`* nous avons le modèle utilisant le critère *BIC* qui nous permet d'avoir toutes nos variables significatives (sauf l'*intercept* ce qui pourrait nous donner envie de faire des modèles sans).\n\nPar contre, nos valeurs de $R^2$ et $R^2_{adjusted}$ sont encore assez faible pour considérer ces modèles comme étant de très bonne qualité.\n:::\n\n::: callout-note\nAussi, si on veut comparer le modèle initial et le modèle final, on peut utiliser la fonction *`anova`*. Cela permet de voir si la sélection de variables a significativement amélioré l'ajustement.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(mod0, modselect_forw_bic, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: Salary ~ 1\nModel 2: Salary ~ CRBI + Hits + PutOuts + Division + AtBat + Walks\n  Res.Df      RSS Df Sum of Sq  Pr(>Chi)    \n1    262 53319113                           \n2    256 26194904  6  27124209 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\nDe manière logique on voit donc tout de même que le modèle avec nos variable explicatives sélectionnées (ici celui avec selection via le critère *BIC*) propose un meilleur ajustement que celui sans variable.\n:::\n\n### Both\n\nMaintenant on va regarder en sélection *both*. D'abord, on fait à nouveau avec la fonction *`regsubset`*.\n\n::::::::: panel-tabset\n#### Modèle\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselec_seq <- regsubsets(Salary~.,\n                         Hitters_Without_NA,\n                         method = \"seqrep\",\n                         nvmax = 19)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(2,2))\nplot(selec_seq, scale = 'bic') \nplot(selec_seq, scale = 'Cp') \nplot(selec_seq, scale = 'r2') \nplot(selec_seq, scale = 'adjr2') \n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-54-1.png){width=1152}\n:::\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nOn remarque à nouveau une importante sélection de variables.\n\nMais ici aussi on a encore de faibles valeurs pour les $R^2$ et $R^2_{adjusted}$ pouvant témoignés d'un mauvais ajustement de modèle.\n:::\n\n#### Evolution des critères\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSCR <- summary(selec_seq)$rss\nr2 <- r2_fun(Hitters_Without_NA$Salary, SCR)\nr2a <- r2a_fun(Hitters_Without_NA$Salary, SCR)\ncp <- cp_fun(mod1, SCR)\naic <- aic_fun(SCR)\nbic <- bic_fun(SCR)\n\ngrid.arrange(Criteria_plot(r2, crit_name = \"R2\"),\n             Criteria_plot(r2a, crit_name = \"R2 ajusté\"),\n             Criteria_plot(cp, crit_name = \"Cp\"),\n             Criteria_plot(SCR, crit_name = \"Somme des Carrés Résiduels\"),\n             Criteria_plot(aic, crit_name = \"AIC\"),\n             Criteria_plot(bic, crit_name = \"BIC\"),\n             ncol = 3)\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-55-1.png){width=2880}\n:::\n:::\n\n\n\n#### Meilleur modèle\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nRegardons donc pour chaque critère quel est le modèle qui resort comme le meilleur\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncriteria_df <- data.frame(r2, r2a, cp, aic, bic)\nBest_model(selec_seq, criteria_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMeilleur modèle selon r2  =  0.546  : Modèle avec 19 variables\n (Intercept) AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN \n \nMeilleur modèle selon r2a  =  0.523  : Modèle avec 11 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists \n \nMeilleur modèle selon cp  =  5.009  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon aic  =  3031.258  : Modèle avec 10 variables\n (Intercept) AtBat Hits Walks CAtBat CRuns CRBI CWalks DivisionW PutOuts Assists \n \nMeilleur modèle selon bic  =  3065.851  : Modèle avec 6 variables\n (Intercept) AtBat Hits Walks CRBI DivisionW PutOuts \n \n```\n\n\n:::\n:::\n\n\n:::\n:::::::::\n\n#### **Utilisation de la fonction step**\n\n------------------------------------------------------------------------\n\nOn peut également utiliser la fonction *`step`* de la library *`{stats}`*.\n\nLa fonction *`step`* nous propose quel critère nous voulons utiliser pour la sélection entre le *BIC*, *AIC* et $C_p$.\n\n::: panel-tabset\n#### BIC\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodselect_seq_bic <- step(mod0,\n                  scope = formula(mod1),\n                  trace = FALSE,\n                  direction = c(\"both\"),\n                  k = log(n))\nmodselect_seq_bic %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-873.11 -181.72  -25.91  141.77 2040.47 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   91.51180   65.00006   1.408 0.160382    \nCRBI           0.64302    0.06443   9.979  < 2e-16 ***\nHits           7.60440    1.66254   4.574 7.46e-06 ***\nPutOuts        0.26431    0.07477   3.535 0.000484 ***\nDivisionW   -122.95153   39.82029  -3.088 0.002239 ** \nAtBat         -1.86859    0.52742  -3.543 0.000470 ***\nWalks          3.69765    1.21036   3.055 0.002488 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 319.9 on 256 degrees of freedom\nMultiple R-squared:  0.5087,\tAdjusted R-squared:  0.4972 \nF-statistic: 44.18 on 6 and 256 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n#### AIC\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodselect_seq_aic <- step(mod0,\n                  scope = formula(mod1),\n                  trace = FALSE,\n                  direction = c(\"both\"),\n                  k = 2)\nmodselect_seq_aic %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists, data = Hitters_Without_NA)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-939.11 -176.87  -34.08  130.90 1910.55 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  162.53544   66.90784   2.429 0.015830 *  \nCRBI           0.77431    0.20961   3.694 0.000271 ***\nHits           6.91802    1.64665   4.201 3.69e-05 ***\nPutOuts        0.29737    0.07444   3.995 8.50e-05 ***\nDivisionW   -112.38006   39.21438  -2.866 0.004511 ** \nAtBat         -2.16865    0.53630  -4.044 7.00e-05 ***\nWalks          5.77322    1.58483   3.643 0.000327 ***\nCWalks        -0.83083    0.26359  -3.152 0.001818 ** \nCRuns          1.40825    0.39040   3.607 0.000373 ***\nCAtBat        -0.13008    0.05550  -2.344 0.019858 *  \nAssists        0.28317    0.15766   1.796 0.073673 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.8 on 252 degrees of freedom\nMultiple R-squared:  0.5405,\tAdjusted R-squared:  0.5223 \nF-statistic: 29.64 on 10 and 252 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n#### $C_p$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodselect_seq_cp <- step(mod0,\n                  scope = formula(mod1),\n                  trace = FALSE,\n                  direction = c(\"both\"),\n                  k = 1)\nmodselect_seq_cp %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Salary ~ CRBI + Hits + PutOuts + Division + AtBat + \n    Walks + CWalks + CRuns + CAtBat + Assists + League, data = Hitters_Without_NA)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-932.2 -175.4  -29.2  130.4 1897.2 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  135.75122   71.34623   1.903 0.058223 .  \nCRBI           0.78525    0.20978   3.743 0.000225 ***\nHits           6.92370    1.64612   4.206 3.62e-05 ***\nPutOuts        0.28941    0.07478   3.870 0.000139 ***\nDivisionW   -111.14603   39.21835  -2.834 0.004970 ** \nAtBat         -2.12775    0.53746  -3.959 9.81e-05 ***\nWalks          5.62028    1.59064   3.533 0.000488 ***\nCWalks        -0.82286    0.26361  -3.121 0.002010 ** \nCRuns          1.45533    0.39270   3.706 0.000259 ***\nCAtBat        -0.13899    0.05609  -2.478 0.013870 *  \nAssists        0.26883    0.15816   1.700 0.090430 .  \nLeagueN       43.11162   39.96612   1.079 0.281755    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 251 degrees of freedom\nMultiple R-squared:  0.5426,\tAdjusted R-squared:  0.5226 \nF-statistic: 27.07 on 11 and 251 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n:::\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nAvec la fonction *`step`* nous avons le modèle utilisant le critère *BIC* qui nous permet d'avoir toutes nos variables significatives (sauf l'*intercept* ce qui pourrait nous donner envie de faire des modèles sans).\n\nPar contre, nos valeurs de $R^2$ et $R^2_{adjusted}$ sont encore assez faible pour considérer ces modèles comme étant de très bonne qualité.\n:::\n\n::: callout-note\nAussi, si on veut comparer le modèle initial et le modèle final, on peut utiliser la fonction *`anova`*. Cela permet de voir si la sélection de variables a significativement amélioré l'ajustement.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(mod0, modselect_seq_bic, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: Salary ~ 1\nModel 2: Salary ~ CRBI + Hits + PutOuts + Division + AtBat + Walks\n  Res.Df      RSS Df Sum of Sq  Pr(>Chi)    \n1    262 53319113                           \n2    256 26194904  6  27124209 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\nDe manière logique on voit donc tout de même que le modèle avec nos variable explicatives sélectionnées (ici celui avec selection via le critère *BIC*) propose un meilleur ajustement que celui sans variable.\n:::\n:::::::::::::::::::::::::::::::::::::::::::::::\n\n# Comparaison des critères\n\nAvant de finir, comparons un peut les critères que nous avons calculés avec ceux que l'on peut récupérer via le summary de regsubset (pour tous sauf l'AIC qui n'est pas présent). On se contentera de faire se comparatif seulement pour le modèle *stepwise*.\n\nPour cela regardons si nous avons régulièrement la valeur 0 (ou valeur proche) lorsque l'on fait la soustraction du critère calculé et du critère donné par regsubset :\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(round(r2-summary(selec_seq)$rsq) %>% mean(), \n    round(r2a-summary(selec_seq)$adjr2) %>% mean(), \n    round(cp-summary(selec_seq)$cp) %>% mean(), \n    round(bic-summary(selec_seq)$bic) %>% mean())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0 0 0 3214\n```\n\n\n:::\n:::\n\n\n\non voit une grosse différence seulement pour le *BIC* donc regardons plus en détail via les représentations visuelles de l'évolution du critère.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid.arrange(Criteria_plot(bic, crit_name = \"BIC\"),\n             Criteria_plot(summary(selec_seq)$bic, crit_name = \"BIC regsubstet ajusté\"),\n             ncol = 2)\n```\n\n::: {.cell-output-display}\n![](Exercice_01_files/figure-html/unnamed-chunk-62-1.png){width=2496}\n:::\n:::\n\n\n\nOn voit que les valeurs sont différentes mais en fait le comportement est identique. Ce qui veut dire que la différence est seulement due à une constant multiplicative près.\n\n# Conclusion\n\nÀ la lumière des résultats de notre analyse, on peut envisager le modèle *both* car bien qu'il n'ait pas montré de grandes améliorations en termes de $R^2$ et $R^2_{adjusted}$, il a une démarche plus \"souple\" pour permettre de réduire le nombre de variables tout en maintenant celles qui sont significatives. Ce modèle est donc plus parcimonieux tout en conservant des variables importantes. Cependant, une réflexion supplémentaire pourrait être menée sur l'éventuelle suppression de l'*intercept*, ce qui nécessiterait une validation supplémentaire.\n\nEn ce qui concerne le choix final du modèle, on peut opter pour celui qui maximise le critère *BIC*, ce qui nous mène à un modèle avec 6 variables. Le *BIC* est particulièrement utile pour privilégier un modèle plus simple et plus parcimonieux, ce qui est un atout lorsqu'on cherche à éviter un surajustement. Toutefois, il est important de noter que la qualité de l'ajustement n'est pas optimale, ce qui suggère qu'il pourrait manquer certaines informations pour expliquer pleinement la variable cible (le salaire).\n\nEnfin, la validité interne est un aspect crucial qui n'a pas été suffisamment exploré dans cette analyse. Il aurait été pertinent de vérifier que toutes les hypothèses sous-jacentes des modèles étaient satisfaites. Cela aurait permis de renforcer la robustesse de nos résultats et de garantir que les conclusions qu'on sont fiables.\n\nDonc, il serait pertinent d'examiner plus en profondeur des modèles sans *intercept* et la validité interne, notamment en testant les hypothèses de normalité, d'homoscédasticité, et d'indépendance des résidus.\n\n# Session info\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info(pkgs = \"attached\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       Ubuntu 24.04.1 LTS\n system   x86_64, linux-gnu\n ui       X11\n language (EN)\n collate  fr_FR.UTF-8\n ctype    fr_FR.UTF-8\n tz       Europe/Paris\n date     2025-02-25\n pandoc   3.2 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/x86_64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package    * version date (UTC) lib source\n car        * 3.1-3   2024-09-27 [1] CRAN (R 4.4.2)\n carData    * 3.0-5   2022-01-06 [1] CRAN (R 4.4.2)\n dplyr      * 1.1.4   2023-11-17 [1] CRAN (R 4.4.2)\n forcats    * 1.0.0   2023-01-29 [1] CRAN (R 4.4.2)\n ggplot2    * 3.5.1   2024-04-23 [1] CRAN (R 4.4.2)\n gridExtra  * 2.3     2017-09-09 [1] CRAN (R 4.4.2)\n ISLR       * 1.4     2021-09-15 [1] CRAN (R 4.4.2)\n kableExtra * 1.4.0   2024-01-24 [1] CRAN (R 4.4.2)\n leaps      * 3.2     2024-06-10 [1] CRAN (R 4.4.2)\n lubridate  * 1.9.4   2024-12-08 [1] CRAN (R 4.4.2)\n purrr      * 1.0.2   2023-08-10 [2] CRAN (R 4.3.3)\n readr      * 2.1.5   2024-01-10 [1] CRAN (R 4.4.2)\n stringr    * 1.5.1   2023-11-14 [2] CRAN (R 4.3.3)\n tibble     * 3.2.1   2023-03-20 [2] CRAN (R 4.3.3)\n tidyr      * 1.3.1   2024-01-24 [1] CRAN (R 4.4.2)\n tidyverse  * 2.0.0   2023-02-22 [1] CRAN (R 4.4.2)\n\n [1] /home/clement/R/x86_64-pc-linux-gnu-library/4.4\n [2] /usr/local/lib/R/site-library\n [3] /usr/lib/R/site-library\n [4] /usr/lib/R/library\n\n──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n",
    "supporting": [
      "Exercice_01_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}