{
  "hash": "4a3cec8583afa95a4f8fd46a6894767b",
  "result": {
    "markdown": "---\ntitle: \"Exercice 05\"\nauthor: \"Clément Poupelin\"\ndate: today\nformat: \n  html:\n    embed-resources: false\n    toc: true\n    code-fold: true\n    code-summary: \"Show the code\"\n    code-tools: true\n    toc-location: right\n    page-layout: article\n    code-overflow: wrap\ntoc: true\nnumber-sections: false\neditor: visual\ncategories: [\"regression logistique\", \"Correlations fortuites\", \"biais de sélection\"]\nimage: \"\"\ndescription: \"On va illustrer dans ce document les problèmes de biais de séléction et de corrélation fortuite pour des données simulé\"\n---\n\n\n\n# Setup \n\n:::: panel-tabset\n## Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Données\nlibrary(ISLR)         # Hitters data \nlibrary(dplyr)        # manipulation des données\n\n# Inférence\nlibrary(leaps)        # regsubsets \nlibrary(car)          # pour VIF\n\n# Plots\n## ggplot\nlibrary(ggplot2)\nlibrary(gridExtra)\n```\n:::\n\n\n## Fonctions\n\n::: panel-tabset\n### boxplot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_boxplot <- function(data) {\n  # Transformer les données en format long pour ggplot\n  data_long <- reshape2::melt(data)\n  \n  ggplot(data_long, aes(x = variable, y = value, fill = variable)) +\n    geom_boxplot() +\n    scale_fill_viridis_d() +  # Palette de couleurs harmonieuse\n    labs(title = \"Distribution des Variables (Boxplot)\", x = \"Variables\", y = \"Valeurs\") +\n    theme_minimal() +  # Thème épuré\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotation des étiquettes\n}\n```\n:::\n\n\n### barplot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_barplot <- function(data, variable1, variable2) {\n  ggplot(data, aes(x = {{ variable1 }}, fill = {{ variable2 }})) +\n    geom_bar(position = \"dodge\") +\n    scale_fill_manual(values = c(\"#C41E3A\", \"#0033A0\")) +  \n    labs(\n      title = \"Répartition des joueurs par League et Division\",\n      x = deparse(substitute(variable1)), \n      y = \"Nombre de joueurs\"\n    ) +\n    theme_minimal()\n}\n```\n:::\n\n\n### Heatmap\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_League_heatmap <- function(data) {\n  table_league <- as.data.frame(table(\n    data$League,\n    data$NewLeague\n  ))\n  colnames(table_league) <- c(\"League\", \"NewLeague\", \"Count\")\n  \n  ggplot(table_league, aes(x = League, y = NewLeague, fill = Count)) +\n    geom_tile(color = \"white\") +\n    scale_fill_gradient(low = \"deeppink\", high = \"deeppink4\") +\n    geom_text(aes(label = Count), color = \"white\", size = 5) +\n    labs(\n      title = \"Transition des Joueurs entre les Ligues\",\n      x = \"League d'origine\",\n      y = \"Nouvelle League\",\n      fill = \"Nombre de joueurs\"\n    ) +\n    theme_minimal()\n}\n```\n:::\n\n\n### pairs.panels\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_pairs.panels <- function(data) {\n  psych::pairs.panels(\n    data,\n    method = \"pearson\",  # Méthode de corrélation\n    hist.col = RColorBrewer::brewer.pal(9, \"Set3\"),  # Couleurs des histogrammes\n    density = TRUE,  # Ajout des courbes de densité\n    ellipses = TRUE,  # Ajout d'ellipses\n    smooth = TRUE,  # Ajout de régressions lissées\n    lm = TRUE,  # Ajout des droites de régression\n    col = \"#69b3a2\",\n    alpha = 0.5,  # Transparence\n    cex.labels = 3.5,  # Taille du texte des variables\n    font.labels = 2  # Mettre en gras\n  )\n}\n```\n:::\n\n\n### VIF plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_VIFplot <- function(vif) {\n  vif_df <- data.frame(Variable = names(vif), VIF = vif)\n  \n  p <- ggplot(vif_df, aes(\n    x = reorder(Variable, VIF),\n    y = pmin(VIF, 15),\n    fill = VIF > 10\n  )) +\n    geom_bar(stat = \"identity\") +\n    geom_text(aes(label = ifelse(VIF > 10, round(VIF, 1), \"\")), hjust = -0.2, size = 6) +\n    coord_flip() +\n    scale_fill_manual(values = c(\"FALSE\" = \"#0072B2\", \"TRUE\" = \"#D55E00\")) +\n    labs(title = \"Variance Inflation Factor (VIF)\", x = \"Variables\", y = \"VIF (limité à 15)\") +\n    theme_minimal() +\n    theme(\n      axis.title = element_text(size = 34, face = \"bold\"),\n      plot.title = element_text(\n        size = 54,\n        face = \"bold\",\n        hjust = 0.5\n      ),\n      axis.text.x = element_text(size = 26),\n      axis.text.y = element_text(size = 18),\n      legend.text = element_text(size = 30),\n      legend.title = element_text(size = 38, face = \"bold\")\n    )\n  \n  return(p)\n}\n```\n:::\n\n\n### Critères\n\nOn rappel que $SCR = \\sum_i (y_i - f(x_i))^2$ et $SCT = \\sum_i (y_i - \\bar{y})^2$.\\\n\nAinsi, on peut aretrouver les différents critères :\n\n$$ R^2 = 1 - \\frac{SCR}{SCT}$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr2_fun <- function(y, SCR){\n  # r2 = SSE/SST = (SST - SSR)/SST = 1 - ssr/sst\n  SCT <- sum((y - mean(y) )^2)\n  r2 <- 1 - SCR/SCT\n  return(r2)\n}\n```\n:::\n\n\n$$ R^2_{adjusted} = 1 - \\frac{SCR (n-1)}{SCT(n-(p+1))}$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr2a_fun <- function(y, SCR){\n  n <- dim(Hitters_Without_NA)[1]\n  p <- 1:(dim(Hitters_Without_NA)[2]-1)\n  SCT <- sum((y - mean(y) )^2)\n  r2a <- 1 - (SCR/(n-(p+1)))/(SCT/(n-1))\n  return(r2a)\n}\n```\n:::\n\n\n$$ C_p = \\frac{SCR}{\\sigma^2} + 2(p+1) - n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncp_fun <- function(mod, SCR){\n  sig <- summary(mod)$sigma\n  n <- dim(Hitters_Without_NA)[1]\n  p <- 1:(dim(Hitters_Without_NA)[2]-1)\n  cp <- SCR/sig^2 + 2*(p+1) - n\n  return(cp)\n}\n```\n:::\n\n\n$$ AIC = n\\text{log}\\left(\\frac{SCR}{n}\\right) + 2(p+1)$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\naic_fun <- function(SCR){\n  n <- dim(Hitters_Without_NA)[1]\n  p <- 1:(dim(Hitters_Without_NA)[2]-1)\n  aic <- n * log(SCR/n) + 2*(p+1)\n  return(aic)\n}\n```\n:::\n\n\n$$ BIC = n\\text{log}\\left(\\frac{SCR}{n}\\right) + \\text{log}(n)(p+1)$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbic_fun <- function(SCR){\n  n <- dim(Hitters_Without_NA)[1]\n  p <- 1:(dim(Hitters_Without_NA)[2]-1)\n  bic <- n * log(SCR/n) + log(n)*(p+1)\n  return(bic)\n}\n```\n:::\n\n\n### plot pour nos critères\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCriteria_plot <- function(Criteria, crit_name = \"Critère\") {\n  # Création d'un data frame pour ggplot\n  df_criteria <- data.frame(\n    nb_var = seq_along(Criteria),  # Nombre de variables du modèle\n    Criteria = Criteria            # Critère\n  )\n\n  # Création du plot avec ggplot2\n  g <- ggplot(df_criteria, aes(x = nb_var, y = Criteria)) +\n    geom_line(color = \"#0072B2\", linewidth = 1) +  \n    geom_point(color = \"#D55E00\", size = 4) + \n    labs(\n      title = paste(\"Évolution de\", crit_name, \"en fonction du nombre de variables\"),\n      x = \"Nombre de variables sélectionnées\",\n      y = crit_name\n    ) +\n    theme_minimal() + \n    theme(\n      plot.title = element_text(hjust = 0.5, face = \"bold\", size = 26),  # Titre centré et agrandi\n      axis.title.x = element_text(face = \"bold\", size = 22),\n      axis.title.y = element_text(face = \"bold\", size = 22),\n      axis.text = element_text(size = 20)\n    )\n\n  return(g)\n}\n```\n:::\n\n\n### Meilleur modèle après regsubset\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBest_model <- function(model, criteria_df){\n  ## On a d'abord les critères à maximiser\n  for(i in 1:2){\n    criteria_name <- colnames(criteria_df)[i]\n    criteria <- criteria_df[,i]\n    \n    best_model_criteria <- which.max(criteria)\n    selected_vars <- summary(model)$which[best_model_criteria,]\n    \n    cat(\"Meilleur modèle selon\", criteria_name, \" = \", round(max(criteria), 3), \" : Modèle avec\", best_model_criteria, \"variables\\n\", \n        rownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE]), \"\\n\", \"\\n\")\n  }\n  ## On a ensuite les critères à minimiser\n  for(i in 3:5){\n    criteria_name <- colnames(criteria_df)[i]\n    criteria <- criteria_df[,i]\n    \n    best_model_criteria <- which.min(criteria)\n    selected_vars <- summary(model)$which[best_model_criteria,]\n    \n    cat(\"Meilleur modèle selon\", criteria_name, \" = \", round(min(criteria), 3),\" : Modèle avec\", best_model_criteria, \"variables\\n\", \n        rownames(as.data.frame(selected_vars)[as.data.frame(selected_vars)[, 1] == TRUE, , drop = FALSE]), \"\\n\", \"\\n\")\n  }\n}\n```\n:::\n\n:::\n\n## Seed\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(140400)\n```\n:::\n\n\n::::\n\n# Données\n\nDans ce rapport, nous allons pouvoir illustrer deux grands problèmes qui apparaissent dans le domaine de la statistique en grande dimension :\n\n-  le biais de sélection\n\n- et les corrélations fortuites\n\nPour faire cela, nous nous baserons sur un jeu de données que l'on créera.  On génère alors\n\n- $y$ de taille $n=100$ avec $y_i \\sim \\mathcal{B}(0.5)$\n\n- $X$ qui contient $p=5000$ variables explicatives qui seront toutes des réalisations indépendantes de $n=100$ valeurs issues d'une loi $\\mathcal{N}_{(0,1)}$ \n\n\nPour cela, nous pouvons utiliser les fonction de *`R`* qui permettent de générer des variables aléatoire.\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 100\np <- 5000\ny <- rbinom(n = 100, size = 1, prob = 0.5)\nx <- matrix(rnorm(n*p, 0, 1), ncol = p) %>% as.data.frame()\n\nSimu_data <- cbind(y, x) %>% as.data.frame()\n```\n:::\n\n\n\n::: callout-note\nPour la variable $y$, il est possible de la simuler de manière deterministe `y <- rep(c(0,1), n/2)`\n:::\n\n::: callout-note\npour des raisons de repouctibilité, une graine ou seed a été défini dans le setup afin que la génération aléatoire reste identique.\n:::\n\n# Analyse descriptive\n\n## Corrélation\n\nMaintenant, nous pouvons déjà souligner que, théoriquement, il ne devrait pas y avoir de lien entre $y$ et $X$ puisque les simulations sont faites indépendament. \\\nPour visualiser cela, il suffit simplement de créer un vecteur qui stockera les différentes valeurs de corrélation entre $y$ et $x^i$ pour $i$ allant de 1 à 5000.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor_vect <- unlist(lapply(x, function(col) cor(col, y)))\n\nmy_hist <- function(data) {\n  cor_df <- data.frame(Correlation = data)\n  \n  p <- ggplot(cor_df, aes(x = Correlation)) +\n    geom_histogram(fill = \"skyblue\",\n                   color = \"black\",\n                   bins = 20) +\n    labs(title = \"Distribution des corrélations entre y et les variables explicatives\", x = \"Corrélation\", y = \"Fréquence\") +\n    theme_minimal() +\n    theme(\n      plot.title = element_text(\n        size = 16,\n        face = \"bold\",\n        hjust = 0.5\n      ),\n      axis.title = element_text(size = 14, face = \"bold\"),\n      axis.text = element_text(size = 12)\n    )\n  return(p)\n}\n\nmy_hist(cor_vect)\n```\n\n::: {.cell-output-display}\n![](Exercice_05_files/figure-html/unnamed-chunk-15-1.png){width=768}\n:::\n:::\n\n\n\n::: panel-tabset\n\n## Texte\n\nDe manière général, il faut savoir qu'une méthode de prévision de $y$ basée sur les variables explicatives s’exprime nécessairement sous la forme $\\hat{y} = f(x^1, ..., x^{5000})$. La forme de la fonction $f$ étant généralement obtenue grâce à une estimation sur un échantillon d’apprentissage. Il faut alors découper notre jeu de données en deux échantillons, un pour l'apprentissage et un pour le test.\\\n\nDans ces méthodes, nous nous intéressons principalement au taux d’erreur de classification \"test\", c’est-à-dire à la probabilité que $\\hat{y}$ soit différent de $y$, lorsque $y$ et $x^1, ..., x^{5000}$ sont dans l'échantillon test et donc indépendants de l’échantillon d’apprentissage.\\\nOn peut facilement démontrer que cette probabilité est de 50% quelle que soit la méthode utilisée (cf **Preuve**).\n\nPourtant, pour illustrer nos problèmes, supposons que nous avons observé le jeu de données simulé ci-dessus, sans connaître les liens théoriques entre les variables. Nous souhaitons alors ajuster un modèle expliquant au mieux $y$ en fonction des variables à disposition, et estimer le taux d’erreur des prévisions associées.\n\n## Preuve\n\nNous remarquons déjà que, $\\hat{y}$ étant une combinaisons de nos variables $x^1, ..., x^{5000}$ qui sont indépendantes de $y$, on a $\\hat{y}$ et y sont deux variables indépendantes l'une de l'autre.\\\n\nAinsi\n$$\\mathbb{P}(\\hat{y} \\neq y) = \\mathbb{P}(\\hat{y}=0, y=1) + \\mathbb{P}(\\hat{y}=1, y=0)$$\n$$ \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad = \\mathbb{P}(\\hat{y}=0)\\mathbb{P}(y=1) + \\mathbb{P}(\\hat{y}=1)\\mathbb{P}(y=0) \\quad  ^{(*)}$$\n$$ \\quad \\quad \\quad \\quad = 0.5\\mathbb{P}(\\hat{y}=0) + 0.5\\mathbb{P}(\\hat{y}=1)  \\quad  ^{(**)} $$\n$$ \\quad \\quad = 0.5 \\left( \\mathbb{P}(\\hat{y}=0) + \\mathbb{P}(\\hat{y}=1) \\right)$$\n\n\nNous reconnaissons ici une somme sur l'univers des possible de la densité discrète de $\\hat{y}$.\\\nCelle ci est donc égale à 1 et on obtient\n\n$$\\mathbb{P}(\\hat{y} \\neq y) = 0.5$$\n\n\n- $^{(*)} \\quad \\text{par indépendance de} \\quad \\hat{y} \\quad \\text{et} \\quad y$\n\n- $^{(**)} \\quad \\text{car} \\quad y \\quad \\text{suit une loi de Bernoulli de paramètre} \\quad 0.5$\n\n:::\n\n# Biais de sélection\n\n::: panel-tabset\n\n## Texte\n\nÉtant donné le très grand nombre de variables explicatives, on ne va garder que les 5 variables les plus corrélées avec $y$ afin d’ajuster un modèle\nde régression logistique. Pour quantifier la corrélation entre la variable $y$, qui est binaire, et une variable quantitative, deux possibilités s’offrent :\n\n- utiliser la corrélation de Pearson $\\hat{\\rho}$ comme si $y$ était une variable\n\n\n- utiliser le \"rapport de corrélation\" quantifiant le lien entre une variable qualitative et une variable quantitative : \n$$\\hat{\\eta}^2 = \\frac{S^2_{inter}}{S^2_{total}}$$\noù $S^2_{inter}$ est la somme des carrés \"inter-classes\" et $S^2_{total}$ la somme des carrés\ntotal.\n\nPar chance, dans notre cas nous avons que $\\hat{\\eta}^2 = \\hat{\\rho}^2$.\\\nMais rassurez vous, la chance n'ayant pas forcément sa place en mathématiques, la démonstration de cette égalité pourra être trouvé dans la partie **Preuve**\\\nAinsi, la corrélation de Pearson pourra suffire pour quantifier le lien entre notre variable binaire et nos variables explicatives. Ce qui tombe bien puisqu'il s'agit de la méthode de corrélation par défaut sous $\\textit{R}$ quand on utilise la fonction $\\textit{cor}$.\\\nNous allons donc pouvoir garder les 5 variables les plus corrélées en valeur absolue avec $y$ et ajuster un modèle de régression logistique faisant intervenir ces 5 variables.\n\n## Preuve\n\n\nNous voulons ici montrer que dans le cas des donnés que nous simulons, il y a égalité entre les deux coefficients suivants.\n$$\\hat{\\rho}^2 = \\left(\\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y}) }{\\sqrt{\\sum_{i=1}^n (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^n(y_i -\\bar{y})^2}}\\right)^2$$\n\n$$\\hat{\\eta}^2 = \\frac{\\sum_{k=0}^1 n_k(\\bar{x}_k - \\bar{x})^2}{\\sum_{i=1}^n (x_i - \\bar{x})^2}$$\n\nNous pouvons déjà reconnaitre un terme en commun.\\\nPour des raisons de simplicité, on notera $S_x^2 = \\sum_{i=1}^n (x_i - \\bar{x})^2$\\\n\nNous pouvons alors manipuler un peu les termes de $\\hat{\\rho}$\\\n$\\sum_{i=1}^n (x_i-\\bar{x})(y_i - \\bar{y})= \\sum_{i=1}^n x_iy_i - n\\bar{x}\\bar{y}$\\\net\\\n$\\sum_{i=1}^n(y_i -\\bar{y})^2= \\sum_{i=1}^n y_i^2 - n\\bar{y}^2$\\\n\nMaintenant, rappelons que dans notre cas précis, $\\forall i=1, ...,n$ où $n=100$, $y_i \\sim \\mathcal{B}(0.5)$. Nous pouvons donc supposer qu'idéalement on a une parfaite séparation en deux groupes avec autant de 0 que de 1. Et ainsi en déduire les simplifications suivantes :\n\n- $\\sum_{i=1}^n y_i^2 = \\sum_{i=1}^n y_i$\n\n- $\\bar{y} = \\frac{n_1}{n}$\n\n- $\\sum_{i=1}^n x_iy_i = n_1\\bar{x}_1 \\quad$ puisque l'on multipli par $0$ les $x_i$ associés au groupe $0$\n\n\nDès lors, nous avons $\\hat{\\eta}^2 = \\frac{n_0(\\bar{x}_0 - \\bar{x})^2 + n_1(\\bar{x}_1 - \\bar{x})^2}{S_x^2}$ et \n\n$$\\hat{\\rho}^2 = \\frac{1}{S_x^2} \\times \\frac{(n_1\\bar{x}_1 - n_1\\bar{x})^2}{n_1 - \\frac{n_1^2}{n}}$$\n    $$\\quad  = \\frac{1}{S_x^2} \\times \\frac{n_1(\\bar{x}_1 - \\bar{x})^2}{1 - \\frac{n_1}{n}}$$\n    $$\\quad  = \\frac{1}{S_x^2} \\times \\frac{n_1(\\bar{x}_1 - \\bar{x})^2}{\\frac{n_0}{n}}$$\n    $$\\quad \\quad = \\frac{1}{S_x^2} \\times \\frac{n n_1(\\bar{x}_1 - \\bar{x})^2}{n_0}$$\n\nCela veut donc dire que l'on cherchera à montrer que\n\n$$\\frac{n n_1(\\bar{x}_1 - \\bar{x})^2}{n_0} = n_0(\\bar{x}_0 - \\bar{x})^2 + n_1(\\bar{x}_1 - \\bar{x})^2$$    \n$$\\quad \\quad \\Leftrightarrow 1 = \\frac{n_0^2(\\bar{x}_0 - \\bar{x})^2}{n n_1(\\bar{x}_1 - \\bar{x})^2} \\times \\frac{n_0}{n}$$\n\nMais si on suppose que $y$ est \"parfaitement équilibrée\", c'est à dire qu'il y aurait autant de 0 que de 1, on aura que $n_0 = n_1 = \\frac{n}{2}$ et aussi \n$$n\\bar{x} = n_0\\bar{x}_0 + n_1\\bar{x}_1 \\Leftrightarrow \\bar{x} = \\frac{1}{2}(\\bar{x}_0 + \\bar{x}_1) \\Leftrightarrow \\bar{x}-\\bar{x}_0 = \\bar{x}_1 - \\bar{x}$$\n\n\\noindent Nous aurons donc que $(\\bar{x}_0-\\bar{x})^2  = (\\bar{x}_1 - \\bar{x})^2$\n\nFinalement,\n$$\\frac{n_0^2(\\bar{x}_0 - \\bar{x})^2}{n n_1(\\bar{x}_1 - \\bar{x})^2} \\times \\frac{n_0}{n} = \\frac{(\\frac{n}{2})^2}{n (\\frac{n}{2})} + \\frac{(\\frac{n}{2})}{n}$$\n  $$\\quad \\quad \\quad \\quad \\quad \\quad = \\frac{(\\frac{n}{2})}{n} + \\frac{(\\frac{n}{2})}{n}$$\n    $$\\quad \\quad \\quad \\quad \\quad \\quad = \\frac{1}{2} + \\frac{1}{2}$$\n    $$\\quad \\quad \\quad \\quad \\quad \\quad= 1$$\n\nDans la situation que nous avons ici, nous pouvons donc conclure que $\\hat{\\rho}^2 = \\hat{\\eta}^2$. On peut également supposer que cette égalité reste approximativement vrai dans des cas où \"l'équilibre\" n'est pas parfait.\n\n\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkeep_variables <- order(abs(cor_vect), decreasing=TRUE)[1:5]\n\nSub_Simu_data <- data.frame(cbind(y, x[,keep_variables]))\n\nmod <- glm(y ~ ., data = Sub_Simu_data, family = 'binomial')\nmod %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = y ~ ., family = \"binomial\", data = Sub_Simu_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1392  -0.6649   0.2322   0.8332   2.0389  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)   \n(Intercept)   0.5826     0.2868   2.031  0.04223 * \nV3530        -0.8820     0.2864  -3.079  0.00207 **\nV2416         0.5686     0.2744   2.073  0.03821 * \nV1512         1.0119     0.3180   3.182  0.00146 **\nV1480        -0.4042     0.3044  -1.328  0.18417   \nV3875         0.9207     0.3254   2.830  0.00466 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 137.628  on 99  degrees of freedom\nResidual deviance:  90.046  on 94  degrees of freedom\nAIC: 102.05\n\nNumber of Fisher Scoring iterations: 5\n```\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Correlations fortuites\n\n# Conclusion\n\nEn conclusion, avec cette étude nous avons pu illustrer deux grands problèmes que nous pouvons observer dans le cas de la Statistique en grande dimension. \\\n\nNous avons le **biais de sélection** qui arrive lorsque l'on utilise notre échantillon test dans la sélection de variable ou l'ajustement du modèle. Et donc quand on confronte nos prévisions à l'échantillon test, ces dernières seront beaucoup trop optimistes. C'est pour ca que la séparation de notre échantillon doit être faite avant la sélection de nos variables.\\\n\nPuis, il y a la **corrélation fortuite** qui est propre à la grande dimension et qui nous montre qu'il faut bien connaître nos données. Lorsque l'on veut construire un modèle, il faut déjà avoir une connaissance sur les variables qui peuvent être liées. Et si on cherche des corrélation sur un jeu de grande dimension, on risque probablement d'en trouver même si théoriquement il n'y en à pas.\\\n\nNous voyons donc qu'il faut comprendre les données sur lesquelles nous travaillons et même si les ordinateurs sont des outils performants, il faut que le statisticien garde toujours un regard critique sur les résultats.\n\n# Session info\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info(pkgs = \"attached\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23 ucrt)\n os       Windows 10 x64 (build 22631)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  French_France.utf8\n ctype    French_France.utf8\n tz       Europe/Paris\n date     2025-02-20\n pandoc   3.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package   * version date (UTC) lib source\n car       * 3.1-2   2023-03-30 [1] CRAN (R 4.2.3)\n carData   * 3.0-5   2022-01-06 [1] CRAN (R 4.2.1)\n dplyr     * 1.1.4   2023-11-17 [1] CRAN (R 4.2.3)\n ggplot2   * 3.5.1   2024-04-23 [1] CRAN (R 4.2.3)\n gridExtra * 2.3     2017-09-09 [1] CRAN (R 4.2.1)\n ISLR      * 1.4     2021-09-15 [1] CRAN (R 4.2.3)\n leaps     * 3.1     2020-01-16 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/cleme/AppData/Local/R/win-library/4.2\n [2] C:/Program Files/R/R-4.2.1/library\n\n──────────────────────────────────────────────────────────────────────────────\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# We simulate our Data Frame\nn = 100\ny = rbinom(n = 100, size = 1, prob = 0.5)\nX = matrix(rnorm(n*5000, 0, 1), ncol = 5000)\n\ndf = cbind.data.frame(y, X)\ndim(df) # We can verify the dimensions\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  100 5001\n```\n:::\n\n```{.r .cell-code}\n# Other way to simulate \n#y = rep(c(0,1), n/2)\n#X = matrix(rnorm(n*5000,0,1), ncol = 5000)\n```\n:::\n\n\n\nStatistique descriptive \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# We build a vector to store the correlation between y and each explanatory variables\ncor_vect = 1:dim(X)[2]\nfor(i in 1:dim(X)[2]){\n  cor_vect[i]=cor(X[,i],y)\n}\n\nhist(cor_vect,\n     main =\"Histogram of the correlation between\n     y and the explanatory variables\",\n     xlab = \"Correlation\",\n     col = \"skyblue\")\n```\n\n::: {.cell-output-display}\n![](Exercice_05_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n### Question 2\n\nQuel est le lien attendu entre y et les variables explicatives ?\n\nOn s'attend à ce qu'il n'y ait pas forcément de lien puisqu'on est dans les cas de variables aléatoires créées indépendamment \n\n\n\n### Question 3\n\nUne méthode de prévision de y basée sur les variables explicatives $x^1, ..., x^{5000}$ s’exprime nécessairement sous la forme $\\hat{y} = f(x^1, ..., x^{5000})$. La forme de la fonction $f$ est généralement obtenue grâce à une estimation sur un échantillon d’apprentissage. On s’intéresse au taux d’erreur de classification \"test\", c’est-à-dire à la probabilité que $\\hat{y}$ soit différent de $y$, lorsque $y$ et $x^1, ..., x^{5000}$ sont indépendants de l’échantillon d’apprentissage.\nMontrer que quelle que soit la méthode utilisée, le taux d’erreur sera de 50%\n\nFAIRE SUR PAPIER\n\n\n\n\n\n\n\n\n\nDans la suite de l’exercice, on suppose qu’on a observé le jeu de données\nsimulé ci-dessus, sans connaître les liens théoriques entre les variables. On\nsouhaite ajuster un modèle expliquant au mieux $y$ en fonction des variables à\ndisposition, et estimer le taux d’erreur des prévisions associées. Etant donné\nle très grand nombre de variables explicatives, un statisticien décide de ne\ngarder que les 5 variables les plus corrélées avec $y$ afin d’ajuster un modèle\nde régression logistique.\n\n\n### Question 4\nPour quantifier la corrélation entre la variable y, qui est binaire, et une\nvariable quantitative, deux possibilités s’offrent a priori au statisticien :\n(i) soit utiliser la corrélation de Pearson $\\hat{\\rho}$ (comme si $y$ était une variable\nquantitative),\n\n\n::: {.cell}\n\n:::\n\n\n\n\n(ii) soit utiliser le \"rapport de corrélation\" quantifiant le lien entre une variable qualitative et une variable quantitative :\n$$\\hat{\\eta}^2 = \\frac{S^2_{inter}}{S^2_{total}}$$\noù $S^2_{inter}$ est la somme des carrés \"inter-classes\" et $S^2_{total}$ la somme des carrés\ntotal.\n\n\n::: {.cell}\n\n:::\n\n\n\n\nMontrer que dans notre cas :\n$$ \\hat{\\eta}^2 = \\hat{\\rho}^2 $$ \n\n\n\n\n\n\n\n\n### Question 5\nQuelles sont les 5 variables les plus corrélées (en valeur absolue) avec $y$ ?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# We can isolate the highest correlations (positive or negative)\nsort(abs(cor_vect), decreasing=TRUE)[1:5] \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3852168 0.3707116 0.3702511 0.3513121 0.3474799\n```\n:::\n\n```{.r .cell-code}\n# We see that we have no correlation above 40%\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# We isolate the index of the 5 variables with the highest correlation \nindex = order(abs(cor_vect), decreasing=TRUE)[1:5]\n\n# We create our new Data Frame\ndf_cut = data.frame(cbind(y, X[,index]))\ndim(df_cut)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 100   6\n```\n:::\n:::\n\n\n\n\n\n### Question 6\nAjuster un modèle de régression logistique faisant intervenir ces 5 variables et analyser la qualité du modèle.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit = glm(y~., data = df_cut, family = 'binomial')\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = y ~ ., family = \"binomial\", data = df_cut)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.3156  -0.5999   0.2005   0.6587   2.0247  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)   \n(Intercept)   0.1902     0.2698   0.705  0.48097   \nV2           -0.6138     0.2988  -2.054  0.03993 * \nV3            0.6526     0.2889   2.259  0.02390 * \nV4           -0.6729     0.3117  -2.159  0.03088 * \nV5            0.8727     0.2878   3.033  0.00242 **\nV6            0.7080     0.2680   2.641  0.00826 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 138.469  on 99  degrees of freedom\nResidual deviance:  87.238  on 94  degrees of freedom\nAIC: 99.238\n\nNumber of Fisher Scoring iterations: 5\n```\n:::\n:::\n\n\n### Question 7\nAfin d’estimer le taux d’erreur de classification associé à ce modèle, le statisticien décide de procéder à une validation croisée K-fold avec K = 10.\nEstimer de cette manière le taux d’erreur.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncost = function(r, pi ){\n  c = mean(abs(r - pi) > 0.5)\n  return(c)\n} \n\n# Cross validation K-fold\ncv.glm(df_cut, fit, cost, 10)$delta[1] \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.24\n```\n:::\n:::\n\n\n\n\n### Question 8\nRecommencer 10 fois la démarche précédente, c’est à dire les questions 1.,\n5., 6. et 7, et stocker les 10 taux d’erreurs estimés. Que valent ces estimations. Quelle est leur moyenne ? Ces résultats sont-ils conformes à la valeur\nthéorique attendue ?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nK = 10\nres = 1:K # Vector to store the raw cross-validation estimate of prediction error\nfor(i in 1:K){\n  cat(paste(i, \"->\")) # counter to see progress\n  \n  # We recreate our explanatory variables and look at correlations\n  X = matrix(rnorm(n*5000, 0, 1), ncol = 5000)\n  cor_vect = 1:dim(X)[2]\n  for(j in 1:dim(X)[2]){\n    cor_vect[j] = cor(X[,j], y)\n  }\n  \n  # We keep the variables with the higher correlation\n  index = order(abs(cor_vect), decreasing = T)[1:5]\n  tab = data.frame(cbind(y, X[, index]))\n  \n  # We fit our glm\n  fit = glm(y~., data = tab, family = 'binomial')\n  res[i] = cv.glm(tab, fit, cost, 10)$delta[1]\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1 ->2 ->3 ->4 ->5 ->6 ->7 ->8 ->9 ->10 ->\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nres\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.23 0.18 0.25 0.21 0.19 0.20 0.18 0.25 0.26 0.20\n```\n:::\n\n```{.r .cell-code}\nmean(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.215\n```\n:::\n\n```{.r .cell-code}\n# erreur dans notre demarche, pas normal on obtient 0.22 alors que c'est 0.5 qui est attendu\n```\n:::\n\n\n\n\nLe problème précédent est appelé biais de sélection. Lorsque l’on effectue la\nvalidation croisée, l’échantillon test n’est certes pas utilisé pour l’estimation\ndu modèle, mais il a été utilisé initialement pour sélectionner les variables.\nAinsi lorsqu’on confronte les prévisions à l’échantillon test, ces dernières\nsont trop optimistes car elles ont déjà utilisé l’information contenue dans\ncet échantillon test. Pour estimer convenablement le taux d’erreur, il faut\nque l’échantillon test ne soit utilisé à aucun moment dans la procédure de\nmodélisation.\n\n\n### Question 9\nMettre en oeuvre une validation croisée valide, respectant la règle précédente,\npour estimer le taux d’erreur associé à la démarche de modélisation choisie\npar le statisticien. Recommencer la démarche 10 fois, comme dans la question\n7., afin d’obtenir 10 estimation du taux d’erreur. Comparer avec la valeur\nthéorique attendue.\nOn pourra utiliser la fonction cvsegments de la librairie pls pour découper\nl’échantillon aléatoirement en K parties de taille égale.\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pls)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: le package 'pls' a été compilé avec la version R 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttachement du package : 'pls'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nL'objet suivant est masqué depuis 'package:stats':\n\n    loadings\n```\n:::\n\n```{.r .cell-code}\n# To avoid selection bias, we create a list of kf segments in order to separate sample \nkf = 10 # number of segments \nseg = cvsegments(nrow(X), kf)\n\ntmp = 1:kf\nfor (i in 1:kf) {\n  # We define our sample test\n  sample_test = seg[[i]]\n  \n  # We build a vector to store the correlation between y and each explanatory variables contain into the segment\n  cor_vect = 1:5000\n  for(j in 1:5000){\n    cor_vect[j] = cor(X[-sample_test, j], y[-sample_test])\n  }\n  \n  # We keep the variables with the higher correlation\n  indexvar = order(abs(cor_vect), decreasing=T)\n  tab = data.frame(cbind(y, X[, indexvar[1:5]]))\n  \n  # We fit our glm \n  fit = glm(y~., data = tab, subset = -sample_test, family = 'binomial')\n  pred = predict(fit, tab[sample_test,], type = \"response\")\n  \n  tmp[i] = cost(y[sample_test], pred)\n}\n\nmean(tmp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.45\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# We repeat the process 10 times \nres2 = 1:10\nfor(k in 1:10){\n  cat(paste(k, \"->\")) # counter to see progress\n  \n  # We recreate our explanatory variables\n  X = matrix(rnorm(n*5000, 0, 1), ncol = 5000)\n  \n  # We create a list of kf segments in order to separate sample\n  Kf = 10\n  seg = cvsegments(nrow(X),Kf) \n  \n  tmp = 1:Kf\n  for(i in 1:Kf){\n    # We define our sample test\n    test = seg[[i]]\n    \n    # We build a vector to store the correlation between y and each explanatory variables contain into the segment\n    cor_vect = 1:5000\n    for(j in 1:5000){\n      cor_vect[j] = cor(X[-test,j],y[-test])\n    }\n    \n    # We keep the variables with the higher correlation\n    indexvar = order(abs(cor_vect), decreasing = T)\n    tab = data.frame(cbind(y, X[, indexvar[1:5]]))\n    \n    # We fit our glm \n    fit = glm(y~., data = tab, subset = -test, family = 'binomial')\n    pred = predict(fit, tab[test,], type = \"response\")\n    \n    tmp[i] = cost(y[test], pred)\n  }\n  res2[k] = mean(tmp)\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1 ->2 ->3 ->4 ->5 ->6 ->7 ->8 ->9 ->10 ->\n```\n:::\n\n```{.r .cell-code}\nres2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.53 0.70 0.52 0.51 0.69 0.42 0.46 0.51 0.61 0.51\n```\n:::\n\n```{.r .cell-code}\nmean(res2) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.546\n```\n:::\n:::\n\n\n\n### Question 10\nà partir de quelle valeur $|\\hat{\\rho}|$ peut-on considérer que deux variables ont une corrélation significativement non-nulle au seuil $α = 5\\%$ ?\n\n::: {.cell}\n\n```{.r .cell-code}\ny = rbinom(n, 1, 0.5)\nX = matrix(rnorm(n*5000, 0, 1), ncol = 5000)\n\n# We build a vector to store the correlation between y and each explanatory variables\ncor_vect = 1:5000\nfor(i in 1:5000){\n  cor_vect[i] = cor(X[,i], y)\n}\n\n# We look at the quantile\nquant = qnorm(0.975, 0, 1/10)\nquant\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1959964\n```\n:::\n:::\n\n\n\n\n### Question 11\nComparer les corrélations des variables dans le modèle précédent avec ce seuil ?\n\n::: {.cell}\n\n```{.r .cell-code}\n# We keep the variables with the higher correlation\nindex = order(abs(cor_vect), decreasing = T)\nindex[1:5] \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  663 3121 2740 3782  259\n```\n:::\n\n```{.r .cell-code}\ncor_vect[index[1:5]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.3548252 -0.3541487  0.3525526 -0.3479385 -0.3453889\n```\n:::\n\n```{.r .cell-code}\n# For our 5 variables with the higher correlation, we look this correlation is more than our quantile\nsum((abs(cor_vect[index[1:5]]))>quant)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5\n```\n:::\n:::\n\n\n\n### Question 12\nParmi 5000 variables théoriquement non corrélées avec $y$, environ combien de variables observées sur $n = 100$ individus présenteront une corrélation empirique significativement non nulles avec y au seuil $α = 5\\%$ ? Le vérifier sur le jeu de données simulé.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# We look at the number of variables in our model where the correlation with y is more than our quantile\nsum((abs(cor_vect))>quant)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 283\n```\n:::\n:::\n",
    "supporting": [
      "Exercice_05_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}