{
  "hash": "547539c0d83f51c317f082cc8b396aea",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exercice 06\"\nauthor: \"Clément Poupelin\"\ndate: \"2025-02-23\"\ndate-modified: \"2025-02-25\"\nformat: \n  html:\n    embed-resources: false\n    toc: true\n    code-fold: true\n    code-summary: \"Show the code\"\n    code-tools: true\n    toc-location: right\n    page-layout: article\n    code-overflow: wrap\ntoc: true\nnumber-sections: false\neditor: visual\ncategories: [\"Régression sur composantes principales\", \"Régression des moindres carrés partiels\", \"Validation croisée\"]\nimage: \"/img/baseball.png\"\ndescription: \"On reprend les données de baseball en mettant en pratique les techniques de **PCR** et **PLSR**\"\n---\n\n\n\n# Intervenant.e.s\n\n### Rédaction\n\n-   **Clément Poupelin**, [clementjc.poupelin\\@gmail.com](mailto:clementjc.poupelin@gmail.com){.email}\\\n\n### Relecture\n\n-   \n\n# Rappels sur PCR et PLSR\n\nDans l’analyse des données et la modélisation statistique, la régression linéaire classique peut être limitée lorsque les variables explicatives sont fortement corrélées (problème de colinéarité) ou lorsque leur nombre est supérieur au nombre d’observations (problème de haute dimensionnalité). Pour remédier à ces défis, des méthodes de réduction de dimensionnalité comme la **Régression sur Composantes Principales** (**PCR**) et la **Régression des Moindres Carrés Partiels** (**PLSR**) sont utilisées.\n\n::: panel-tabset\n## PCR\n\nLa **régression sur Composantes Principales** (**PCR**) repose sur une Analyse en Composantes Principales (ACP) pour transformer les variables explicatives en nouvelles variables orthogonales appelées composantes principales. Seules les premières composantes, capturant le plus de variance, sont conservées dans la régression.\\\n\nCette approche permet de réduire la multicolinéarité et d’éviter le sur-ajustement en limitant la complexité du modèle.\\\n\nCependant, la **PCR** ne prend pas en compte la relation entre les variables explicatives et la variable réponse lors de la sélection des composantes.\n\n## PLSR\n\nContrairement à la **PCR**, la **régression des Moindres Carrés Partiels** (**PLSR**) cherche à maximiser la covariance entre les variables explicatives et la variable réponse.\\\nElle construit des composantes latentes qui capturent non seulement la variance des variables explicatives mais aussi leur corrélation avec la variable à prédire.\\\n\nCette méthode est souvent plus efficace que la **PCR** pour les problèmes de prédiction, car elle optimise directement la relation entre les prédicteurs et la réponse.\n:::\n\nEn résumé, la **PCR** est une approche basée sur la variance des prédicteurs, tandis que la **PLSR** optimise la relation entre les prédicteurs et la réponse.\\\nLe choix entre ces deux méthodes dépend du contexte : la **PCR** est utile pour la réduction de dimensionnalité, tandis que la **PLSR** est souvent plus performante pour la prédiction\n\n# Setup\n\n:::: panel-tabset\n## Packages\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Données\nlibrary(ISLR)         # Hitters data \nlibrary(dplyr)        # manipulation des données\n\n# Infrence\nlibrary(pls) ## PCR et PLSR\n\n\n# Plots\n## ggplot\nlibrary(ggplot2)\nlibrary(gridExtra)\n```\n:::\n\n\n\n## Fonctions\n\n::: panel-tabset\n### Plot de validation\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_validationplot <- function(mod, data) {\n  msep.cv <- MSEP(mod, estimate = c(\"CV\", \"adjCV\"))\n  rmsep.cv <- RMSEP(mod, estimate = c(\"CV\", \"adjCV\"))\n  \n  x_msep <- c(msep.cv$val[1, , ], msep.cv$val[2, , ])\n  x_rmsep <- c(rmsep.cv$val[1, , ], rmsep.cv$val[2, , ])\n  y <- c(rep(\"CV\", length(msep.cv$val[2, , ])), rep(\"adjCV\", length(msep.cv$val[2, , ])))\n  \n  z <- c(0:(ncol(data) - 1), 0:(ncol(data) - 1))\n  dt <- data.frame(x_msep, x_rmsep, y, z)\n  colnames(dt) <- c(\"MSEP\", \"RMSEP\", \"sample\", \"comps\")\n  \n  ## MSEP\n  p.msep <- ggplot(dt, aes(x = comps, y = MSEP, col = sample)) +\n    geom_line() +\n    theme_bw() +\n    labs(\n      title = \"Évolution du MSEP en fonction du nombre de composantes\",\n      x = \"Nombre de composantes\",\n      y = \"RMSEP\",\n      color = \"Échantillon\"\n    ) +\n    theme(\n      plot.title = element_text(size = 16, face = \"bold\"),\n      axis.title = element_text(size = 14, face = \"bold\"),\n      axis.text = element_text(size = 12),\n      legend.title = element_text(size = 14, face = \"bold\"),\n      legend.text = element_text(size = 12)\n    )\n  \n  ## RMSEP\n  p.rmsep <- ggplot(dt, aes(x = comps, y = RMSEP, col = sample)) +\n    geom_line() +\n    theme_bw() +\n    labs(\n      title = \"Évolution du RMSEP en fonction du nombre de composantes\",\n      x = \"Nombre de composantes\",\n      y = \"RMSEP\",\n      color = \"Échantillon\"\n    ) +\n    theme(\n      plot.title = element_text(size = 16, face = \"bold\"),\n      axis.title = element_text(size = 14, face = \"bold\"),\n      axis.text = element_text(size = 12),\n      legend.title = element_text(size = 14, face = \"bold\"),\n      legend.text = element_text(size = 12)\n    )\n  \n  ## Explain variance\n  explain_variance <- explvar(mod)\n  \n  # Créer un data frame\n  dt_var <- data.frame(comps = seq_along(explain_variance),\n                       variance = explain_variance * 100)\n                       \n  # Tracer le graphique\n  p.variance <- ggplot(dt_var, aes(x = comps, y = variance)) +\n                         geom_line(color = \"blue\") +\n                         geom_point(color = \"red\") +\n                         theme_bw() +\n                         labs(title = \"Évolution de la Variance Expliquée en Fonction du Nombre de Composantes\", x = \"Nombre de Composantes\", y = \"Variance Expliquée (%)\") +\n                         theme(\n                           plot.title = element_text(size = 16, face = \"bold\"),\n                           axis.title = element_text(size = 14, face = \"bold\"),\n                           axis.text = element_text(size = 12)\n                         )\n                       \n                       \n  return(list(MSEP = p.msep, RMSEP = p.rmsep, Exp_Var = p.variance))\n}\n```\n:::\n\n\n:::\n\n## Seed\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(140400)\n```\n:::\n\n\n::::\n\n# Données\n\nOn étudie à nouveau le jeu de données [**Hitters**](https://rdrr.io/cran/ISLR/man/Hitters.html) disponible dans la libraire *`{ISLR}`* de *`R`*. Il s'agit d'un jeu de données de la *Major League Baseball* provenant des saisons de 1986 et 1987.\n\nLe jeu de données possède 322 lignes/individus pour les différents joueurs et 20 variables.\\\nParmi les variables, on trouve les informations suivantes :\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-hover table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">AtBat</span> </td>\n   <td style=\"text-align:left;\"> Number of times at bat in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Hits</span> </td>\n   <td style=\"text-align:left;\"> Number of hits in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">HmRun</span> </td>\n   <td style=\"text-align:left;\"> Number of home runs in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Runs</span> </td>\n   <td style=\"text-align:left;\"> Number of runs in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">RBI</span> </td>\n   <td style=\"text-align:left;\"> Number of runs batted in in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Walks</span> </td>\n   <td style=\"text-align:left;\"> Number of walks in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Years</span> </td>\n   <td style=\"text-align:left;\"> Number of years in the major leagues </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">CAtBat</span> </td>\n   <td style=\"text-align:left;\"> Number of times at bat during his career </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">CHits</span> </td>\n   <td style=\"text-align:left;\"> Number of hits during his career </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">CHmRun</span> </td>\n   <td style=\"text-align:left;\"> Number of home runs during his career </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">CRuns</span> </td>\n   <td style=\"text-align:left;\"> Number of runs during his career </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">CRBI</span> </td>\n   <td style=\"text-align:left;\"> Number of runs batted in during his career </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">CWalks</span> </td>\n   <td style=\"text-align:left;\"> Number of walks during his career </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">League</span> </td>\n   <td style=\"text-align:left;\"> A factor with levels A and N indicating player's league at the end of 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Division</span> </td>\n   <td style=\"text-align:left;\"> A factor with levels E and W indicating player's division at the end of 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">PutOuts</span> </td>\n   <td style=\"text-align:left;\"> Number of put outs in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Assists</span> </td>\n   <td style=\"text-align:left;\"> Number of assists in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Errors</span> </td>\n   <td style=\"text-align:left;\"> Number of errors in 1986 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">Salary</span> </td>\n   <td style=\"text-align:left;\"> 1987 annual salary on opening day in thousands of dollars </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    \">NewLeague</span> </td>\n   <td style=\"text-align:left;\"> A factor with levels A and N indicating player's league at the beginning of 1987 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nComme pour l'[Exercice 1](../posts/Exercice_01.qmd), on va commencer par se débarasser des variables manquantes.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHitters_Without_NA <- Hitters %>% na.omit()\n```\n:::\n\n\n\nComme cela fait maintenant plusieurs fois que l'on fait affaire à ce jeu de données, on se passera des analyses descritpives faites en [Exercice 1](../posts/Exercice_01.qmd).\n\nAinsi, on va pouvoir tout de suite commencer par faire le découpage de notre jeu de données en échantillon *train* et *test*. Le jeu de données *train* contiendra 3/4 des individus sans valeurs manquantes de Hitters, tirés aléatoirement. Le reste du jeu de données composera l’échantillon *test*.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npercent_to_draw <- 0.75\nindex_train <- sample(nrow(Hitters_Without_NA), size = floor(percent_to_draw * nrow(Hitters_Without_NA)))\n\nHitters_train <- Hitters_Without_NA[index_train, ]\n\nHitters_test <- Hitters_Without_NA[-index_train, ]\n```\n:::\n\n\n\n# Analyse Inférentielle\n\nOn va maintenant effectuer une régression **PCR** et une régression **PLSR** sur l’échantillon *train* en sélectionnant le nombre de composantes par une validation croisée *K-fold* où $K = 10$.\n\n::: panel-tabset\n## PCR\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_pcr <- pcr(\n  Salary ~ .,\n  scale = TRUE,\n  data = Hitters_train,\n  validation = \"CV\",\n  segments = 10\n)\nmod_pcr %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nData: \tX dimension: 197 19 \n\tY dimension: 197 1\nFit method: svdpc\nNumber of components considered: 19\n\nVALIDATION: RMSEP\nCross-validated using 10 random segments.\n       (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps\nCV           451.6    359.2    360.4    362.1    358.4    355.4    361.6\nadjCV        451.6    358.6    359.6    361.3    357.6    354.6    360.3\n       7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps\nCV       362.3    367.7    373.1     374.9     376.3     378.2     378.9\nadjCV    360.8    365.8    370.9     372.2     373.7     375.4     376.0\n       14 comps  15 comps  16 comps  17 comps  18 comps  19 comps\nCV        372.9     375.5       352     350.3     349.2     349.8\nadjCV     369.6     372.2       349     347.1     345.9     346.4\n\nTRAINING: % variance explained\n        1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps  8 comps\nX         38.57    60.46     71.0    79.17    84.43    88.90    92.26     95.1\nSalary    39.51    40.48     40.6    42.04    43.04    44.32    45.36     45.8\n        9 comps  10 comps  11 comps  12 comps  13 comps  14 comps  15 comps\nX         96.48     97.43     98.12     98.70     99.18      99.5     99.75\nSalary    45.81     47.70     47.71     48.14     48.26      51.2     51.55\n        16 comps  17 comps  18 comps  19 comps\nX          99.91     99.97     99.99    100.00\nSalary     57.09     58.10     58.89     59.19\n```\n\n\n:::\n:::\n\n\n\n## PLSR\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_pls <- plsr(\n  Salary ~ .,\n  scale = TRUE,\n  data = Hitters_train,\n  validation = \"CV\",\n  segments = 10\n)\nmod_pls %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nData: \tX dimension: 197 19 \n\tY dimension: 197 1\nFit method: kernelpls\nNumber of components considered: 19\n\nVALIDATION: RMSEP\nCross-validated using 10 random segments.\n       (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps\nCV           451.6    353.8    354.0    355.4    354.6    358.6    354.5\nadjCV        451.6    353.3    353.1    354.5    353.0    355.7    351.3\n       7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps\nCV       346.0    338.3    336.1     337.5     335.9     332.6     332.7\nadjCV    343.4    336.0    333.7     335.2     333.3     330.3     330.4\n       14 comps  15 comps  16 comps  17 comps  18 comps  19 comps\nCV        329.2     330.3     331.1     329.8     329.1     329.4\nadjCV     327.1     328.1     328.7     327.6     326.9     327.2\n\nTRAINING: % variance explained\n        1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps  8 comps\nX         38.35    51.49    65.93     72.1    76.66    83.61    87.75    89.94\nSalary    41.91    45.71    47.66     49.8    52.71    54.18    55.37    56.92\n        9 comps  10 comps  11 comps  12 comps  13 comps  14 comps  15 comps\nX         93.10     95.65     96.66     97.49     98.39     98.58     99.05\nSalary    57.52     57.78     58.24     58.40     58.52     58.81     58.88\n        16 comps  17 comps  18 comps  19 comps\nX          99.41     99.74     99.99    100.00\nSalary     58.97     59.05     59.09     59.19\n```\n\n\n:::\n:::\n\n\n:::\n\nOn peut maintenant visualiser l'évolution du MSEP et RMSEP en fonction du nombre de composantes gardées.\n\n::: callout-note\nPour des raisons esthétiques, on à ici construit un graphique à partir de `ggplot2`mais on aurait pu se contenter d'utiliser la fonction `validationplot` de la library `pls`.\n:::\n\n::: panel-tabset\n## PCR\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid.arrange(my_validationplot(mod_pcr, Hitters_train)$RMSEP,\n             my_validationplot(mod_pcr, Hitters_train)$Exp_Var,\n             ncol=2)\n```\n\n::: {.cell-output-display}\n![](Exercice_06_files/figure-html/unnamed-chunk-8-1.png){width=1728}\n:::\n:::\n\n\n\n## PLS\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid.arrange(my_validationplot(mod_pls, Hitters_train)$RMSEP,\n             my_validationplot(mod_pls, Hitters_train)$Exp_Var,\n             ncol=2)\n```\n\n::: {.cell-output-display}\n![](Exercice_06_files/figure-html/unnamed-chunk-9-1.png){width=1728}\n:::\n:::\n\n\n:::\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nPour la **PCR** on peut voir courbe proche entre *CV* et *adjCV* avec une première valeur minimum qui semble se trouver à partir de 5 composantes.\\\nEnsuite la courbe remonte à nouveau pour redescendre progressivement. Et concernant le pourcentage de variance expliquée, on voit un coude au niveau de 5 composantes.\n\nTandus que pour la **PLSR** on voit plutôt que c'est à partir de 5 composantes que la décroissance commence. Et pour le pourcentage de variance expliquée, on voit un coude au niveau de 5 composantes.\n:::\n\nEt on peut alors récupérer le nombre de composantes à garder qui minimsent le MSEP et RMSEP.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nncomp.rmsep_pcr <- which.min(RMSEP(mod_pcr, estimate = c(\"CV\"))$val[\"CV\",,])-1\nncomp.rmsep_pls <- which.min(RMSEP(mod_pls, estimate = c(\"CV\"))$val[\"CV\",,])-1\n```\n:::\n\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nOn a que le nombre de composante à retenir est de 18 pour la PCR et 18 pour la PLSR.\n:::\n\n# Prédiction\n\nOn va calculer le RMSEP calculé à partir de la prédiction pour l'échantillon test.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhat_Hitters_test_mod_pcr <- predict(mod_pcr,\n                                    Hitters_test,\n                                    ncomp = (which.min(RMSEP(mod_pcr, estimate = c(\"CV\"))$val[\"CV\", , ]) - 1))\nrmsep_mod_pcr_pred <- sqrt(mean((hat_Hitters_test_mod_pcr - Hitters_test$Salary) ** 2))\n\nhat_df_test_salary.pls <- predict(mod_pls,\n                                  Hitters_test,\n                                  ncomp = (which.min(RMSEP(mod_pls, estimate = c(\"CV\"))$val[\"CV\", , ]) - 1))\nrmsep_mod_pls_pred <- sqrt(mean((hat_df_test_salary.pls - Hitters_test$Salary) ** 2))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrmsep_pred_df <- data.frame(\"prediction PCR\" = rmsep_mod_pcr_pred, \"prediction PLS\" = rmsep_mod_pls_pred) \nrownames(rmsep_pred_df) <- \"RMSEP\"\nrmsep_pred_df \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      prediction.PCR prediction.PLS\nRMSEP       369.5149       373.6123\n```\n\n\n:::\n:::\n\n\n\nLe choix final du modèle peut ainsi se reposer sur celui qui minimise la *RMSEP* pour la prediction de notre échantillon *test*.\n\n# Conclusion\n\nEn conclusion, on a ici 2 méthodes complémentaires permettant de construire des modèles linéaires pour des données de grandes dimension.\\\n\nCe sont des méthodes intuitives et robustes souvent utilisés par les statisticiens.\n\n# Session info\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info(pkgs = \"attached\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       Ubuntu 24.04.1 LTS\n system   x86_64, linux-gnu\n ui       X11\n language (EN)\n collate  fr_FR.UTF-8\n ctype    fr_FR.UTF-8\n tz       Europe/Paris\n date     2025-02-25\n pandoc   3.2 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/x86_64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package    * version date (UTC) lib source\n dplyr      * 1.1.4   2023-11-17 [1] CRAN (R 4.4.2)\n forcats    * 1.0.0   2023-01-29 [1] CRAN (R 4.4.2)\n ggplot2    * 3.5.1   2024-04-23 [1] CRAN (R 4.4.2)\n gridExtra  * 2.3     2017-09-09 [1] CRAN (R 4.4.2)\n ISLR       * 1.4     2021-09-15 [1] CRAN (R 4.4.2)\n kableExtra * 1.4.0   2024-01-24 [1] CRAN (R 4.4.2)\n lubridate  * 1.9.4   2024-12-08 [1] CRAN (R 4.4.2)\n pls        * 2.8-5   2024-09-15 [1] CRAN (R 4.4.2)\n purrr      * 1.0.2   2023-08-10 [2] CRAN (R 4.3.3)\n readr      * 2.1.5   2024-01-10 [1] CRAN (R 4.4.2)\n stringr    * 1.5.1   2023-11-14 [2] CRAN (R 4.3.3)\n tibble     * 3.2.1   2023-03-20 [2] CRAN (R 4.3.3)\n tidyr      * 1.3.1   2024-01-24 [1] CRAN (R 4.4.2)\n tidyverse  * 2.0.0   2023-02-22 [1] CRAN (R 4.4.2)\n\n [1] /home/clement/R/x86_64-pc-linux-gnu-library/4.4\n [2] /usr/local/lib/R/site-library\n [3] /usr/lib/R/site-library\n [4] /usr/lib/R/library\n\n──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n",
    "supporting": [
      "Exercice_06_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}