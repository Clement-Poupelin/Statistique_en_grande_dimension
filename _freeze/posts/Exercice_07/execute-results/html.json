{
  "hash": "35b98291497a18ba8a3f22f96b36a5c9",
  "result": {
    "markdown": "---\ntitle: \"Exercice 07\"\nauthor: \"Clément Poupelin\"\ndate: \"2025-02-23\"\nformat: \n  html:\n    embed-resources: false\n    toc: true\n    code-fold: true\n    code-summary: \"Show the code\"\n    code-tools: true\n    toc-location: right\n    page-layout: article\n    code-overflow: wrap\ntoc: true\nnumber-sections: false\neditor: visual\ncategories: [\"regression Ridge\", \"regression Lasso\", \"Validation croisée\"]\nimage: \"/img/baseball.png\"\ndescription: \"Ici, on continu sur des données de baseball en mettant en pratique les techniques de PCR et PLS avec de la validation croisée\"\n---\n\n\n\n# Intervenant.e.s\n\n### Rédaction\n\n-   **Clément Poupelin**, [clementjc.poupelin\\@gmail.com](mailto:clementjc.poupelin@gmail.com){.email}\\\n\n### Relecture\n\n-   \n\n\n\n# Setup\n\n:::: panel-tabset\n## Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Données\nlibrary(ISLR)         # Hitters data \nlibrary(dplyr)        # manipulation des données\n\n# Infrence\nlibrary(pls) ## PCR et PLSR\nlibrary(glmnet) ## regression pénalisée\n\n# Plots\n## ggplot\nlibrary(ggplot2)\nlibrary(gridExtra)\n```\n:::\n\n\n## Fonctions\n\n::: panel-tabset\n\n:::\n\n## Seed\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(140400)\n```\n:::\n\n\n::::\n\n\n# Données\n\nCette exercice est la suite direct de l'[Exercice 6](../posts/Exercice_06.qmd) où l'on a pu utiliser les méthodes de regressions avec reduction de dimension **PCR** et **PLSR**.\n\nOn va donc reprdre les mêmes données avec le même découpage en *train* et *test*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHitters_Without_NA <- Hitters %>% na.omit()\npercent_to_draw <- 0.75\nindex_train <- sample(nrow(Hitters_Without_NA), size = floor(percent_to_draw * nrow(Hitters_Without_NA)))\n\nHitters_train <- Hitters_Without_NA[index_train, ]\n\nHitters_test <- Hitters_Without_NA[-index_train, ]\n```\n:::\n\n\n\n\n\nNOtre objectif ici sera donc de compléter l'analyse de l'exercice 6 (lien)en utilisant cette fois ci les méthodes de regression pénalisée Ridge et Lasso (méthodes détaillées dans le 6 bonus lien).\n\n# Analyse inférentielle\n\nContrairement à la plupart des autres package *`R`* qui permettent de faire de l’apprentissage, le package *`glmnet`* n’autorise pas l’utilisation de formules.  Il faut donc spécifier explicitement la matrice $X$ et le vecteur $y$.\\\n\nOn peut obtenir la matrice $X$ et notamment le codage des variables qualitatives avec la fonction *`model.matrix`*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX_train <- model.matrix(Salary ~ ., data = Hitters_train)[, -1]\nY_train <- Hitters_train$Salary\n\nX_test <- model.matrix(Salary ~ ., data = Hitters_test)[, -1]\nY_test <- Hitters_test$Salary\n```\n:::\n\n\nEt ce n'est qu'après que l'on peut mettre en place la modélisation.\n\n::::::::: panel-tabset\n## Ridge\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod.R <- glmnet(X_train, Y_train, alpha = 0) \n```\n:::\n\n\n\nPuis on peut visualiser les chemins de régularisation des estimateurs **Ridge**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mod.R, xvar = \"lambda\", label = TRUE)\n```\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nIci on voit l'évolution de nos coefficients $\\beta$ en fonction des diffrentes valeurs de $\\lambda$. Ainsi, sur la gauche on se retrouve dans la situation où il n'y a pas de pénalisation et donc nos coefficients sont les $\\beta$ de l'estimation par moindres carrés. Et donc plus $\\lambda$ va augmenter, plus on se retrouvera dans une situation où les coefficients vont tendrent vers 0.\n:::\n\n## Lasso\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod.L <- glmnet(X_train, Y_train, alpha = 1) \n```\n:::\n\nPuis on peut visualiser les chemins de régularisation des estimateurs **Lasso**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mod.L, xvar = \"lambda\", label = TRUE)\n```\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nIci on voit l'évolution de nos coefficients $\\beta$ en fonction des diffrentes valeurs de $\\lambda$. Ainsi, sur la gauche on se retrouve dans la situation où il n'y a pas de pénalisation et donc nos coefficients sont les $\\beta$ de l'estimation par moindres carrés. Et donc plus $\\lambda$ va augmenter, plus on se retrouvera dans une situation où les coefficients vont tendrent vers 0.\n:::\n:::::::::\n\n# Selection des paramètres de régularisation\n\nMaintenant que les modèles sont estimés avec plusieurs valeurs de $\\lambda$ possibles, il se pose la question du choix du bon paramètre.\\\nPour cela, on utilise la fonction *`cv.glmnet`* qui, comme son nom le laisse suggérer, permet d'effectuer une validation croisée pour notre modèle avec par défaut *`nfolds=10`* (le nombre de pli pour le découpage de sous ensembles). Puis on peut faire un *`plot`* de l’objet.\n\n::: panel-tabset\n## Ridge\n\n\n::: {.cell}\n\n```{.r .cell-code}\nridgeCV <- cv.glmnet(X_train, Y_train, alpha = 0)\nplot(ridgeCV)\n```\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nOn visualise ici les erreurs quadratiques calculées par validation croisée 10 blocs en fonction de $\\lambda$ (échelle logarithmique). Deux traits verticaux sont représentés :\n\n-   celui de gauche correspond à la valeur de $\\lambda$ qui minimise l’erreur quadratique\n\n-   celui de droite correspond à la plus grande valeur de $\\lambda$ telle que l’erreur ne dépasse pas l’erreur minimale + 1 écart-type estimé de cette erreur\n\nD’un point de vu pratique, cela signifie que l’utilisateur peut choisir n’importe quelle valeur de lambda entre les deux traits verticaux.\\\nA savoir que si l'on veut diminuer la complexité du modèle on choisira la valeur de droite.\n\nOn peut obtenir ces deux valeurs assez facilement.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\" Valeur minimale : \", ridgeCV$lambda.min, \"\\n\", \"Valeur maximale : \", ridgeCV$lambda.1se)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Valeur minimale :  25.74237 \n Valeur maximale :  2457.234\n```\n:::\n:::\n\n\n## Lasso\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlassoCV <- cv.glmnet(X_train, Y_train, alpha = 1)\nplot(lassoCV)\n```\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nOn visualise ici les erreurs quadratiques calculées par validation croisée 10 blocs en fonction de $\\lambda$ (échelle logarithmique). Deux traits verticaux sont représentés :\n\n-   celui de gauche correspond à la valeur de $\\lambda$ qui minimise l’erreur quadratique\n\n-   celui de droite correspond à la plus grande valeur de $\\lambda$ telle que l’erreur ne dépasse pas l’erreur minimale + 1 écart-type estimé de cette erreur\n\nD’un point de vu pratique, cela signifie que l’utilisateur peut choisir n’importe quelle valeur de lambda entre les deux traits verticaux.\\\nA savoir que si l'on veut diminuer la complexité du modèle on choisira la valeur de droite.\n\nOn peut obtenir ces deux valeurs assez facilement.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\" Valeur minimale : \", lassoCV$lambda.min, \"\\n\", \"Valeur maximale : \", lassoCV$lambda.1se)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Valeur minimale :  0.5546026 \n Valeur maximale :  76.80616\n```\n:::\n:::\n\n:::\n\n\n# Prédiction\n\n\n# Prédiction\n\nOn souhaite maintenant prédiction pour le jeu de données *test*.\n\nUne première approche pourrait consister à réajuster le modèle sur toutes les données pour la valeur de $lambda$ sélectionnée.\\\nCette étape est en réalité déjà effectuée par la fonction *`cv.glmnet`*. Il suffit par conséquent d’appliquer la fonction predict à l’objet obtenu avec *`cv.glmnet`* en spécifiant la valeur de $lambda$ souhaitée.\n\n::: panel-tabset\n## Ridge\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred.ridge_min <- predict(ridgeCV, newx = X_test, s = \"lambda.min\")\nerr_ridge <- sqrt(mean((pred.ridge_min - Y_test)^2, na.rm=T))\n```\n:::\n\n\n\n## Lasso\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred.lasso_min <- predict(lassoCV, newx = X_test, s = \"lambda.min\") \nerr_lasso <- sqrt(mean((pred.lasso_min - Y_test)^2, na.rm=T))\n```\n:::\n\n\n:::\n\nAinsi on peut obtenir l'erreur de prédiction via le RMSEP pour les 2 modèles et les comparer avec les valeurs obtenues à l'exercice 6 (lien).\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrmsep_pred_df <- data.frame(\"prediction Ridge\" = err_ridge, \"prediction Lasso\" = err_lasso) \nrownames(rmsep_pred_df) <- \"RMSEP\"\nrmsep_pred_df \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      prediction.Ridge prediction.Lasso\nRMSEP         343.7543         373.2681\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nerr_vect = c(err_lasso, err_ridge, rmsep_mod.step, min(RMSEP(pls.fit_final,'CV')$val[,,]), min(RMSEP(pcr.fit_final,'CV')$val[,,]))\nplot(err_vect, type = \"h\", main = \"erreur pour les différentes méthodes\")\npoints(err_vect, col=1:6)\nlegend(\"topright\", \n       legend=c(\"Lasso_lars\", \"Lasso_glmnet\", \"Ridge\", \"mod.step\", \"pls\", \"pcr\"),\n       pch = 1,\n       col = 1:6)\n```\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\n\n# Conclusion\n\n\n\n\n\n\n\n\n\n\n\n# Session info\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info(pkgs = \"attached\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23 ucrt)\n os       Windows 10 x64 (build 22631)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  French_France.utf8\n ctype    French_France.utf8\n tz       Europe/Paris\n date     2025-02-23\n pandoc   3.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package   * version date (UTC) lib source\n dplyr     * 1.1.4   2023-11-17 [1] CRAN (R 4.2.3)\n ggplot2   * 3.5.1   2024-04-23 [1] CRAN (R 4.2.3)\n glmnet    * 4.1-8   2023-08-22 [1] CRAN (R 4.2.3)\n gridExtra * 2.3     2017-09-09 [1] CRAN (R 4.2.1)\n ISLR      * 1.4     2021-09-15 [1] CRAN (R 4.2.3)\n Matrix    * 1.6-4   2023-11-30 [1] CRAN (R 4.2.3)\n pls       * 2.8-3   2023-11-17 [1] CRAN (R 4.2.3)\n\n [1] C:/Users/cleme/AppData/Local/R/win-library/4.2\n [2] C:/Program Files/R/R-4.2.1/library\n\n──────────────────────────────────────────────────────────────────────────────\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ISLR)\n\n# Découpage des données ####\ndf = na.omit(Hitters)\ndim(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 263  20\n```\n:::\n\n```{.r .cell-code}\nset.seed(234)\n\npourcentage_a_tirer = 0.75\nindices_train = sample(nrow(df), size = floor(pourcentage_a_tirer * nrow(df)))\n\ndf_train = df[indices_train, ]\ndim(df_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 197  20\n```\n:::\n\n```{.r .cell-code}\ndf_test = df[-indices_train, ] \ndim(df_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 66 20\n```\n:::\n\n```{.r .cell-code}\n####\n# Création des modèles ####\nX.train = model.matrix(Salary~.,data=df_train)[,-1]\nY.train = df_train$Salary\n\nmod.R <- glmnet(X.train, Y.train, alpha=0) ## Ridge \nmod.R$beta[,1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        AtBat          Hits         HmRun          Runs           RBI \n 1.656025e-36  5.820679e-36  2.170157e-35  9.728331e-36  1.033190e-35 \n        Walks         Years        CAtBat         CHits        CHmRun \n 1.064338e-35  4.429311e-35  1.235428e-37  4.666557e-37  3.061051e-36 \n        CRuns          CRBI        CWalks       LeagueN     DivisionW \n 9.529597e-37  8.740946e-37  9.575279e-37 -4.738583e-35 -1.791793e-34 \n      PutOuts       Assists        Errors    NewLeagueN \n 5.817502e-37  5.691328e-38  2.355126e-36 -4.492469e-35 \n```\n:::\n\n```{.r .cell-code}\nmod.L <- glmnet(X.train, Y.train, alpha=1) ## Lasso\nmod.L$beta[,1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     AtBat       Hits      HmRun       Runs        RBI      Walks      Years \n         0          0          0          0          0          0          0 \n    CAtBat      CHits     CHmRun      CRuns       CRBI     CWalks    LeagueN \n         0          0          0          0          0          0          0 \n DivisionW    PutOuts    Assists     Errors NewLeagueN \n         0          0          0          0          0 \n```\n:::\n\n```{.r .cell-code}\npar(mfrow=c(2,2))\nplot(mod.R, label=TRUE, main = \"Ridge\")  \nplot(mod.R, xvar=\"lambda\",label=TRUE, main = \"Ridge\")\n\nplot(mod.L, label=TRUE, main = \"Lasso\")  \nplot(mod.L, xvar=\"lambda\",label=TRUE, main = \"Lasso\")\n```\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n```{.r .cell-code}\npar(mfrow=c(1,1))\n\n\n####\n# Sélectionn des paramètres de régularisation ####\n\nridgeCV <- cv.glmnet(X.train, Y.train, alpha=0)\nlassoCV <- cv.glmnet(X.train, Y.train, alpha=1)\n\npar(mfrow=c(1,2))\nplot(ridgeCV, main = \"Ridge\")\n\nplot(lassoCV, main = \"Lasso\")\n```\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-2.png){width=672}\n:::\n\n```{.r .cell-code}\npar(mfrow=c(1,1))\n\nridgeCV$lambda.min\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 29.75282\n```\n:::\n\n```{.r .cell-code}\nridgeCV$lambda.1se\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1783.635\n```\n:::\n\n```{.r .cell-code}\nlassoCV$lambda.min\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 12.58319\n```\n:::\n\n```{.r .cell-code}\nlassoCV$lambda.1se\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 88.77192\n```\n:::\n\n```{.r .cell-code}\n####\n# Prédiction de la variable cible pour de nouveaux individus ####\nX.test = model.matrix(Salary~.,data=df_test)[,-1]\nY.test = df_test$Salary\n\npred.ridge_min = predict(ridgeCV, newx = X.test, s=\"lambda.min\")\n# predict(ridgeCV, newx = X.test, s=\"lambda.1se\")\nerr_ridge = sqrt(mean((pred.ridge_min - Y.test)^2, na.rm=T))\nerr_ridge\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 396.5798\n```\n:::\n\n```{.r .cell-code}\n# 345.5415\n\npred.lasso_min = predict(lassoCV, newx = X.test, s=\"lambda.min\")\n# predict(lassoCV, newx = X.test, s=\"lambda.1se\")\nerr_lasso = sqrt(mean((pred.lasso_min - Y.test)^2, na.rm=T))\nerr_lasso\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 402.3248\n```\n:::\n\n```{.r .cell-code}\n# 349.1404\n\n####\n# Lasso avec lars ####\nlibrary(lars)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoaded lars 1.3\n```\n:::\n\n```{.r .cell-code}\nlars.cv = cv.lars(X.train, Y.train)\n```\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-3.png){width=672}\n:::\n\n```{.r .cell-code}\nchoix = lars.cv$index[which.min(lars.cv$cv)]\ntemp = lars(X.train, Y.train)\nplot(temp) # chemin lasso\n```\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-4.png){width=672}\n:::\n\n```{.r .cell-code}\ncoef(temp, s=choix, mode='fraction') \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       AtBat         Hits        HmRun         Runs          RBI        Walks \n  0.00000000   2.59390330   0.00000000   0.00000000   0.78377076   1.63049059 \n       Years       CAtBat        CHits       CHmRun        CRuns         CRBI \n  0.00000000   0.00000000   0.00000000   0.00000000   0.54921581   0.11932395 \n      CWalks      LeagueN    DivisionW      PutOuts      Assists       Errors \n  0.00000000   0.00000000 -73.04517633   0.19156413  -0.04324735   0.00000000 \n  NewLeagueN \n  0.00000000 \n```\n:::\n\n```{.r .cell-code}\n#le resultat est diff qu'avec glmnet parce que le choix de lambda est diff\n#attention: les lambda ne sont pas normalise pareil dans glmnet et dans lars\n#cela n'a pas de sens d'utiliser le lambda choisi par glmnet dans lars et inversement\n#cf le poly section 4.3.3 pour une explication\n\n\nlars.pred = predict(temp, X.train, s=choix, mode='fraction')$fit\nerr_lars = sqrt(mean((lars.pred - Y.test)^2, na.rm=T))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in lars.pred - Y.test: la taille d'un objet plus long n'est pas\nmultiple de la taille d'un objet plus court\n```\n:::\n\n```{.r .cell-code}\nerr_lars\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 446.5635\n```\n:::\n\n```{.r .cell-code}\n# 499.6627\n\n\n\n####\n# Reprenons les modèles sélectionnés à l'Exo 6 ####\nlibrary(pls)\n\n## PCR\nres.pcr = NULL\nfor(i in 1:100){\n  # modele PCR\n  pcr.fit = pcr(Salary~., data = df, scale = TRUE, subset = indices_train, validation = \"CV\", segments = 10)\n  # RMSEP\n  RMSEP.cv = RMSEP(pcr.fit,'CV')$val[,,]\n  \n  # On stocke les resultats\n  res.pcr = cbind(res.pcr, RMSEP.cv)\n}\npcr.mean.cv = apply(res.pcr, MARGIN = 1, FUN = mean)\n\npcr.fit_final = pcr(Salary~., data = df, ncomp = which.min(pcr.mean.cv)-1, scale = TRUE, subset = indices_train, validation = \"CV\", segments = 10 )\n\nmin(RMSEP(pcr.fit_final,'CV')$val[,,])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 333.268\n```\n:::\n\n```{.r .cell-code}\n#  345.3995\nwhich.min(RMSEP(pcr.fit_final,'CV')$val[,,])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n17 comps \n      18 \n```\n:::\n\n```{.r .cell-code}\n# 16 comps\n\n# PLS\nres.pls = NULL\nfor(i in 1:100){\n  pls.fit = plsr(Salary~., data = df, scale = TRUE, subset = indices_train, validation = \"CV\", segments = 10)\n  # RMSEP\n  RMSEP.cv = RMSEP(pls.fit,'CV')$val[,,]\n  # On stocke les resultats\n  res.pls = cbind(res.pls, RMSEP.cv)\n}\n\npls.mean.cv = apply(res.pls, MARGIN = 1, FUN = mean) \npls.fit_final = plsr(Salary~., data = df, ncomp = which.min(pls.mean.cv)-1, scale = TRUE, subset = indices_train, validation = \"CV\", segments = 10 )\n\nmin(RMSEP(pls.fit_final,'CV')$val[,,])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 316.0469\n```\n:::\n\n```{.r .cell-code}\n# 346.1336\nwhich.min(RMSEP(pls.fit_final,'CV')$val[,,])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n11 comps \n      12 \n```\n:::\n\n```{.r .cell-code}\n# 8 comps\n\n\n# faire une selec forwise-stepwise avec critere BIC sur train puis rmsep sur test\nmod0=lm(Salary~0, data=df_train)\nmod_full=lm(Salary~., data=df_train)\nmod.step = step(mod0, scope = formula(mod_full), trace = FALSE, direction = \"both\", k = log(nrow(Hitters_train)))\n\nhat_df_test_mod.step = predict(mod.step, df_test)\nrmsep_mod.step = sqrt(mean((hat_df_test_mod.step - df_test$Salary)**2))\nrmsep_mod.step\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 408.6114\n```\n:::\n\n```{.r .cell-code}\n# 370.2405\n\n\n####\n\n\n\n\nerr_vect = c(err_lars, err_lasso, err_ridge, rmsep_mod.step, min(RMSEP(pls.fit_final,'CV')$val[,,]), min(RMSEP(pcr.fit_final,'CV')$val[,,]))\nplot(err_vect, type = \"h\", main = \"erreur pour les différentes méthodes\")\npoints(err_vect, col=1:6)\nlegend(\"topright\", \n       legend=c(\"Lasso_lars\", \"Lasso_glmnet\", \"Ridge\", \"mod.step\", \"pls\", \"pcr\"),\n       pch = 1,\n       col = 1:6)\n```\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-5.png){width=672}\n:::\n\n```{.r .cell-code}\n# Cette operation peut egalement etre repete pour avoir davantage que 10 decoupes.\nK=10\nn = nrow(df)\nseg = cvsegments(n,K) #library(pls)\nerr_reg=NULL; err_pcr=NULL; err_pls=NULL; err_ridge=NULL; err_lasso=NULL; err_lars=NULL\nfor(i in 1:K){\n  cat(i)\n  \n  test=seg[[i]]\n  reg=lm(Salary~., data=df, subset=-test)\n  reg0=lm(Salary~0,data=df, subset=-test)\n  resfwd=step(reg0, scope=formula(reg), direction=\"forward\", k=log(n), trace=0)\n  reg.pred=predict(resfwd, df[test,])\n  err_reg[i]=sqrt(mean((reg.pred - df[test,19])^2, na.rm=T))\n  \n  pcr.fit=pcr(Salary~., data=df,scale=TRUE,subset=-test,validation=\"CV\",segments=10)\n  nbcomp=which.min(RMSEP(pcr.fit,'CV')$val[,,1:10])\n  pcr.pred=predict(pcr.fit,df[test,],ncomp=nbcomp)\n  err_pcr[i]=sqrt(mean((pcr.pred-df[test,19])^2,na.rm=T))\n  \n  pls.fit=plsr(Salary~., data=df,subset=-test,scale=TRUE, validation=\"CV\")\n  nbcomp=which.min(RMSEP(pls.fit,'CV')$val[,,1:10])\n  pls.pred=predict(pls.fit,df[test,],ncomp=nbcomp)\n  err_pls[i]=sqrt(mean((pls.pred-df[test,19])^2,na.rm=T))\n  \n  train.mat=model.matrix(Salary~.,data=df[-test,])\n  train.mat=train.mat[,-1]\n  y=df[-test,19]\n  test.mat=model.matrix(Salary~.,data=df[test,])\n  test.mat=test.mat[,-1]\n  ytest=df[test,19]\n  \n  \n  ridge.cv=cv.glmnet(train.mat,y,alpha=0,lambda=seq(1,5000))\n  lambdachoisi=ridge.cv$lambda.min\n  ridge.pred=predict(ridge.cv,test.mat,s=lambdachoisi)\n  err_ridge[i]=sqrt(mean((ridge.pred-df[test,19])^2,na.rm=T))\n  \n  \n  lasso.cv=cv.glmnet(train.mat,y,alpha=1)\n  lasso.pred=predict(lasso.cv,test.mat,s=lasso.cv$lambda.min)\n  err_lasso[i]=sqrt(mean((lasso.pred-df[test,19])^2,na.rm=T))\n  \n  lars.cv = cv.lars(train.mat, y)\n  choix = lars.cv$index[which.min(lars.cv$cv)]\n  temp = lars(train.mat, y)\n  lars.pred = predict(temp, train.mat, s=choix, mode='fraction')$fit\n  err_lars[i] = sqrt(mean((lars.pred - df[test,19])^2, na.rm=T))\n  \n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in lars.pred - df[test, 19]: la taille d'un objet plus long n'est pas\nmultiple de la taille d'un objet plus court\n```\n:::\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-6.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in lars.pred - df[test, 19]: la taille d'un objet plus long n'est pas\nmultiple de la taille d'un objet plus court\n```\n:::\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-7.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in lars.pred - df[test, 19]: la taille d'un objet plus long n'est pas\nmultiple de la taille d'un objet plus court\n```\n:::\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-8.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n4\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in lars.pred - df[test, 19]: la taille d'un objet plus long n'est pas\nmultiple de la taille d'un objet plus court\n```\n:::\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-9.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n5\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in lars.pred - df[test, 19]: la taille d'un objet plus long n'est pas\nmultiple de la taille d'un objet plus court\n```\n:::\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-10.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n6\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in lars.pred - df[test, 19]: la taille d'un objet plus long n'est pas\nmultiple de la taille d'un objet plus court\n```\n:::\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-11.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n7\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in lars.pred - df[test, 19]: la taille d'un objet plus long n'est pas\nmultiple de la taille d'un objet plus court\n```\n:::\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-12.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n8\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in lars.pred - df[test, 19]: la taille d'un objet plus long n'est pas\nmultiple de la taille d'un objet plus court\n```\n:::\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-13.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n9\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in lars.pred - df[test, 19]: la taille d'un objet plus long n'est pas\nmultiple de la taille d'un objet plus court\n```\n:::\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-14.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n10\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in lars.pred - df[test, 19]: la taille d'un objet plus long n'est pas\nmultiple de la taille d'un objet plus court\n```\n:::\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-15.png){width=672}\n:::\n\n```{.r .cell-code}\nboxplot(err_reg,err_pcr,err_pls,err_ridge,err_lasso, err_lars,\n        names=c('reg','pcr','pls','ridge','lasso', 'lasso_lars'), \n        col=2:8, \n        main=\"Erreurs des différentes méthodes\")\n```\n\n::: {.cell-output-display}\n![](Exercice_07_files/figure-html/unnamed-chunk-18-16.png){width=672}\n:::\n\n```{.r .cell-code}\n#abline(h = median(err_pcr), col='red')\n\nmean(err_reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 339.1316\n```\n:::\n\n```{.r .cell-code}\nmean(err_pcr)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 327.925\n```\n:::\n\n```{.r .cell-code}\nmean(err_pls)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 343.9135\n```\n:::\n\n```{.r .cell-code}\nmean(err_ridge)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 336.408\n```\n:::\n\n```{.r .cell-code}\nmean(err_lasso) # moyenne pas toujours la plus basse (change en relancant)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 331.4097\n```\n:::\n\n```{.r .cell-code}\nmean(err_lars)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 547.187\n```\n:::\n\n```{.r .cell-code}\n# On ne constate pas de grandes differences.\n# Finalement la reg avec selection forward (ici 6 var retenues) est pas mal.\n# Ce n'est pas illogique :\n#    - le jeu de donnees n'est pas de tres grande dimension\n#    - les methodes de reduction de dimension et contraintes\n#      n'apportent pas grand chose\n```\n:::\n",
    "supporting": [
      "Exercice_07_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}