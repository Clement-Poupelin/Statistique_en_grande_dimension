---
title: "Exercice 02"
author: "Clément Poupelin"
date: today
format: 
  html:
    embed-resources: false
    toc: true
    code-fold: true
    code-summary: "Show the code"
    code-tools: true
    toc-location: right
    page-layout: article
    code-overflow: wrap
toc: true
number-sections: false
editor: visual
categories: ["regression", "selection de variable"]
image: "/img/baseball.png"
description: "Ici, on continu sur des données de baseball à utilser des méthodes de regression avec selection de variable en testant cette fois ci le lien linéaire existant et en mettant en avant le fléau de la dimensionalité"
---

# Intervenant.e.s

### Rédaction

- **Clément Poupelin**, [clementjc.poupelin\@gmail.com](mailto:clementjc.poupelin@gmail.com){.email}\


### Relecture

- 



# Setup

::: panel-tabset
## Packages

```{r, setup, warning=FALSE, message=FALSE}
# Données
library(ISLR)         # Hitters data 
library(dplyr)        # manipulation des données
```

## Fonctions

## Seed

```{r}
set.seed(140400)
```

:::

# Données

On étudie toujours le jeu de données [**Hitters**](https://rdrr.io/cran/ISLR/man/Hitters.html) disponible dans la libraire *`{ISLR}`* de *`R`*. Il s'agit d'un jeu de données de la *Major League Baseball* provenant des saisons de 1986 et 1987.

Le jeu de données possède `r dim(Hitters)[1]` lignes/individus pour les différents joueurs et `r dim(Hitters)[2]` variables.\
Parmi les variables, on trouve les informations suivantes :

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(kableExtra)
identity_keys <- cell_spec(
  x = colnames(Hitters), format = "html", bold = TRUE)
identity_values <- c("Number of times at bat in 1986", "Number of hits in 1986", "Number of home runs in 1986", "Number of runs in 1986", "Number of runs batted in in 1986", "Number of walks in 1986", "Number of years in the major leagues", "Number of times at bat during his career", "Number of hits during his career", "Number of home runs during his career", "Number of runs during his career", "Number of runs batted in during his career", "Number of walks during his career", "A factor with levels A and N indicating player's league at the end of 1986", "A factor with levels E and W indicating player's division at the end of 1986", "Number of put outs in 1986", "Number of assists in 1986", "Number of errors in 1986", "1987 annual salary on opening day in thousands of dollars", "A factor with levels A and N indicating player's league at the beginning of 1987")
tibble(
  keys = identity_keys, 
  values = identity_values, 
) %>% 
  kbl(
    format = "html", 
    booktabs = TRUE, 
    escape = FALSE, 
    col.names = NULL
  ) %>% 
  kable_styling(bootstrap_options = c("hover", "condensed"))
```

Comme pour l'[Exercice 1](../posts/Exercice_01.qmd), on va commencer par se débarasser des variables manquantes.
```{r}
Hitters_Without_NA <- Hitters %>% na.omit()
```

Puis cette fois ci nous allons dans un premier temps nous concentrer sur un sous jeu de données composé des 18 premières lignes sans valeurs manquantes.

```{r}
Hitters_Without_NA_18 <- Hitters_Without_NA[1:18, ]
Hitters_Without_NA_18 %>% dim()
```

::: callout-warning
Attention, on peut remarquer ici que le nombre de variable est supérieur au nombre d'individus. On est donc dans un cas classique de grandes dimension avec $p>n$.
:::

Maintenant, il conviendrait dans ce genre de situation d'effectuer de premières analyses descritptives. Mais celle ci ayant déjà été faite sur le jeu de données complet pendant l'[Exercice 1](../posts/Exercice_01.qmd), on se permettra de ne pas les refaires.

# Analyse inférentielle

## Modèle brut

On désire modéliser le salaire *Salary* en fonction des variables disponibles.

On va donc ajuster un modèle de régression linéaire en utilisant toutes les variables à disposition et analyser la qualité de cet ajustement.

```{r}
mod1 <- lm(formula = Salary ~ .,
           Hitters_Without_NA_18) 
mod1 %>% summary()
```

::: success-header
::: success-icon
::: 
Résultats
:::

::: success
On peut clairement constater que ce modèle brut ne fonctionne pas avec pourtant un $R^2 = 1$. On retrouve donc le problème typique de l'analyse en grande dimension lorsque $p>n$ (fléau de la dimensionalité).
:::


On peut aussi s'amuser à regarder les critères *AIC* et *BIC* de ce modèles qui théoriquement se retrouve à tendre vers l'infini.

```{r}
cat( "AIC = ", AIC(mod1), "et BIC = ", BIC(mod1))
```

### Prediction

On va maintenant tenter de prédire la variable *Salary* pour les autres joueurs.\
Déjà on peut regarder sur les 18 joueurs si la prédiction via le modèle nous donne des bonnes valeur.

```{r, warning=FALSE, message=FALSE}
Salary_hat <- predict(mod1, Hitters_Without_NA_18)
Salary <- Hitters_Without_NA_18$Salary
```

- $\widehat{Salary^{(1:18)}} - Salary^{(1:18)} =$ `r round(mean(Salary_hat - Salary), 2)`

Ce que l'on constate c'est qu'effectivement nous sommes avec un résultat qui pourrait nous faire penser que le modèle est bien ajusté avec une prédiction quasiment égale à la variable à prédire.
 
 
Pourtant si nous regardons la prédiction obtenue par le modèle pour les autres joueurs et que nous effectuons la même soustraction pour comparer la qualité de prediction, nous voyons bien l'inéfficacité du modèle. 

```{r, warning=FALSE, message=FALSE}
Hitters_Without_NA_No18 <- Hitters_Without_NA[19:nrow(Hitters_Without_NA),]
Salary_hat_No18 <- predict(mod1, Hitters_Without_NA_No18)
Salary_No18 <- Hitters_Without_NA_No18$Salary
```

- $\widehat{Salary^{(\neg 1:18)}} - Salary^{(\neg 1:18)} =$ `r round(mean(Salary_hat_No18 - Salary_No18), 2)`

En effet on voit bien au dessus que les valeurs ne sont en moyennes pas proche de 0.


## Modèles parcimonieux

On va maintenant mettre un oeuvre une méthode de sélection automatique classique pour réduire le nombre de variable explicative et tenter d'éviter les problèmes de grande dimension.

Pour cela nous allons donc partir du plus petit modèle (celui avec seulement l'*intercept*) puis faire grandir le nombre de variable. Il va donc s'agir d'une méthode de sélection automatique *forward*. 


```{r}
mod0 <- lm(Salary~1, Hitters_Without_NA_18)
mod_forw <- step(mod0,
                 scope = formula(mod1),
                 trace = FALSE,
                 direction = c("forward"))
mod_forw %>% summary()
```


::: success-header
::: success-icon
::: 
Résultats
:::

::: success
Nous obtenons maintenant un modèle avec 2 variable dont une significative. Puis nous pouvons constater des valeurs assez élevés pour le $R^2$ et $R^2_{adjusted}$.

Et on a *AIC* = `r round(AIC(mod_forw), 3)` et *BIC* = `r round(BIC(mod_forw), 3)`.

Donc sans aller tester si c'est un bon modèle prédictif, on constate déjà qu'il va s'agir d'un modèle descriptif fonctionnel avec $n<p$
:::



# Permutations

Maintenant, nous allons permuter de façon aléatoire les salaires des 18 joueurs et refaire la même analyse inférentielle. Ainsi, le lien linéaire devrait disparaitre et nous donner de mauvais résultats.

::: callout-note
pour des raisons de repouctibilité, une graine ou seed a été défini dans le setup afin que la génération aléatoire reste identique.
:::

Faisons à nouveau le modèle brute sur nos 18 joueurs.
```{r}
Hitters_Without_NA_18$Salary_permute <- sample(Salary)

mod1_permute <- lm(Salary_permute~., subset(Hitters_Without_NA_18, select = -Salary))
mod1_permute %>% summary()
```
::: success-header
::: success-icon
::: 
Résultats
:::

::: success
A nouveau on peut constater l'inéfficacité d'un modèle avec toutes les variables du fait d'avoir $p>n$.
:::


Utilisons maintenant la sélection automatique en testant à nouveau l'approche *forward*.

```{r}
mod0_permute <- lm(Salary_permute~1, subset(Hitters_Without_NA_18, select = -Salary))
mod_forw_permute <- step(mod0_permute, 
                         scope = formula(mod1_permute),
                         trace = FALSE,
                         direction = c("forward"))
mod_forw_permute %>% summary()
```

::: success-header
::: success-icon
::: 
Résultats
:::

::: success
On constate que plusieurs variables son significatives. Pourtant, on trouve ici un modèle avec de très mauvais $R^2$ et $R^2_{adjusted}$. Donc un modèle de mauvaise qualité avec en plus une variance assez grande.
:::


Pour finir, on va maintenant reprendre le jeu de données **Hitters** complet et permuter tous les salaires de façon aléatoire. Ensuite, on va ajuster le meilleur modèle de régression possible pour expliquer les salaires en fonction des autres variables.

```{r}
Hitters_Without_NA$Salary_permute <- sample(Hitters_Without_NA$Salary)

mod0_permute <- lm(Salary_permute~., subset(Hitters_Without_NA, select = -Salary))
mod1_permute <- lm(Salary_permute~1, subset(Hitters_Without_NA, select = -Salary))


mod_permute_back <- step(mod1_permute,
                         scope = formula(mod1_permute),
                         trace = FALSE,
                         direction = c("backward"))



mod_permute_forw <- step(mod0_permute,
                         scope = formula(mod1_permute),
                         trace = FALSE,
                         direction = c("forward"))


mod_permute_both <- step(mod0_permute,
                         scope = formula(mod1_permute),
                         trace = FALSE,
                         direction = c("both"))

```

::: panel-tabset

## *Backward*

```{r}
mod_permute_back %>% summary()
```


## *Forward*


```{r}
mod_permute_forw %>% summary()
```

## *Both*

```{r}
mod_permute_both %>% summary()
```


:::

::: success-header
::: success-icon
::: 
Résultats
:::

::: success
On constate qu'aucune méthode de sélection de variable ne permet d'avoir ne serait-ce qu'un modèle correct ce qui montre bien qu'avec la permutation aléatoire de la variable *Salary*, le lien linéaire qui existait à disparu.
:::


# Conclusion

Dans un premier temps, on a pu avoir un aperçu de ce qu'il se passe lorsque l'on se retrouve face au fléa de la dimensionalité avec un sous jeu de données où le nombre de variables était supérieur au nombre d'individus.

Puis, on a aussi pu voir l'importance du lien linéaire dans la construction d'un modèle de regression. Cela renforce par l'exemple la véracité du modèle de régression linéaire (au cas où l'on en doutais encore).

# Session info

```{r}
sessioninfo::session_info(pkgs = "attached")
```
