---
title: "Exercice 2"
author: "Clément Poupelin"
date: "`r Sys.Date()`"
format: 
  html:
    embed-resources: false
    toc: true
    code-fold: true
    code-summary: "Show the code"
    code-tools: true
    toc-location: right
    page-layout: article
    code-overflow: wrap
toc: true
number-sections: false
editor: visual
categories: ["TP"]
image: "/img/baseball.png"
description: "Ici, on continu sur des données de baseball à utilser des méthodes de regression avec selection de variable en testant le lien linéaire existant et en mettant en avant le fléau de la dimensionalité"
---

# Setup

::: panel-tabset
## packages

```{r, setup, warning=FALSE, message=FALSE}
# Données
library(ISLR)         # Hitters data 
library(dplyr)        # manipulation des données
```

## Fonctions
:::

# Données

On étudie à nouveau le jeu de données [**Hitters**](https://rdrr.io/cran/ISLR/man/Hitters.html) disponible dans la libraire { *ISLR* } de *R*.

Il s'agit d'un jeu de données de la Major League Baseball provenant des saisons de 1986 et 1987 possèdant `r dim(Hitters)[1]` lignes/individus pour les différents joueurs et `r dim(Hitters)[2]` variables.

Parmi les variables, on trouve les informations suivantes :

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(kableExtra)
identity_keys <- cell_spec(
  x = colnames(Hitters), format = "html", bold = TRUE)
identity_values <- c("Number of times at bat in 1986", "Number of hits in 1986", "Number of home runs in 1986", "Number of runs in 1986", "Number of runs batted in in 1986", "Number of walks in 1986", "Number of years in the major leagues", "Number of times at bat during his career", "Number of hits during his career", "Number of home runs during his career", "Number of runs during his career", "Number of runs batted in during his career", "Number of walks during his career", "A factor with levels A and N indicating player's league at the end of 1986", "A factor with levels E and W indicating player's division at the end of 1986", "Number of put outs in 1986", "Number of assists in 1986", "Number of errors in 1986", "1987 annual salary on opening day in thousands of dollars", "A factor with levels A and N indicating player's league at the beginning of 1987")
tibble(
  keys = identity_keys, 
  values = identity_values, 
) %>% 
  kbl(
    format = "html", 
    booktabs = TRUE, 
    escape = FALSE, 
    col.names = NULL
  ) %>% 
  kable_styling(bootstrap_options = c("hover", "condensed"))
```

Regardons maintenant le *summary*() pour examiner les différentes variables.

```{r}
# ?Hitters
Hitters %>%
  summary()
```

::: callout-warning
On peut déjà remarquer la présence de 59 valeurs manquantes pour la variable *Salary*.
:::

On va donc commencer par s'en débarasser (il ne s'agit que de 59 lignes sur 322). Puis on va également se concentrer sur les variables quantitatives .

```{r}
Hitters_Without_NA <- Hitters %>% na.omit()
```

Puis cette fois ci nous allons simplement nous concentrer sur un sous jeu de données composé des 18 premières lignes sans valeurs manquantes.

```{r}
Hitters_Without_NA_18 <- Hitters_Without_NA[1:18, ]
Hitters_Without_NA_18 %>% dim()
```

::: callout-warning
Attention, on peut remarquer ici que le nombre de variable est supérieur au nombre d'individus.
:::

Maintenant, il conviendrait dans ce genre de situation d'effectuer de premières analyses descritptives. Mais celle ci ayant déjà été faite pendant l'[Exercice 1](../posts/Exercice_01.qmd), on se permettra de ne pas les refaires.

# Analyse inférentielle

## Modèle brut

On désire modéliser le salaire *Salary* en fonction des variables disponibles.

On va donc ajuster un modèle de régression linéaire en utilisant toutes les variables à disposition et analyser la qualité de cet ajustement.

```{r}
mod1 <- lm(formula = Salary ~ .,
           Hitters_Without_NA_18) 
mod1 %>% summary()

```

::: success-header
::: success-icon
::: 
Résultats
:::

::: success
On peut clairement constater que ce modèle brut ne fonctionne pas avec pourtant un $R^2 = 1$. On retrouve donc le problème typique de l'analyse en grande dimension lorsque $p>n$ (fléau de la dimensionalité).
:::


On peut aussi s'amuser à regarder les critères AIC et BIC de ce modèles qui se retrouve à tendre vers l'infini.

```{r}
cat( "AIC = ", AIC(mod1), "et BIC = ", BIC(mod1))
```

### Prediction

On va maintenant tenter de prédire la variable *Salary* pour les autres joueurs.

Déjà on peut regarder sur les 18 joueurs si la prédiction via le modèle nous donne des bonnes valeur.

```{r, warning=FALSE, message=FALSE}
Salary_hat <- predict(mod1, Hitters_Without_NA_18)
Salary <- Hitters_Without_NA_18$Salary
```

- $\widehat{Salary} - Salary =$ `r round(mean(Salary_hat - Salary), 2)`

Ce que l'on constate c'est qu'effectivement nous sommes avec un résultat qui pourrait nous faire penser que le modèle est bien ajusté.
 
 
Pourtant si nous regardons la prédiction obtenue par le modèle pour les autres joueurs et que nous effectuons la même soustraction pour comparer la qualité de prediction, nous voyons bien l'inéfficacité du modèle. 

```{r, warning=FALSE, message=FALSE}
Hitters_Without_NA_No18 <- Hitters_Without_NA[19:nrow(Hitters_Without_NA),]
Salary_hat_No18 <- predict(mod1, Hitters_Without_NA_No18)
Salary_No18 <- Hitters_Without_NA_No18$Salary
summary(Salary_hat_No18 - Salary_No18 )
```

En effet on voit bien au dessus que les valeurs ne sont pas proche de 0 en moyennes et on même des valeurs assez extrêmes.


## Modèles parcimonieux

On va maintenant mettre un oeuvre une méthode de sélection automatique classique pour réduire le nombre de variable explicative et tenter d'éviter les problèmes de grande dimension.

Pour cela nous allons donc partir du plus petit modèle (celui avec seulement l'*intercept*) puis faire grandir le nombre de variable. Il av donc s'agir d'une méthode de sélection automatique *forward*.

```{r}
mod0 <- lm(Salary~1, Hitters_Without_NA_18)
mod_forw <- step(mod0,
                 scope = formula(mod1),
                 trace = FALSE,
                 direction = c("forward"))
mod_forw %>% summary()
```


::: success-header
::: success-icon
::: 
Résultats
:::

::: success
Nous obtenons maintenant un modèle avec 2 variable dont une significative. Puis nous pouvons constater des valeurs assez élevés pour le $R^2$ et $R^2_{adjusted}$.

Regardons aussi les critères AIC et BIC.
```{r}
cat( "AIC = ", AIC(mod_forw), "et BIC = ", BIC(mod_forw))
```
:::

Maintenant, nous allons permuter de façon aléatoire les salaires des 18 joueurs et refaire la même analyse inférentielle. Ainsi, le lien linéaire devrait disparaitre et nous donner de mauvais résultats.

```{r}
Salary_permute <- sample(Salary)

mod1_permute <- lm(Salary_permute~., Hitters_Without_NA_18)
mod1_permute %>% summary()
```

A nouveau on peut constater l'inéfficacité d'un modèle avec toutes les variables du fait d'avoir $p>n$.

Utilisons maintenant la sélection automatique.

```{r}
mod0_permute <- lm(Salary_permute~1, Hitters_Without_NA_18)
mod_forw_permute <- step(mod0_permute, 
                         scope = formula(mod1_permute),
                         trace = FALSE,
                         direction = c("forward"))
mod_forw_permute %>% summary()
```

::: success-header
::: success-icon
::: 
Résultats
:::

::: success
On retrouve ici un modèle très différent concernant les variables sélectionnés avec de très mauvais résultats de $R^2$ et $R^2_{adjusted}$.
:::

Pour finir, on va maintenant reprendre le jeu de données **Hitters** complet et permuter tous les salaires de façon aléatoire. Ensuite, on va ajuster le meilleur modèle de régression possible pour expliquer les salaires en fonction des autres variables.

```{r}
Salary_permute <- sample(Hitters_Without_NA$Salary)
Hitters_Without_NA_And_Salary = Hitters_Without_NA[,-19]

Hitters_With_Salary_permute <- cbind(Hitters_Without_NA_And_Salary, Salary_permute)

mod0_permute <- lm(Salary_permute~., Hitters_With_Salary_permute)
mod1_permute <- lm(Salary_permute~1, Hitters_With_Salary_permute)


mod_permute_back <- step(mod1_permute,
                         scope = formula(mod1_permute),
                         trace = FALSE,
                         direction = c("backward"))
mod_permute_back %>% summary()


mod_permute_forw <- step(mod0_permute,
                         scope = formula(mod1_permute),
                         trace = FALSE,
                         direction = c("forward"))
mod_permute_forw %>% summary()

mod_permute_both <- step(mod0_permute,
                         scope = formula(mod1_permute),
                         trace = FALSE,
                         direction = c("both"))
mod_permute_both %>% summary()
```

::: success-header
::: success-icon
::: 
Résultats
:::

::: success
On constate de très mauvais résultats de $R^2$ et $R^2_{adjusted}$ et au final la seule variable qui semble vraiment significative est l'*intercept* ce qui montre bien qu'avec la permutation aléatoire de la variable *Salary*, le lien linéaire qui existait à disparu.
:::


# Conclusion

On a donc pu voir l'importance du lien linéaire dans la construction d'un modèle de regression linéaire. Cela renforce par l'exemple la véracité du modèle de régression linéaire (au cas où l'on en doutais encore).

# Session info

```{r}
sessioninfo::session_info(pkgs = "attached")
```
