---
title: "Exercice 06"
author: "Clément Poupelin"
date: "2025-02-23"
date-modified: "`r Sys.Date()`"
format: 
  html:
    embed-resources: false
    toc: true
    code-fold: true
    code-summary: "Show the code"
    code-tools: true
    toc-location: right
    page-layout: article
    code-overflow: wrap
toc: true
number-sections: false
editor: visual
categories: ["Régression sur composantes principales", "Régression des moindres carrés partiels", "Validation croisée"]
image: "/img/baseball.png"
description: "On reprend les données de baseball en mettant en pratique les techniques de **PCR** et **PLSR**"
---

# Intervenant.e.s

### Rédaction

-   **Clément Poupelin**, [clementjc.poupelin\@gmail.com](mailto:clementjc.poupelin@gmail.com){.email}\

### Relecture

-   

# Rappels sur PCR et PLSR

Dans l’analyse des données et la modélisation statistique, la régression linéaire classique peut être limitée lorsque les variables explicatives sont fortement corrélées (problème de colinéarité) ou lorsque leur nombre est supérieur au nombre d’observations (problème de haute dimensionnalité). Pour remédier à ces défis, des méthodes de réduction de dimensionnalité comme la **Régression sur Composantes Principales** (**PCR**) et la **Régression des Moindres Carrés Partiels** (**PLSR**) sont utilisées.

::: panel-tabset
## PCR

La **régression sur Composantes Principales** (**PCR**) repose sur une Analyse en Composantes Principales (ACP) pour transformer les variables explicatives en nouvelles variables orthogonales appelées composantes principales. Seules les premières composantes, capturant le plus de variance, sont conservées dans la régression.\

Cette approche permet de réduire la multicolinéarité et d’éviter le sur-ajustement en limitant la complexité du modèle.\

Cependant, la **PCR** ne prend pas en compte la relation entre les variables explicatives et la variable réponse lors de la sélection des composantes.

## PLSR

Contrairement à la **PCR**, la **régression des Moindres Carrés Partiels** (**PLSR**) cherche à maximiser la covariance entre les variables explicatives et la variable réponse.\
Elle construit des composantes latentes qui capturent non seulement la variance des variables explicatives mais aussi leur corrélation avec la variable à prédire.\

Cette méthode est souvent plus efficace que la **PCR** pour les problèmes de prédiction, car elle optimise directement la relation entre les prédicteurs et la réponse.
:::

En résumé, la **PCR** est une approche basée sur la variance des prédicteurs, tandis que la **PLSR** optimise la relation entre les prédicteurs et la réponse.\
Le choix entre ces deux méthodes dépend du contexte : la **PCR** est utile pour la réduction de dimensionnalité, tandis que la **PLSR** est souvent plus performante pour la prédiction

# Setup

:::: panel-tabset
## Packages

```{r, setup, warning=FALSE, message=FALSE}
# Données
library(ISLR)         # Hitters data 
library(dplyr)        # manipulation des données

# Infrence
library(pls) ## PCR et PLSR


# Plots
## ggplot
library(ggplot2)
library(gridExtra)
```

## Fonctions

::: panel-tabset
### Plot de validation

```{r}
my_validationplot <- function(mod, data) {
  msep.cv <- MSEP(mod, estimate = c("CV", "adjCV"))
  rmsep.cv <- RMSEP(mod, estimate = c("CV", "adjCV"))
  
  x_msep <- c(msep.cv$val[1, , ], msep.cv$val[2, , ])
  x_rmsep <- c(rmsep.cv$val[1, , ], rmsep.cv$val[2, , ])
  y <- c(rep("CV", length(msep.cv$val[2, , ])), rep("adjCV", length(msep.cv$val[2, , ])))
  
  z <- c(0:(ncol(data) - 1), 0:(ncol(data) - 1))
  dt <- data.frame(x_msep, x_rmsep, y, z)
  colnames(dt) <- c("MSEP", "RMSEP", "sample", "comps")
  
  ## MSEP
  p.msep <- ggplot(dt, aes(x = comps, y = MSEP, col = sample)) +
    geom_line() +
    theme_bw() +
    labs(
      title = "Évolution du MSEP en fonction du nombre de composantes",
      x = "Nombre de composantes",
      y = "RMSEP",
      color = "Échantillon"
    ) +
    theme(
      plot.title = element_text(size = 16, face = "bold"),
      axis.title = element_text(size = 14, face = "bold"),
      axis.text = element_text(size = 12),
      legend.title = element_text(size = 14, face = "bold"),
      legend.text = element_text(size = 12)
    )
  
  ## RMSEP
  p.rmsep <- ggplot(dt, aes(x = comps, y = RMSEP, col = sample)) +
    geom_line() +
    theme_bw() +
    labs(
      title = "Évolution du RMSEP en fonction du nombre de composantes",
      x = "Nombre de composantes",
      y = "RMSEP",
      color = "Échantillon"
    ) +
    theme(
      plot.title = element_text(size = 16, face = "bold"),
      axis.title = element_text(size = 14, face = "bold"),
      axis.text = element_text(size = 12),
      legend.title = element_text(size = 14, face = "bold"),
      legend.text = element_text(size = 12)
    )
  
  ## Explain variance
  explain_variance <- explvar(mod)
  
  # Créer un data frame
  dt_var <- data.frame(comps = seq_along(explain_variance),
                       variance = explain_variance * 100)
                       
  # Tracer le graphique
  p.variance <- ggplot(dt_var, aes(x = comps, y = variance)) +
                         geom_line(color = "blue") +
                         geom_point(color = "red") +
                         theme_bw() +
                         labs(title = "Évolution de la Variance Expliquée en Fonction du Nombre de Composantes", x = "Nombre de Composantes", y = "Variance Expliquée (%)") +
                         theme(
                           plot.title = element_text(size = 16, face = "bold"),
                           axis.title = element_text(size = 14, face = "bold"),
                           axis.text = element_text(size = 12)
                         )
                       
                       
  return(list(MSEP = p.msep, RMSEP = p.rmsep, Exp_Var = p.variance))
}
```
:::

## Seed

```{r}
set.seed(140400)
```
::::

# Données

On étudie à nouveau le jeu de données [**Hitters**](https://rdrr.io/cran/ISLR/man/Hitters.html) disponible dans la libraire *`{ISLR}`* de *`R`*. Il s'agit d'un jeu de données de la *Major League Baseball* provenant des saisons de 1986 et 1987.

Le jeu de données possède `r dim(Hitters)[1]` lignes/individus pour les différents joueurs et `r dim(Hitters)[2]` variables.\
Parmi les variables, on trouve les informations suivantes :

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(kableExtra)
identity_keys <- cell_spec(
  x = colnames(Hitters), format = "html", bold = TRUE)
identity_values <- c("Number of times at bat in 1986", "Number of hits in 1986", "Number of home runs in 1986", "Number of runs in 1986", "Number of runs batted in in 1986", "Number of walks in 1986", "Number of years in the major leagues", "Number of times at bat during his career", "Number of hits during his career", "Number of home runs during his career", "Number of runs during his career", "Number of runs batted in during his career", "Number of walks during his career", "A factor with levels A and N indicating player's league at the end of 1986", "A factor with levels E and W indicating player's division at the end of 1986", "Number of put outs in 1986", "Number of assists in 1986", "Number of errors in 1986", "1987 annual salary on opening day in thousands of dollars", "A factor with levels A and N indicating player's league at the beginning of 1987")
tibble(
  keys = identity_keys, 
  values = identity_values, 
) %>% 
  kbl(
    format = "html", 
    booktabs = TRUE, 
    escape = FALSE, 
    col.names = NULL
  ) %>% 
  kable_styling(bootstrap_options = c("hover", "condensed"))
```

Comme pour l'[Exercice 1](../posts/Exercice_01.qmd), on va commencer par se débarasser des variables manquantes.

```{r}
Hitters_Without_NA <- Hitters %>% na.omit()
```

Comme cela fait maintenant plusieurs fois que l'on fait affaire à ce jeu de données, on se passera des analyses descritpives faites en [Exercice 1](../posts/Exercice_01.qmd).

Ainsi, on va pouvoir tout de suite commencer par faire le découpage de notre jeu de données en échantillon *train* et *test*. Le jeu de données *train* contiendra 3/4 des individus sans valeurs manquantes de Hitters, tirés aléatoirement. Le reste du jeu de données composera l’échantillon *test*.

```{r}
percent_to_draw <- 0.75
index_train <- sample(nrow(Hitters_Without_NA), size = floor(percent_to_draw * nrow(Hitters_Without_NA)))

Hitters_train <- Hitters_Without_NA[index_train, ]

Hitters_test <- Hitters_Without_NA[-index_train, ]
```

# Analyse Inférentielle

On va maintenant effectuer une régression **PCR** et une régression **PLSR** sur l’échantillon *train* en sélectionnant le nombre de composantes par une validation croisée *K-fold* où $K = 10$.

::: panel-tabset
## PCR

```{r}
mod_pcr <- pcr(
  Salary ~ .,
  scale = TRUE,
  data = Hitters_train,
  validation = "CV",
  segments = 10
)
mod_pcr %>% summary()
```

## PLSR

```{r}
mod_pls <- plsr(
  Salary ~ .,
  scale = TRUE,
  data = Hitters_train,
  validation = "CV",
  segments = 10
)
mod_pls %>% summary()
```
:::

On peut maintenant visualiser l'évolution du MSEP et RMSEP en fonction du nombre de composantes gardées.

::: callout-note
Pour des raisons esthétiques, on à ici construit un graphique à partir de `ggplot2`mais on aurait pu se contenter d'utiliser la fonction `validationplot` de la library `pls`.
:::

::: panel-tabset
## PCR

```{r, fig.height=8, fig.width=18}
grid.arrange(my_validationplot(mod_pcr, Hitters_train)$RMSEP,
             my_validationplot(mod_pcr, Hitters_train)$Exp_Var,
             ncol=2)
```

## PLS

```{r, fig.height=8, fig.width=18}
grid.arrange(my_validationplot(mod_pls, Hitters_train)$RMSEP,
             my_validationplot(mod_pls, Hitters_train)$Exp_Var,
             ncol=2)
```
:::

:::: success-header
::: success-icon
:::

Résultats
::::

::: success
Pour la **PCR** on peut voir courbe proche entre *CV* et *adjCV* avec une première valeur minimum qui semble se trouver à partir de 5 composantes.\
Ensuite la courbe remonte à nouveau pour redescendre progressivement. Et concernant le pourcentage de variance expliquée, on voit un coude au niveau de 5 composantes.

Tandus que pour la **PLSR** on voit plutôt que c'est à partir de 5 composantes que la décroissance commence. Et pour le pourcentage de variance expliquée, on voit un coude au niveau de 5 composantes.
:::

Et on peut alors récupérer le nombre de composantes à garder qui minimsent le MSEP et RMSEP.

```{r}
ncomp.rmsep_pcr <- which.min(RMSEP(mod_pcr, estimate = c("CV"))$val["CV",,])-1
ncomp.rmsep_pls <- which.min(RMSEP(mod_pls, estimate = c("CV"))$val["CV",,])-1
```

:::: success-header
::: success-icon
:::

Résultats
::::

::: success
On a que le nombre de composante à retenir est de `r ncomp.rmsep_pcr` pour la PCR et `r ncomp.rmsep_pls` pour la PLSR.
:::

# Prédiction

On va calculer le RMSEP calculé à partir de la prédiction pour l'échantillon test.

```{r}
hat_Hitters_test_mod_pcr <- predict(mod_pcr,
                                    Hitters_test,
                                    ncomp = (which.min(RMSEP(mod_pcr, estimate = c("CV"))$val["CV", , ]) - 1))
rmsep_mod_pcr_pred <- sqrt(mean((hat_Hitters_test_mod_pcr - Hitters_test$Salary) ** 2))

hat_df_test_salary.pls <- predict(mod_pls,
                                  Hitters_test,
                                  ncomp = (which.min(RMSEP(mod_pls, estimate = c("CV"))$val["CV", , ]) - 1))
rmsep_mod_pls_pred <- sqrt(mean((hat_df_test_salary.pls - Hitters_test$Salary) ** 2))
```

```{r}
rmsep_pred_df <- data.frame("prediction PCR" = rmsep_mod_pcr_pred, "prediction PLS" = rmsep_mod_pls_pred) 
rownames(rmsep_pred_df) <- "RMSEP"
rmsep_pred_df 
```

Le choix final du modèle peut ainsi se reposer sur celui qui minimise la *RMSEP* pour la prediction de notre échantillon *test*.

# Conclusion

En conclusion, on a ici 2 méthodes complémentaires permettant de construire des modèles linéaires pour des données de grandes dimension.\

Ce sont des méthodes intuitives et robustes souvent utilisés par les statisticiens.

# Session info

```{r}
sessioninfo::session_info(pkgs = "attached")
```
